{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview What Is Argo CD? Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes. Why Argo CD? Application definitions, configurations, and environments should be declarative and version controlled. Application deployment and lifecycle management should be automated, auditable, and easy to understand. Getting Started Quick Start kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml Follow our getting started guide . Further documentation is provided for additional features. How it works Argo CD follows the GitOps pattern of using Git repositories as the source of truth for defining the desired application state. Kubernetes manifests can be specified in several ways: kustomize applications helm charts ksonnet applications jsonnet files Plain directory of YAML/json manifests Any custom config management tool configured as a config management plugin Argo CD automates the deployment of the desired application states in the specified target environments. Application deployments can track updates to branches, tags, or pinned to a specific version of manifests at a Git commit. See tracking strategies for additional details about the different tracking strategies available. For a quick 10 minute overview of Argo CD, check out the demo presented to the Sig Apps community meeting: Architecture Argo CD is implemented as a kubernetes controller which continuously monitors running applications and compares the current, live state against the desired target state (as specified in the Git repo). A deployed application whose live state deviates from the target state is considered OutOfSync . Argo CD reports visualizes the differences, while providing facilities to automatically or manually sync the live state back to the desired target state. Any modifications made to the desired target state in the Git repo can be automatically applied and reflected in the specified target environments. For additional details, see architecture overview . Features Automated deployment of applications to specified target environments Support for multiple config management/templating tools (Kustomize, Helm, Ksonnet, Jsonnet, plain-YAML) Ability to manage and deploy to multiple clusters SSO Integration (OIDC, OAuth2, LDAP, SAML 2.0, GitHub, GitLab, Microsoft, LinkedIn) Multi-tenancy and RBAC policies for authorization Rollback/Roll-anywhere to any application configuration committed in Git repository Health status analysis of application resources Automated configuration drift detection and visualization Automated or manual syncing of applications to its desired state Web UI which provides real-time view of application activity CLI for automation and CI integration Webhook integration (GitHub, BitBucket, GitLab) Access tokens for automation PreSync, Sync, PostSync hooks to support complex application rollouts (e.g.blue/green canary upgrades) Audit trails for application events and API calls Prometheus metrics Parameter overrides for overriding ksonnet/helm parameters in Git Community Blogs And Presentations GitOps with Argo CD: Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager KubeCon talk: CI/CD in Light Speed with K8s and Argo CD KubeCon talk: Machine Learning as Code Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML SIG Apps demo: Argo CD - GitOps Continuous Delivery for Kubernetes Development Status Argo CD is actively developed and is being used in production to deploy SaaS services at Intuit","title":"Overview"},{"location":"#overview","text":"","title":"Overview"},{"location":"#what-is-argo-cd","text":"Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.","title":"What Is Argo CD?"},{"location":"#why-argo-cd","text":"Application definitions, configurations, and environments should be declarative and version controlled. Application deployment and lifecycle management should be automated, auditable, and easy to understand.","title":"Why Argo CD?"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#quick-start","text":"kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml Follow our getting started guide . Further documentation is provided for additional features.","title":"Quick Start"},{"location":"#how-it-works","text":"Argo CD follows the GitOps pattern of using Git repositories as the source of truth for defining the desired application state. Kubernetes manifests can be specified in several ways: kustomize applications helm charts ksonnet applications jsonnet files Plain directory of YAML/json manifests Any custom config management tool configured as a config management plugin Argo CD automates the deployment of the desired application states in the specified target environments. Application deployments can track updates to branches, tags, or pinned to a specific version of manifests at a Git commit. See tracking strategies for additional details about the different tracking strategies available. For a quick 10 minute overview of Argo CD, check out the demo presented to the Sig Apps community meeting:","title":"How it works"},{"location":"#architecture","text":"Argo CD is implemented as a kubernetes controller which continuously monitors running applications and compares the current, live state against the desired target state (as specified in the Git repo). A deployed application whose live state deviates from the target state is considered OutOfSync . Argo CD reports visualizes the differences, while providing facilities to automatically or manually sync the live state back to the desired target state. Any modifications made to the desired target state in the Git repo can be automatically applied and reflected in the specified target environments. For additional details, see architecture overview .","title":"Architecture"},{"location":"#features","text":"Automated deployment of applications to specified target environments Support for multiple config management/templating tools (Kustomize, Helm, Ksonnet, Jsonnet, plain-YAML) Ability to manage and deploy to multiple clusters SSO Integration (OIDC, OAuth2, LDAP, SAML 2.0, GitHub, GitLab, Microsoft, LinkedIn) Multi-tenancy and RBAC policies for authorization Rollback/Roll-anywhere to any application configuration committed in Git repository Health status analysis of application resources Automated configuration drift detection and visualization Automated or manual syncing of applications to its desired state Web UI which provides real-time view of application activity CLI for automation and CI integration Webhook integration (GitHub, BitBucket, GitLab) Access tokens for automation PreSync, Sync, PostSync hooks to support complex application rollouts (e.g.blue/green canary upgrades) Audit trails for application events and API calls Prometheus metrics Parameter overrides for overriding ksonnet/helm parameters in Git","title":"Features"},{"location":"#community-blogs-and-presentations","text":"GitOps with Argo CD: Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager KubeCon talk: CI/CD in Light Speed with K8s and Argo CD KubeCon talk: Machine Learning as Code Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML SIG Apps demo: Argo CD - GitOps Continuous Delivery for Kubernetes","title":"Community Blogs And Presentations"},{"location":"#development-status","text":"Argo CD is actively developed and is being used in production to deploy SaaS services at Intuit","title":"Development Status"},{"location":"CONTRIBUTING/","text":"Contributing Before You Start You must install and run the ArgoCD using a local Kubernetes (e.g. Docker for Desktop or Minikube) first. This will help you understand the application, but also get your local environment set-up. Then, to get a good grounding in Go, try out the tutorial . Pre-requisites Install: docker golang dep protobuf ksonnet helm kustomize go-swagger jq kubectl kubectx minikube or Docker for Desktop Versions You will find problems generating code if you do not have the correct versions of protoc and swagger $ protoc --version libprotoc 3 .7.1 ~/go/src/github.com/argoproj/argo-cd ( ui ) $ swagger version version: v0.19.0 Brew users can quickly install the lot: brew tap go-swagger/go-swagger brew install go dep protobuf kubectl kubectx ksonnet/tap/ks kubernetes-helm jq go-swagger kustomize Kustomize Since Argo CD supports Kustomize v1.0 and v2.0, you will need to install both versions in order for the unit tests to run. The Kustomize 1 unit test expects to find a kustomize1 binary in the path. You can use this link to find the Kustomize 1 currently used by Argo CD and modify the curl command to download the correct OS. Set up environment variables (e.g. is ~/.bashrc ): export GOPATH = ~/go export PATH = $PATH : $GOPATH /bin Checkout the code: go get -u github.com/argoproj/argo-cd cd ~/go/src/github.com/argoproj/argo-cd Install go dependencies: make install-dev-tools Building make The make command can take a while, and we recommend building the specific component you are working on make codegen - Builds protobuf and swagger files make cli - Make the argocd CLI tool make server - Make the API/repo/controller server make argocd-util - Make the administrator's utility, used for certain tasks such as import/export Running Tests To run unit tests: make test Check out the following documentation for instructions on running the e2e tests. Running Locally It is much easier to run and debug if you run ArgoCD on your local machine than in the Kubernetes cluster. You should scale the deployments to zero: kubectl -n argocd scale deployment.extensions/argocd-application-controller --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-dex-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-repo-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-redis --replicas 0 Note: you'll need to use the https://localhost:6443 cluster now. Then start the services: cd ~/go/src/github.com/argoproj/argo-cd make start You can now execute argocd command against your locally running ArgoCD by appending --server localhost:8080 --plaintext --insecure , e.g.: argocd app set guestbook --path guestbook --repo https://github.com/argoproj/argocd-example-apps.git --dest-server https://localhost:6443 --dest-namespace default --server localhost:8080 --plaintext --insecure You can open the UI: http://localhost:8080 Note: you'll need to use the https://kubernetes.default.svc cluster now. Running Local Containers You may need to run containers locally, so here's how: Create login to Docker Hub, then login. docker login Add your username as the environment variable, e.g. to your ~/.bash_profile : export IMAGE_NAMESPACE = alexcollinsintuit If you have not built the UI image (see the UI README ), then do the following: docker pull argoproj/argocd-ui:latest docker tag argoproj/argocd-ui:latest $IMAGE_NAMESPACE /argocd-ui:latest docker push $IMAGE_NAMESPACE /argocd-ui:latest Build the images: DOCKER_PUSH = true make image Update the manifests: make manifests Install the manifests: kubectl -n argocd apply --force -f manifests/install.yaml Scale your deployments up: kubectl -n argocd scale deployment.extensions/argocd-application-controller --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-dex-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-repo-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-redis --replicas 1 Now you can set-up the port-forwarding and open the UI or CLI.","title":"Contributing"},{"location":"CONTRIBUTING/#contributing","text":"","title":"Contributing"},{"location":"CONTRIBUTING/#before-you-start","text":"You must install and run the ArgoCD using a local Kubernetes (e.g. Docker for Desktop or Minikube) first. This will help you understand the application, but also get your local environment set-up. Then, to get a good grounding in Go, try out the tutorial .","title":"Before You Start"},{"location":"CONTRIBUTING/#pre-requisites","text":"Install: docker golang dep protobuf ksonnet helm kustomize go-swagger jq kubectl kubectx minikube or Docker for Desktop Versions You will find problems generating code if you do not have the correct versions of protoc and swagger $ protoc --version libprotoc 3 .7.1 ~/go/src/github.com/argoproj/argo-cd ( ui ) $ swagger version version: v0.19.0 Brew users can quickly install the lot: brew tap go-swagger/go-swagger brew install go dep protobuf kubectl kubectx ksonnet/tap/ks kubernetes-helm jq go-swagger kustomize Kustomize Since Argo CD supports Kustomize v1.0 and v2.0, you will need to install both versions in order for the unit tests to run. The Kustomize 1 unit test expects to find a kustomize1 binary in the path. You can use this link to find the Kustomize 1 currently used by Argo CD and modify the curl command to download the correct OS. Set up environment variables (e.g. is ~/.bashrc ): export GOPATH = ~/go export PATH = $PATH : $GOPATH /bin Checkout the code: go get -u github.com/argoproj/argo-cd cd ~/go/src/github.com/argoproj/argo-cd Install go dependencies: make install-dev-tools","title":"Pre-requisites"},{"location":"CONTRIBUTING/#building","text":"make The make command can take a while, and we recommend building the specific component you are working on make codegen - Builds protobuf and swagger files make cli - Make the argocd CLI tool make server - Make the API/repo/controller server make argocd-util - Make the administrator's utility, used for certain tasks such as import/export","title":"Building"},{"location":"CONTRIBUTING/#running-tests","text":"To run unit tests: make test Check out the following documentation for instructions on running the e2e tests.","title":"Running Tests"},{"location":"CONTRIBUTING/#running-locally","text":"It is much easier to run and debug if you run ArgoCD on your local machine than in the Kubernetes cluster. You should scale the deployments to zero: kubectl -n argocd scale deployment.extensions/argocd-application-controller --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-dex-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-repo-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-server --replicas 0 kubectl -n argocd scale deployment.extensions/argocd-redis --replicas 0 Note: you'll need to use the https://localhost:6443 cluster now. Then start the services: cd ~/go/src/github.com/argoproj/argo-cd make start You can now execute argocd command against your locally running ArgoCD by appending --server localhost:8080 --plaintext --insecure , e.g.: argocd app set guestbook --path guestbook --repo https://github.com/argoproj/argocd-example-apps.git --dest-server https://localhost:6443 --dest-namespace default --server localhost:8080 --plaintext --insecure You can open the UI: http://localhost:8080 Note: you'll need to use the https://kubernetes.default.svc cluster now.","title":"Running Locally"},{"location":"CONTRIBUTING/#running-local-containers","text":"You may need to run containers locally, so here's how: Create login to Docker Hub, then login. docker login Add your username as the environment variable, e.g. to your ~/.bash_profile : export IMAGE_NAMESPACE = alexcollinsintuit If you have not built the UI image (see the UI README ), then do the following: docker pull argoproj/argocd-ui:latest docker tag argoproj/argocd-ui:latest $IMAGE_NAMESPACE /argocd-ui:latest docker push $IMAGE_NAMESPACE /argocd-ui:latest Build the images: DOCKER_PUSH = true make image Update the manifests: make manifests Install the manifests: kubectl -n argocd apply --force -f manifests/install.yaml Scale your deployments up: kubectl -n argocd scale deployment.extensions/argocd-application-controller --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-dex-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-repo-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-server --replicas 1 kubectl -n argocd scale deployment.extensions/argocd-redis --replicas 1 Now you can set-up the port-forwarding and open the UI or CLI.","title":"Running Local Containers"},{"location":"SUPPORT/","text":"Support Make sure you've read understanding the basics the getting started guide . Looked for an answer the frequently asked questions . Ask a question in the Argo CD Slack channel \u29c9 . Read issues, report a bug, or request a feature \u29c9","title":"Support"},{"location":"SUPPORT/#support","text":"Make sure you've read understanding the basics the getting started guide . Looked for an answer the frequently asked questions . Ask a question in the Argo CD Slack channel \u29c9 . Read issues, report a bug, or request a feature \u29c9","title":"Support"},{"location":"core_concepts/","text":"Core Concepts Let's assume you're familiar with core Git, Docker, Kubernetes, Continuous Delivery, and GitOps concepts. Application A group of Kubernetes resources as defined by a manifest. This is a Custom Resource Definition (CRD). Application source type Which Tool is used to build the application. Target state The desired state of an application, as represented by files in a Git repository. Live state The live state of that application. What pods etc are deployed. Sync status Whether or not the live state matches the target state. Is the deployed application the same as Git says it should be? Sync The process of making an application move to its target state. E.g. by applying changes to a Kubernetes cluster. Sync operation status Whether or not a sync succeeded. Refresh Compare the latest code in Git with the live state. Figure out what is different. Health The health the application, is it running correctly? Can it serve requests? Tool A tool to create manifests from a directory of files. E.g. Kustomize or Ksonnet. See Application Source Type . Configuration management tool See Tool . Configuration management plugin A custom tool.","title":"Core Concepts"},{"location":"core_concepts/#core-concepts","text":"Let's assume you're familiar with core Git, Docker, Kubernetes, Continuous Delivery, and GitOps concepts. Application A group of Kubernetes resources as defined by a manifest. This is a Custom Resource Definition (CRD). Application source type Which Tool is used to build the application. Target state The desired state of an application, as represented by files in a Git repository. Live state The live state of that application. What pods etc are deployed. Sync status Whether or not the live state matches the target state. Is the deployed application the same as Git says it should be? Sync The process of making an application move to its target state. E.g. by applying changes to a Kubernetes cluster. Sync operation status Whether or not a sync succeeded. Refresh Compare the latest code in Git with the live state. Figure out what is different. Health The health the application, is it running correctly? Can it serve requests? Tool A tool to create manifests from a directory of files. E.g. Kustomize or Ksonnet. See Application Source Type . Configuration management tool See Tool . Configuration management plugin A custom tool.","title":"Core Concepts"},{"location":"faq/","text":"FAQ I've deleted/corrupted my repo and can't delete my app. Argo CD can't delete an app if it cannot generate manifests. You need to either: Reinstate/fix your repo. Delete the app using --cascade=false and then manually deleting the resources. Why is my application still OutOfSync immediately after a successful Sync? See Diffing documentation for reasons resources can be OutOfSync, and ways to configure Argo CD to ignore fields when differences are expected. Why is my application stuck in Progressing state? Argo CD provides health for several standard Kubernetes types. The Ingress and StatefulSet types have known issues which might cause health check to return Progressing state instead of Healthy . Ingress is considered healthy if status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP . Some ingress controllers ( contour , traefik ) don't update status.loadBalancer.ingress field which causes Ingress to stuck in Progressing state forever. StatefulSet is considered healthy if value of status.updatedReplicas field matches to spec.replicas field. Due to Kubernetes bug kubernetes/kubernetes#68573 the status.updatedReplicas is not populated. So unless you run Kubernetes version which include the fix kubernetes/kubernetes#67570 StatefulSet might stay in Progressing state. As workaround Argo CD allows providing health check customization which overrides default behavior. I forgot the admin password, how do I reset it? By default the password is set to the name of the server pod, as per the getting started guide . To change the password, edit the argocd-secret secret and update the admin.password field with a new bcrypt hash. You can use a site like https://www.browserling.com/tools/bcrypt to generate a new hash. For example: # bcrypt(Password1!)=$2a$10$hDj12Tw9xVmvybSahN1Y0.f9DZixxN8oybyA32Uy/eqWklFU4Mo8O kubectl -n argocd patch secret argocd-secret \\ -p {\\ data\\ : \\ {\\ \\ admin.password\\ : \\ $( echo -n $2a$10$hDj12Tw9xVmvybSahN1Y0.f9DZixxN8oybyA32Uy/eqWklFU4Mo8O | base64 ) \\ , \\ \\ admin.passwordMtime\\ : \\ $( date +%FT%T%Z | base64 ) \\ \\ }} Another option is to delete both the admin.password and admin.passwordMtime keys and restart argocd-server. This will set the password back to the pod name as per the getting started guide . Argo CD cannot deploy Helm Chart based applications without internet access, how can I solve it? Argo CD might fail to generate Helm chart manifests if the chart has dependencies located in external repositories. To solve the problem you need to make sure that requirements.yaml uses only internally available Helm repositories. Even if the chart uses only dependencies from internal repos Helm might decide to refresh stable repo. As workaround override stable repo URL in argocd-cm config map: data : helm.repositories : | - url: http:// internal-helm-repo-host :8080 name: stable I've configured cluster secret but it does not show up in CLI/UI, how do I fix it? Check if cluster secret has argocd.argoproj.io/secret-type: cluster label. If secret has the label but the cluster is still not visible then make sure it might be a permission issue. Try to list clusters using admin user (e.g. argocd login --username admin argocd cluster list ). Argo CD is unable to connect to my cluster, how do I troubleshoot it? Use the following steps to reconstruct configured cluster config and connect to your cluster manually using kubectl: kubectl exec -it argocd-pod-name bash # ssh into any argocd server pod argocd-util kubeconfig https:// cluster-url /tmp/config --namespace argocd # generate your cluster config KUBECONFIG = /tmp/config kubectl get pods # test connection manually Now you can manually verify that cluster is accessible from the Argo CD pod. How Can I Terminate A Sync? To terminate the sync, click on the \"synchronisation\" then \"terminate\":","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#ive-deletedcorrupted-my-repo-and-cant-delete-my-app","text":"Argo CD can't delete an app if it cannot generate manifests. You need to either: Reinstate/fix your repo. Delete the app using --cascade=false and then manually deleting the resources.","title":"I've deleted/corrupted my repo and can't delete my app."},{"location":"faq/#why-is-my-application-still-outofsync-immediately-after-a-successful-sync","text":"See Diffing documentation for reasons resources can be OutOfSync, and ways to configure Argo CD to ignore fields when differences are expected.","title":"Why is my application still OutOfSync immediately after a successful Sync?"},{"location":"faq/#why-is-my-application-stuck-in-progressing-state","text":"Argo CD provides health for several standard Kubernetes types. The Ingress and StatefulSet types have known issues which might cause health check to return Progressing state instead of Healthy . Ingress is considered healthy if status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP . Some ingress controllers ( contour , traefik ) don't update status.loadBalancer.ingress field which causes Ingress to stuck in Progressing state forever. StatefulSet is considered healthy if value of status.updatedReplicas field matches to spec.replicas field. Due to Kubernetes bug kubernetes/kubernetes#68573 the status.updatedReplicas is not populated. So unless you run Kubernetes version which include the fix kubernetes/kubernetes#67570 StatefulSet might stay in Progressing state. As workaround Argo CD allows providing health check customization which overrides default behavior.","title":"Why is my application stuck in Progressing state?"},{"location":"faq/#i-forgot-the-admin-password-how-do-i-reset-it","text":"By default the password is set to the name of the server pod, as per the getting started guide . To change the password, edit the argocd-secret secret and update the admin.password field with a new bcrypt hash. You can use a site like https://www.browserling.com/tools/bcrypt to generate a new hash. For example: # bcrypt(Password1!)=$2a$10$hDj12Tw9xVmvybSahN1Y0.f9DZixxN8oybyA32Uy/eqWklFU4Mo8O kubectl -n argocd patch secret argocd-secret \\ -p {\\ data\\ : \\ {\\ \\ admin.password\\ : \\ $( echo -n $2a$10$hDj12Tw9xVmvybSahN1Y0.f9DZixxN8oybyA32Uy/eqWklFU4Mo8O | base64 ) \\ , \\ \\ admin.passwordMtime\\ : \\ $( date +%FT%T%Z | base64 ) \\ \\ }} Another option is to delete both the admin.password and admin.passwordMtime keys and restart argocd-server. This will set the password back to the pod name as per the getting started guide .","title":"I forgot the admin password, how do I reset it?"},{"location":"faq/#argo-cd-cannot-deploy-helm-chart-based-applications-without-internet-access-how-can-i-solve-it","text":"Argo CD might fail to generate Helm chart manifests if the chart has dependencies located in external repositories. To solve the problem you need to make sure that requirements.yaml uses only internally available Helm repositories. Even if the chart uses only dependencies from internal repos Helm might decide to refresh stable repo. As workaround override stable repo URL in argocd-cm config map: data : helm.repositories : | - url: http:// internal-helm-repo-host :8080 name: stable","title":"Argo CD cannot deploy Helm Chart based applications without internet access, how can I solve it?"},{"location":"faq/#ive-configured-cluster-secret-but-it-does-not-show-up-in-cliui-how-do-i-fix-it","text":"Check if cluster secret has argocd.argoproj.io/secret-type: cluster label. If secret has the label but the cluster is still not visible then make sure it might be a permission issue. Try to list clusters using admin user (e.g. argocd login --username admin argocd cluster list ).","title":"I've configured cluster secret but it does not show up in CLI/UI, how do I fix it?"},{"location":"faq/#argo-cd-is-unable-to-connect-to-my-cluster-how-do-i-troubleshoot-it","text":"Use the following steps to reconstruct configured cluster config and connect to your cluster manually using kubectl: kubectl exec -it argocd-pod-name bash # ssh into any argocd server pod argocd-util kubeconfig https:// cluster-url /tmp/config --namespace argocd # generate your cluster config KUBECONFIG = /tmp/config kubectl get pods # test connection manually Now you can manually verify that cluster is accessible from the Argo CD pod.","title":"Argo CD is unable to connect to my cluster, how do I troubleshoot it?"},{"location":"faq/#how-can-i-terminate-a-sync","text":"To terminate the sync, click on the \"synchronisation\" then \"terminate\":","title":"How Can I Terminate A Sync?"},{"location":"getting_started/","text":"Getting Started Tip This guide assumes you have a grounding in the tools that Argo CD is based on. Please read the understanding the basics . Requirements Installed kubectl command-line tool Have a kubeconfig file (default location is ~/.kube/config ). 1. Install Argo CD kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml This will create a new namespace, argocd , where Argo CD services and application resources will live. On GKE, you will need grant your account the ability to create new cluster roles: kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole = cluster-admin --user = YOUREMAIL@gmail.com 2. Download Argo CD CLI Download the latest Argo CD version from [https://github.com/argoproj/argo-cd/releases/latest]. Also available in Mac Homebrew: brew tap argoproj/tap brew install argoproj/tap/argocd 3. Access The Argo CD API Server By default, the Argo CD API server is not exposed with an external IP. To access the API server, choose one of the following techniques to expose the Argo CD API server: Service Type Load Balancer Change the argocd-server service type to LoadBalancer : kubectl patch svc argocd-server -n argocd -p { spec : { type : LoadBalancer }} Ingress Follow the ingress documentation on how to configure Argo CD with ingress. Port Forwarding Kubectl port-forwarding can also be used to connect to the API server without exposing the service. kubectl port-forward svc/argocd-server -n argocd 8080 :443 The API server can then be accessed using the localhost:8080 4. Login Using The CLI Login as the admin user. The initial password is autogenerated to be the pod name of the Argo CD API server. This can be retrieved with the command: kubectl get pods -n argocd -l app.kubernetes.io/name = argocd-server -o name | cut -d / -f 2 Using the above password, login to Argo CD's IP or hostname: argocd login ARGOCD_SERVER Change the password using the command: argocd account update-password 5. Register A Cluster To Deploy Apps To (Optional) This step registers a cluster's credentials to Argo CD, and is only necessary when deploying to an external cluster. When deploying internally (to the same cluster that Argo CD is running in), https://kubernetes.default.svc should be used as the application's K8s API server address. First list all clusters contexts in your current kubconfig: argocd cluster add Choose a context name from the list and supply it to argocd cluster add CONTEXTNAME . For example, for docker-for-desktop context, run: argocd cluster add docker-for-desktop The above command installs a ServiceAccount ( argocd-manager ), into the kube-system namespace of that kubectl context, and binds the service account to an admin-level ClusterRole. Argo CD uses this service account token to perform its management tasks (i.e. deploy/monitoring). Note The rules of the argocd-manager-role role can be modified such that it only has create , update , patch , delete privileges to a limited set of namespaces, groups, kinds. However get , list , watch privileges are required at the cluster-scope for Argo CD to function. 6. Create An Application From A Git Repository An example repository containing a guestbook application is available at https://github.com/argoproj/argocd-example-apps.git to demonstrate how Argo CD works. Creating Apps Via CLI argocd app create guestbook \\ --repo https://github.com/argoproj/argocd-example-apps.git \\ --path guestbook \\ --dest-server https://kubernetes.default.svc \\ --dest-namespace default Creating Apps Via UI Open a browser to the Argo CD external UI, and login using the credentials, IP/hostname set in step 4. Connect the https://github.com/argoproj/argocd-example-apps.git repo to Argo CD: After connecting a repository, select the guestbook application for creation: 7. Sync (Deploy) The Application Once the guestbook application is created, you can now view its status: $ argocd app get guestbook Name: guestbook Server: https://kubernetes.default.svc Namespace: default URL: https://10.97.164.88/applications/guestbook Repo: https://github.com/argoproj/argocd-example-apps.git Target: Path: guestbook Sync Policy: none Sync Status: OutOfSync from ( 1ff8a67 ) Health Status: Missing GROUP KIND NAMESPACE NAME STATUS HEALTH apps Deployment default guestbook-ui OutOfSync Missing Service default guestbook-ui OutOfSync Missing The application status is initially OutOfSync state, since the application has yet to be deployed, and no Kubernetes resources have been created. To sync (deploy) the application, run: argocd app sync guestbook This command retrieves the manifests from the repository and performs a kubectl apply of the manifests. The guestbook app is now running and you can now view its resource components, logs, events, and assessed health status: From UI:","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"Tip This guide assumes you have a grounding in the tools that Argo CD is based on. Please read the understanding the basics .","title":"Getting Started"},{"location":"getting_started/#requirements","text":"Installed kubectl command-line tool Have a kubeconfig file (default location is ~/.kube/config ).","title":"Requirements"},{"location":"getting_started/#1-install-argo-cd","text":"kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml This will create a new namespace, argocd , where Argo CD services and application resources will live. On GKE, you will need grant your account the ability to create new cluster roles: kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole = cluster-admin --user = YOUREMAIL@gmail.com","title":"1. Install Argo CD"},{"location":"getting_started/#2-download-argo-cd-cli","text":"Download the latest Argo CD version from [https://github.com/argoproj/argo-cd/releases/latest]. Also available in Mac Homebrew: brew tap argoproj/tap brew install argoproj/tap/argocd","title":"2. Download Argo CD CLI"},{"location":"getting_started/#3-access-the-argo-cd-api-server","text":"By default, the Argo CD API server is not exposed with an external IP. To access the API server, choose one of the following techniques to expose the Argo CD API server:","title":"3. Access The Argo CD API Server"},{"location":"getting_started/#service-type-load-balancer","text":"Change the argocd-server service type to LoadBalancer : kubectl patch svc argocd-server -n argocd -p { spec : { type : LoadBalancer }}","title":"Service Type Load Balancer"},{"location":"getting_started/#ingress","text":"Follow the ingress documentation on how to configure Argo CD with ingress.","title":"Ingress"},{"location":"getting_started/#port-forwarding","text":"Kubectl port-forwarding can also be used to connect to the API server without exposing the service. kubectl port-forward svc/argocd-server -n argocd 8080 :443 The API server can then be accessed using the localhost:8080","title":"Port Forwarding"},{"location":"getting_started/#4-login-using-the-cli","text":"Login as the admin user. The initial password is autogenerated to be the pod name of the Argo CD API server. This can be retrieved with the command: kubectl get pods -n argocd -l app.kubernetes.io/name = argocd-server -o name | cut -d / -f 2 Using the above password, login to Argo CD's IP or hostname: argocd login ARGOCD_SERVER Change the password using the command: argocd account update-password","title":"4. Login Using The CLI"},{"location":"getting_started/#5-register-a-cluster-to-deploy-apps-to-optional","text":"This step registers a cluster's credentials to Argo CD, and is only necessary when deploying to an external cluster. When deploying internally (to the same cluster that Argo CD is running in), https://kubernetes.default.svc should be used as the application's K8s API server address. First list all clusters contexts in your current kubconfig: argocd cluster add Choose a context name from the list and supply it to argocd cluster add CONTEXTNAME . For example, for docker-for-desktop context, run: argocd cluster add docker-for-desktop The above command installs a ServiceAccount ( argocd-manager ), into the kube-system namespace of that kubectl context, and binds the service account to an admin-level ClusterRole. Argo CD uses this service account token to perform its management tasks (i.e. deploy/monitoring). Note The rules of the argocd-manager-role role can be modified such that it only has create , update , patch , delete privileges to a limited set of namespaces, groups, kinds. However get , list , watch privileges are required at the cluster-scope for Argo CD to function.","title":"5. Register A Cluster To Deploy Apps To (Optional)"},{"location":"getting_started/#6-create-an-application-from-a-git-repository","text":"An example repository containing a guestbook application is available at https://github.com/argoproj/argocd-example-apps.git to demonstrate how Argo CD works.","title":"6. Create An Application From A Git Repository"},{"location":"getting_started/#creating-apps-via-cli","text":"argocd app create guestbook \\ --repo https://github.com/argoproj/argocd-example-apps.git \\ --path guestbook \\ --dest-server https://kubernetes.default.svc \\ --dest-namespace default","title":"Creating Apps Via CLI"},{"location":"getting_started/#creating-apps-via-ui","text":"Open a browser to the Argo CD external UI, and login using the credentials, IP/hostname set in step 4. Connect the https://github.com/argoproj/argocd-example-apps.git repo to Argo CD: After connecting a repository, select the guestbook application for creation:","title":"Creating Apps Via UI"},{"location":"getting_started/#7-sync-deploy-the-application","text":"Once the guestbook application is created, you can now view its status: $ argocd app get guestbook Name: guestbook Server: https://kubernetes.default.svc Namespace: default URL: https://10.97.164.88/applications/guestbook Repo: https://github.com/argoproj/argocd-example-apps.git Target: Path: guestbook Sync Policy: none Sync Status: OutOfSync from ( 1ff8a67 ) Health Status: Missing GROUP KIND NAMESPACE NAME STATUS HEALTH apps Deployment default guestbook-ui OutOfSync Missing Service default guestbook-ui OutOfSync Missing The application status is initially OutOfSync state, since the application has yet to be deployed, and no Kubernetes resources have been created. To sync (deploy) the application, run: argocd app sync guestbook This command retrieves the manifests from the repository and performs a kubectl apply of the manifests. The guestbook app is now running and you can now view its resource components, logs, events, and assessed health status:","title":"7. Sync (Deploy) The Application"},{"location":"getting_started/#from-ui","text":"","title":"From UI:"},{"location":"understand_the_basics/","text":"Understand The Basics Before effectively using Argo CD, it is necessary to understand the underlying technology that the platform is built on. It is also necessary to understand the features being provided to you and how to use them. The section below provides some useful links to build up this understanding. Learn The Fundamentals Go through the online Docker and Kubernetes tutorials A Beginner-Friendly Introduction to Containers, VMs and Docker Introduction to Kubernetes Tutorials Hands on labs Depending on how you plan to template your applications: Kustomize Helm Ksonnet If you're integrating with Jenkins: Jenkins User Guide","title":"Understand The Basics"},{"location":"understand_the_basics/#understand-the-basics","text":"Before effectively using Argo CD, it is necessary to understand the underlying technology that the platform is built on. It is also necessary to understand the features being provided to you and how to use them. The section below provides some useful links to build up this understanding.","title":"Understand The Basics"},{"location":"understand_the_basics/#learn-the-fundamentals","text":"Go through the online Docker and Kubernetes tutorials A Beginner-Friendly Introduction to Containers, VMs and Docker Introduction to Kubernetes Tutorials Hands on labs Depending on how you plan to template your applications: Kustomize Helm Ksonnet If you're integrating with Jenkins: Jenkins User Guide","title":"Learn The Fundamentals"},{"location":"developer-guide/","text":"Overview You probably don't want to be reading this section of the docs. This part of the manual is aimed at people wanting to develop third-party applications that interact with Argo CD, e.g. An chat bot An Slack integration Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"developer-guide/#overview","text":"You probably don't want to be reading this section of the docs. This part of the manual is aimed at people wanting to develop third-party applications that interact with Argo CD, e.g. An chat bot An Slack integration Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"developer-guide/api-docs/","text":"API Docs You can find Swagger docs but setting the path /swagger-ui to your Argo CD UI's. E.g. http://localhost:8080/swagger-ui .","title":"API Docs"},{"location":"developer-guide/api-docs/#api-docs","text":"You can find Swagger docs but setting the path /swagger-ui to your Argo CD UI's. E.g. http://localhost:8080/swagger-ui .","title":"API Docs"},{"location":"developer-guide/ci/","text":"CI Troubleshooting Builds \"Check nothing has changed\" step fails If your PR fails the codegen CI step, you can either: (1) Simple - download the codgen.patch file from CircleCI and apply it: git apply codegen.patch git commit -am Applies codegen patch (2) Advanced - if you have the tools installed (see the contributing guide), run the following: make pre-commit git commit -am Ran pre-commit checks Updating The Builder Image Login to Docker Hub: docker login Build image: make builder-image IMAGE_NAMESPACE = argoproj IMAGE_TAG = v1.0.0 Public CD https://cd.apps.argoproj.io/","title":"CI"},{"location":"developer-guide/ci/#ci","text":"","title":"CI"},{"location":"developer-guide/ci/#troubleshooting-builds","text":"","title":"Troubleshooting Builds"},{"location":"developer-guide/ci/#check-nothing-has-changed-step-fails","text":"If your PR fails the codegen CI step, you can either: (1) Simple - download the codgen.patch file from CircleCI and apply it: git apply codegen.patch git commit -am Applies codegen patch (2) Advanced - if you have the tools installed (see the contributing guide), run the following: make pre-commit git commit -am Ran pre-commit checks","title":"\"Check nothing has changed\" step fails"},{"location":"developer-guide/ci/#updating-the-builder-image","text":"Login to Docker Hub: docker login Build image: make builder-image IMAGE_NAMESPACE = argoproj IMAGE_TAG = v1.0.0","title":"Updating The Builder Image"},{"location":"developer-guide/ci/#public-cd","text":"https://cd.apps.argoproj.io/","title":"Public CD"},{"location":"developer-guide/releasing/","text":"Releasing Make sure you are logged into Docker Hub: docker login Export the upstream repository and branch name, e.g.: REPO = upstream ; # or origin BRANCH = release-1.0 Set the VERSION environment variable: # release candidate VERSION = v1.0.0-rc1 # GA release VERSION = v1.0.2 Prior to v1.1, the UI is in a separate repo. If not already created, create UI release branch: cd argo-cd-ui git checkout -b $BRANCH Tag and release UI: git checkout $BRANCH git tag $VERSION git push $REPO $BRANCH --tags git clean -fd IMAGE_NAMESPACE = argoproj IMAGE_TAG = $VERSION DOCKER_PUSH = true yarn docker If not already created, create release branch: cd argo-cd git checkout -b $BRANCH git push $REPO $BRANCH Update VERSION and manifests with new version: git checkout $BRANCH echo ${ VERSION : 1 } VERSION make manifests IMAGE_TAG = $VERSION git commit -am Update manifests to $VERSION git push $REPO $BRANCH Tag, build, and push release to Docker Hub git tag $VERSION git clean -fd make release IMAGE_NAMESPACE = argoproj IMAGE_TAG = $VERSION DOCKER_PUSH = true git push $REPO $VERSION Update Github releases with: Getting started (copy from previous release) Changelog Binaries (e.g. dist/argocd-darwin-amd64 ). If GA, update stable tag: git tag stable --force git push $REPO stable --force If GA, update Brew formula: git clone https://github.com/argoproj/homebrew-tap cd homebrew-tap git checkout master git pull ./update.sh ~/go/src/github.com/argoproj/argo-cd/dist/argocd-darwin-amd64 git commit -am Update argocd to $VERSION git push Verify Locally: kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/ $VERSION /manifests/install.yaml Follow the Getting Started Guide . If GA: brew upgrade argocd /usr/local/bin/argocd version Sync Argo CD in https://cd.apps.argoproj.io/applications/argo-cd . Deploy the site .","title":"Releasing"},{"location":"developer-guide/releasing/#releasing","text":"Make sure you are logged into Docker Hub: docker login Export the upstream repository and branch name, e.g.: REPO = upstream ; # or origin BRANCH = release-1.0 Set the VERSION environment variable: # release candidate VERSION = v1.0.0-rc1 # GA release VERSION = v1.0.2 Prior to v1.1, the UI is in a separate repo. If not already created, create UI release branch: cd argo-cd-ui git checkout -b $BRANCH Tag and release UI: git checkout $BRANCH git tag $VERSION git push $REPO $BRANCH --tags git clean -fd IMAGE_NAMESPACE = argoproj IMAGE_TAG = $VERSION DOCKER_PUSH = true yarn docker If not already created, create release branch: cd argo-cd git checkout -b $BRANCH git push $REPO $BRANCH Update VERSION and manifests with new version: git checkout $BRANCH echo ${ VERSION : 1 } VERSION make manifests IMAGE_TAG = $VERSION git commit -am Update manifests to $VERSION git push $REPO $BRANCH Tag, build, and push release to Docker Hub git tag $VERSION git clean -fd make release IMAGE_NAMESPACE = argoproj IMAGE_TAG = $VERSION DOCKER_PUSH = true git push $REPO $VERSION Update Github releases with: Getting started (copy from previous release) Changelog Binaries (e.g. dist/argocd-darwin-amd64 ). If GA, update stable tag: git tag stable --force git push $REPO stable --force If GA, update Brew formula: git clone https://github.com/argoproj/homebrew-tap cd homebrew-tap git checkout master git pull ./update.sh ~/go/src/github.com/argoproj/argo-cd/dist/argocd-darwin-amd64 git commit -am Update argocd to $VERSION git push","title":"Releasing"},{"location":"developer-guide/releasing/#verify","text":"Locally: kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/ $VERSION /manifests/install.yaml Follow the Getting Started Guide . If GA: brew upgrade argocd /usr/local/bin/argocd version Sync Argo CD in https://cd.apps.argoproj.io/applications/argo-cd . Deploy the site .","title":"Verify"},{"location":"developer-guide/site/","text":"Site Developing And Testing The web site is build using mkdocs and mkdocs-material . To test: mkdocs serve Check for broken external links: find docs -name *.md -exec grep -l http {} + | xargs awesome_bot -t 3 --allow-dupe --allow-redirect -w argocd.example.com:443,argocd.example.com,kubernetes.default.svc:443,kubernetes.default.svc,mycluster.com,https://github.com/argoproj/my-private-repository,192.168.0.20,storage.googleapis.com,localhost:8080,localhost:6443,your-kubernetes-cluster-addr,10.97.164.88 --skip-save-results -- Deploying mkdocs gh-deploy Analytics Tip Don't forget to disable your ad-blocker when testing. We collect Google Analytics .","title":"Site"},{"location":"developer-guide/site/#site","text":"","title":"Site"},{"location":"developer-guide/site/#developing-and-testing","text":"The web site is build using mkdocs and mkdocs-material . To test: mkdocs serve Check for broken external links: find docs -name *.md -exec grep -l http {} + | xargs awesome_bot -t 3 --allow-dupe --allow-redirect -w argocd.example.com:443,argocd.example.com,kubernetes.default.svc:443,kubernetes.default.svc,mycluster.com,https://github.com/argoproj/my-private-repository,192.168.0.20,storage.googleapis.com,localhost:8080,localhost:6443,your-kubernetes-cluster-addr,10.97.164.88 --skip-save-results --","title":"Developing And Testing"},{"location":"developer-guide/site/#deploying","text":"mkdocs gh-deploy","title":"Deploying"},{"location":"developer-guide/site/#analytics","text":"Tip Don't forget to disable your ad-blocker when testing. We collect Google Analytics .","title":"Analytics"},{"location":"developer-guide/test-e2e/","text":"E2E Tests The directory contains E2E tests and test applications. The test assume that Argo CD services are installed into argocd-e2e namespace or cluster in current context. One throw-away namespace argocd-e2e*** is created prior to tests execute. The throw-away namespace is used as a target namespace for test applications. The test/e2e/testdata directory contains various Argo CD applications. Before test execution directory is copies into /tmp/argocd-e2e*** temp directory and used in tests as a Git repository via file url: file:///tmp/argocd-e2e*** . Running Tests Locally Start the e2e version make start-e2e Run the tests: make test-e2e You can observe the tests by using the UI http://localhost:8080/applications . Configuration of E2E Tests execution The Makefile's start-e2e target starts instances of ArgoCD on your local machine, of which the most will require a network listener. If for whatever reason you already have network services on your machine listening on the same ports, the e2e tests will not be able to run. You can derive from the defaults by setting the following environment variables before you run make start-e2e : ARGOCD_E2E_APISERVER_PORT : Listener port for argocd-server (default: 8080 ) ARGOCD_E2E_REPOSERVER_PORT : Listener port for argocd-reposerver (default: 8081 ) ARGOCD_E2E_DEX_PORT : Listener port for dex (default: 5556 ) ARGOCD_E2E_REDIS_PORT : Listener port for redis (default: 6379 ) ARGOCD_E2E_YARN_CMD : Command to use for starting the UI via Yarn (default: yarn ) If you have changed the port for argocd-server , be sure to also set ARGOCD_SERVER environment variable to point to that port, e.g. export ARGOCD_SERVER=localhost:8888 before running make test-e2e so that the test will communicate to the correct server component. CI Set-up The tests are executed by Argo Workflow defined at .argo-ci/ci.yaml . CI job The builds an Argo CD image, deploy argo cd components into throw-away kubernetes cluster provisioned using k3s and run e2e tests against it. Test Isolation Some effort has been made to balance test isolation with speed. Tests are isolated as follows as each test gets: A random 5 character ID. A unique Git repository containing the testdata in /tmp/argocd-e2e/${id} . A namespace argocd-e2e-ns-${id} . An primary name for the app argocd-e2e-${id} . Troubleshooting Tests fails to delete argocd-e2e-ns-* namespaces. This maybe due to the metrics server, run this: kubectl api-resources If it exits with status code 1, run: kubectl delete apiservice v1beta1.metrics.k8s.io Remove /spec/finalizers from the namespace kubectl edit ns argocd-e2e-ns-*","title":"E2E Tests"},{"location":"developer-guide/test-e2e/#e2e-tests","text":"The directory contains E2E tests and test applications. The test assume that Argo CD services are installed into argocd-e2e namespace or cluster in current context. One throw-away namespace argocd-e2e*** is created prior to tests execute. The throw-away namespace is used as a target namespace for test applications. The test/e2e/testdata directory contains various Argo CD applications. Before test execution directory is copies into /tmp/argocd-e2e*** temp directory and used in tests as a Git repository via file url: file:///tmp/argocd-e2e*** .","title":"E2E Tests"},{"location":"developer-guide/test-e2e/#running-tests-locally","text":"Start the e2e version make start-e2e Run the tests: make test-e2e You can observe the tests by using the UI http://localhost:8080/applications .","title":"Running Tests Locally"},{"location":"developer-guide/test-e2e/#configuration-of-e2e-tests-execution","text":"The Makefile's start-e2e target starts instances of ArgoCD on your local machine, of which the most will require a network listener. If for whatever reason you already have network services on your machine listening on the same ports, the e2e tests will not be able to run. You can derive from the defaults by setting the following environment variables before you run make start-e2e : ARGOCD_E2E_APISERVER_PORT : Listener port for argocd-server (default: 8080 ) ARGOCD_E2E_REPOSERVER_PORT : Listener port for argocd-reposerver (default: 8081 ) ARGOCD_E2E_DEX_PORT : Listener port for dex (default: 5556 ) ARGOCD_E2E_REDIS_PORT : Listener port for redis (default: 6379 ) ARGOCD_E2E_YARN_CMD : Command to use for starting the UI via Yarn (default: yarn ) If you have changed the port for argocd-server , be sure to also set ARGOCD_SERVER environment variable to point to that port, e.g. export ARGOCD_SERVER=localhost:8888 before running make test-e2e so that the test will communicate to the correct server component.","title":"Configuration of E2E Tests execution"},{"location":"developer-guide/test-e2e/#ci-set-up","text":"The tests are executed by Argo Workflow defined at .argo-ci/ci.yaml . CI job The builds an Argo CD image, deploy argo cd components into throw-away kubernetes cluster provisioned using k3s and run e2e tests against it.","title":"CI Set-up"},{"location":"developer-guide/test-e2e/#test-isolation","text":"Some effort has been made to balance test isolation with speed. Tests are isolated as follows as each test gets: A random 5 character ID. A unique Git repository containing the testdata in /tmp/argocd-e2e/${id} . A namespace argocd-e2e-ns-${id} . An primary name for the app argocd-e2e-${id} .","title":"Test Isolation"},{"location":"developer-guide/test-e2e/#troubleshooting","text":"Tests fails to delete argocd-e2e-ns-* namespaces. This maybe due to the metrics server, run this: kubectl api-resources If it exits with status code 1, run: kubectl delete apiservice v1beta1.metrics.k8s.io Remove /spec/finalizers from the namespace kubectl edit ns argocd-e2e-ns-*","title":"Troubleshooting"},{"location":"operator-manual/","text":"Overview This guide is for administrator and operator wanting to install and configure Argo CD for other developers. Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"operator-manual/#overview","text":"This guide is for administrator and operator wanting to install and configure Argo CD for other developers. Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"operator-manual/architecture/","text":"Architectural Overview Components API Server The API server is a gRPC/REST server which exposes the API consumed by the Web UI, CLI, and CI/CD systems. It has the following responsibilities: application management and status reporting invoking of application operations (e.g. sync, rollback, user-defined actions) repository and cluster credential management (stored as K8s secrets) authentication and auth delegation to external identity providers RBAC enforcement listener/forwarder for Git webhook events Repository Server The repository server is an internal service which maintains a local cache of the Git repository holding the application manifests. It is responsible for generating and returning the Kubernetes manifests when provided the following inputs: repository URL revision (commit, tag, branch) application path template specific settings: parameters, ksonnet environments, helm values.yaml Application Controller The application controller is a Kubernetes controller which continuously monitors running applications and compares the current, live state against the desired target state (as specified in the repo). It detects OutOfSync application state and optionally takes corrective action. It is responsible for invoking any user-defined hooks for lifcecycle events (PreSync, Sync, PostSync)","title":"Architectural Overview"},{"location":"operator-manual/architecture/#architectural-overview","text":"","title":"Architectural Overview"},{"location":"operator-manual/architecture/#components","text":"","title":"Components"},{"location":"operator-manual/architecture/#api-server","text":"The API server is a gRPC/REST server which exposes the API consumed by the Web UI, CLI, and CI/CD systems. It has the following responsibilities: application management and status reporting invoking of application operations (e.g. sync, rollback, user-defined actions) repository and cluster credential management (stored as K8s secrets) authentication and auth delegation to external identity providers RBAC enforcement listener/forwarder for Git webhook events","title":"API Server"},{"location":"operator-manual/architecture/#repository-server","text":"The repository server is an internal service which maintains a local cache of the Git repository holding the application manifests. It is responsible for generating and returning the Kubernetes manifests when provided the following inputs: repository URL revision (commit, tag, branch) application path template specific settings: parameters, ksonnet environments, helm values.yaml","title":"Repository Server"},{"location":"operator-manual/architecture/#application-controller","text":"The application controller is a Kubernetes controller which continuously monitors running applications and compares the current, live state against the desired target state (as specified in the repo). It detects OutOfSync application state and optionally takes corrective action. It is responsible for invoking any user-defined hooks for lifcecycle events (PreSync, Sync, PostSync)","title":"Application Controller"},{"location":"operator-manual/cluster-bootstrapping/","text":"Cluster Bootstrapping This guide for operators who have already installed Argo CD, and have a new cluster and are looking to install many applications in that cluster. There's no one particular pattern to solve this problem, e.g. you could write a script to create your applications, or you could even manually create them. However, users of Argo CD tend to use the application of applications pattern . Application Of Applications Pattern Declaratively specify one Argo CD application that consists only of other applications. Helm Example This example shows how to use Helm to achieve this. You can, of course, use another tool if you like. A typical layout of your Git repository for this might be: \u251c\u2500\u2500 Chart . yaml \u251c\u2500\u2500 templates \u2502 \u251c\u2500\u2500 guestbook . yaml \u2502 \u251c\u2500\u2500 helm - dependency . yaml \u2502 \u251c\u2500\u2500 helm - guestbook . yaml \u2502 \u2514\u2500\u2500 kustomize - guestbook . yaml \u2514\u2500\u2500 values . yaml Chart.yaml is boiler-plate. templates contains one file for each application, roughly: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : guestbook namespace : argocd finalizers : - resources-finalizer.argocd.argoproj.io spec : destination : namespace : argocd server : {{ .Values.spec.destination.server }} project : default source : path : guestbook repoURL : https://github.com/argoproj/argocd-example-apps targetRevision : {{ .Values.spec.source.targetRevision }} syncPolicy : automated : prune : true In this example, I've set the sync policy to automated + prune, so that applications are automatically created, synced, and deleted when the manifest is changed, but you may wish to disable this. I've also added the finalizer, which will ensure that you applications are deleted correctly. As you probably want to override the cluster server and maybe the revision, these are templated values. values.yaml contains the default values: spec : destination : server : https://kubernetes.default.svc source : targetRevision : HEAD Finally, you need to create your application, e.g.: argocd app create applications \\ --dest-namespace argocd \\ --dest-server https://kubernetes.default.svc \\ --repo https://github.com/argoproj/argocd-example-apps.git \\ --path applications \\ --sync-policy automated In this example, I excluded auto-prune, as this would result in all applications being deleted if some accidentally deleted the application of applications . View the example on Github .","title":"Cluster Bootstrapping"},{"location":"operator-manual/cluster-bootstrapping/#cluster-bootstrapping","text":"This guide for operators who have already installed Argo CD, and have a new cluster and are looking to install many applications in that cluster. There's no one particular pattern to solve this problem, e.g. you could write a script to create your applications, or you could even manually create them. However, users of Argo CD tend to use the application of applications pattern .","title":"Cluster Bootstrapping"},{"location":"operator-manual/cluster-bootstrapping/#application-of-applications-pattern","text":"Declaratively specify one Argo CD application that consists only of other applications.","title":"Application Of Applications Pattern"},{"location":"operator-manual/cluster-bootstrapping/#helm-example","text":"This example shows how to use Helm to achieve this. You can, of course, use another tool if you like. A typical layout of your Git repository for this might be: \u251c\u2500\u2500 Chart . yaml \u251c\u2500\u2500 templates \u2502 \u251c\u2500\u2500 guestbook . yaml \u2502 \u251c\u2500\u2500 helm - dependency . yaml \u2502 \u251c\u2500\u2500 helm - guestbook . yaml \u2502 \u2514\u2500\u2500 kustomize - guestbook . yaml \u2514\u2500\u2500 values . yaml Chart.yaml is boiler-plate. templates contains one file for each application, roughly: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : guestbook namespace : argocd finalizers : - resources-finalizer.argocd.argoproj.io spec : destination : namespace : argocd server : {{ .Values.spec.destination.server }} project : default source : path : guestbook repoURL : https://github.com/argoproj/argocd-example-apps targetRevision : {{ .Values.spec.source.targetRevision }} syncPolicy : automated : prune : true In this example, I've set the sync policy to automated + prune, so that applications are automatically created, synced, and deleted when the manifest is changed, but you may wish to disable this. I've also added the finalizer, which will ensure that you applications are deleted correctly. As you probably want to override the cluster server and maybe the revision, these are templated values. values.yaml contains the default values: spec : destination : server : https://kubernetes.default.svc source : targetRevision : HEAD Finally, you need to create your application, e.g.: argocd app create applications \\ --dest-namespace argocd \\ --dest-server https://kubernetes.default.svc \\ --repo https://github.com/argoproj/argocd-example-apps.git \\ --path applications \\ --sync-policy automated In this example, I excluded auto-prune, as this would result in all applications being deleted if some accidentally deleted the application of applications . View the example on Github .","title":"Helm Example"},{"location":"operator-manual/custom_tools/","text":"Custom Tooling Argo CD bundles preferred versions of its supported templating tools (helm, kustomize, ks, jsonnet) as part of its container images. Sometimes, it may be desired to use a specific version of a tool other than what Argo CD bundles. Some reasons to do this might be: To upgrade/downgrade to a specific version of a tool due to bugs or bug fixes. To install additional dependencies which to be used by kustomize's configmap/secret generators (e.g. curl, vault, gpg, AWS CLI) To install a config management plugin As the Argo CD repo-server is the single service responsible for generating Kubernetes manifests, it can be customized to use alternative toolchain required by your environment. Adding Tools Via Volume Mounts The first technique is to use an init container and a volumeMount to copy a different verison of a tool into the repo-server container. In the following example, an init container is overwriting the helm binary with a different version than what is bundled in Argo CD: spec : # 1. Define an emptyDir volume which will hold the custom binaries volumes : - name : custom-tools emptyDir : {} # 2. Use an init container to download/copy custom binaries into the emptyDir initContainers : - name : download-tools image : alpine:3.8 command : [ sh , -c ] args : - wget -qO- https://storage.googleapis.com/kubernetes-helm/helm-v2.12.3-linux-amd64.tar.gz | tar -xvzf - mv linux-amd64/helm /custom-tools/ volumeMounts : - mountPath : /custom-tools name : custom-tools # 3. Volume mount the custom binary to the bin directory (overriding the existing version) containers : - name : argocd-repo-server volumeMounts : - mountPath : /usr/local/bin/helm name : custom-tools subPath : helm BYOI (Build Your Own Image) Sometimes replacing a binary isn't sufficient and you need to install other dependencies. The following example builds an entirely customized repo-server from a Dockerfile, installing extra dependencies that may be needed for generating manifests. FROM argoproj/argocd:latest # Switch to root for the ability to perform install USER root # Install tools needed for your repo-server to retrieve decrypt secrets, render manifests # (e.g. curl, awscli, gpg, sops) RUN apt-get update \\ apt-get install -y \\ curl \\ awscli \\ gpg \\ apt-get clean \\ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \\ curl -o /usr/local/bin/sops -L https://github.com/mozilla/sops/releases/download/3.2.0/sops-3.2.0.linux \\ chmod +x /usr/local/bin/sops # Switch back to non-root user USER argocd","title":"Custom Tooling"},{"location":"operator-manual/custom_tools/#custom-tooling","text":"Argo CD bundles preferred versions of its supported templating tools (helm, kustomize, ks, jsonnet) as part of its container images. Sometimes, it may be desired to use a specific version of a tool other than what Argo CD bundles. Some reasons to do this might be: To upgrade/downgrade to a specific version of a tool due to bugs or bug fixes. To install additional dependencies which to be used by kustomize's configmap/secret generators (e.g. curl, vault, gpg, AWS CLI) To install a config management plugin As the Argo CD repo-server is the single service responsible for generating Kubernetes manifests, it can be customized to use alternative toolchain required by your environment.","title":"Custom Tooling"},{"location":"operator-manual/custom_tools/#adding-tools-via-volume-mounts","text":"The first technique is to use an init container and a volumeMount to copy a different verison of a tool into the repo-server container. In the following example, an init container is overwriting the helm binary with a different version than what is bundled in Argo CD: spec : # 1. Define an emptyDir volume which will hold the custom binaries volumes : - name : custom-tools emptyDir : {} # 2. Use an init container to download/copy custom binaries into the emptyDir initContainers : - name : download-tools image : alpine:3.8 command : [ sh , -c ] args : - wget -qO- https://storage.googleapis.com/kubernetes-helm/helm-v2.12.3-linux-amd64.tar.gz | tar -xvzf - mv linux-amd64/helm /custom-tools/ volumeMounts : - mountPath : /custom-tools name : custom-tools # 3. Volume mount the custom binary to the bin directory (overriding the existing version) containers : - name : argocd-repo-server volumeMounts : - mountPath : /usr/local/bin/helm name : custom-tools subPath : helm","title":"Adding Tools Via Volume Mounts"},{"location":"operator-manual/custom_tools/#byoi-build-your-own-image","text":"Sometimes replacing a binary isn't sufficient and you need to install other dependencies. The following example builds an entirely customized repo-server from a Dockerfile, installing extra dependencies that may be needed for generating manifests. FROM argoproj/argocd:latest # Switch to root for the ability to perform install USER root # Install tools needed for your repo-server to retrieve decrypt secrets, render manifests # (e.g. curl, awscli, gpg, sops) RUN apt-get update \\ apt-get install -y \\ curl \\ awscli \\ gpg \\ apt-get clean \\ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \\ curl -o /usr/local/bin/sops -L https://github.com/mozilla/sops/releases/download/3.2.0/sops-3.2.0.linux \\ chmod +x /usr/local/bin/sops # Switch back to non-root user USER argocd","title":"BYOI (Build Your Own Image)"},{"location":"operator-manual/declarative-setup/","text":"Declarative Setup Argo CD applications, projects and settings can be defined declaratively using Kubernetes manifests. Quick Reference Name Kind Description argocd-cm.yaml ConfigMap General Argo CD configuration argocd-secret.yaml Secret Password, Certificates, Signing Key argocd-rbac-cm.yaml ConfigMap RBAC Configuration argocd-tls-certs-cm.yaml ConfigMap Custom TLS certificates for connecting Git repositories via HTTPS (v1.2 and later) argocd-ssh-known-hosts-cm.yaml ConfigMap SSH known hosts data for connecting Git repositories via SSH (v1.2 and later) application.yaml Application Example application spec project.yaml AppProject Example project spec Applications The Application CRD is the Kubernetes resource object representing a deployed application instance in an environment. It is defined by two key pieces of information: source reference to the desired state in Git (repository, revision, path, environment) destination reference to the target cluster and namespace. A minimal Application spec is as follows: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : guestbook namespace : argocd spec : project : default source : repoURL : https://github.com/argoproj/argocd-example-apps.git targetRevision : HEAD path : guestbook destination : server : https://kubernetes.default.svc namespace : guestbook See application.yaml for additional fields Note The namespace must match the namespace of your Argo cd, typically this is argocd . Warning By default, deleting an application will not perform a cascade delete, thereby deleting its resources. You must add the finalizer if you want this behaviour - which you may well not want. metadata : finalizers : - resources-finalizer.argocd.argoproj.io Application of Applications You can create an application that creates other applications, which in turn can create other applications. This allows you to declaratively manage a group of applications that can be deployed and configured in concert. See cluster bootstrapping . Projects The AppProject CRD is the Kubernetes resource object representing a logical grouping of applications. It is defined by the following key pieces of information: sourceRepos reference to the repositories that applications within the project can pull manifests from. destinations reference to clusters and namespaces that applications within the project can deploy into. roles list of entities with definitions of their access to resources within the project. An example spec is as follows: apiVersion : argoproj.io/v1alpha1 kind : AppProject metadata : name : my-project namespace : argocd spec : description : Example Project # Allow manifests to deploy from any Git repos sourceRepos : - * # Only permit applications to deploy to the guestbook namespace in the same cluster destinations : - namespace : guestbook server : https://kubernetes.default.svc # Deny all cluster-scoped resources from being created, except for Namespace clusterResourceWhitelist : - group : kind : Namespace # Allow all namespaced-scoped resources to be created, except for ResourceQuota, LimitRange, NetworkPolicy namespaceResourceBlacklist : - group : kind : ResourceQuota - group : kind : LimitRange - group : kind : NetworkPolicy roles : # A role which provides read-only access to all applications in the project - name : read-only description : Read-only privileges to my-project policies : - p, proj:my-project:read-only, applications, get, my-project/*, allow groups : - my-oidc-group # A role which provides sync privileges to only the guestbook-dev application, e.g. to provide # sync privileges to a CI system - name : ci-role description : Sync privileges for guestbook-dev policies : - p, proj:my-project:ci-role, applications, sync, my-project/guestbook-dev, allow # NOTE: JWT tokens can only be generated by the API server and the token is not persisted # anywhere by Argo CD. It can be prematurely revoked by removing the entry from this list. jwtTokens : - iat : 1535390316 Repositories Repository credentials are stored in secret. Use following steps to configure a repo: Create secret which contains repository credentials. Consider using bitnami-labs/sealed-secrets to store encrypted secret definition as a Kubernetes manifest. Register repository in the argocd-cm config map. Each repository must have url field and, depending on whether you connect using HTTPS or SSH, usernameSecret and passwordSecret (for HTTPS) or sshPrivateKeySecret (for SSH). Example for HTTPS: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: https://github.com/argoproj/my-private-repository passwordSecret: name: my-secret key: password usernameSecret: name: my-secret key: username Example for SSH: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: git@github.com:argoproj/my-private-repository sshPrivateKeySecret: name: my-secret key: sshPrivateKey Tip The Kubernetes documentation has instructions for creating a secret containing a private key . Repository Credentials v1.1 If you want to use the same credentials for multiple repositories, you can use repository.credentials : apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: https://github.com/argoproj/private-repo - url: https://github.com/argoproj/other-private-repo repository.credentials : | - url: https://github.com/argoproj passwordSecret: name: my-secret key: password usernameSecret: name: my-secret key: username Argo CD will only use the credentials if you omit usernameSecret , passwordSecret , and sshPrivateKeySecret fields ( insecureIgnoreHostKey is ignored). A credential may be match if it's URL is the prefix of the repository's URL. The means that credentials may match, e.g in the above example both https://github.com/argoproj and https://github.com would match. Argo CD selects the first one that matches. Tip Order your credentials with the most specific at the top and the least specific at the bottom. A complete example. apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : repositories : | # this has it s own credentials - url: https://github.com/argoproj/private-repo passwordSecret: name: private-repo-secret key: password usernameSecret: name: private-repo-secret key: username sshPrivateKeySecret: name: private-repo-secret key: sshPrivateKey - url: https://github.com/argoproj/other-private-repo - url: https://github.com/otherproj/another-private-repo repository.credentials : | # this will be used for the second repo - url: https://github.com/argoproj passwordSecret: name: other-private-repo-secret key: password usernameSecret: name: other-private-repo-secret key: username sshPrivateKeySecret: name: other-private-repo-secret key: sshPrivateKey # this will be used for the third repo - url: https://github.com passwordSecret: name: another-private-repo-secret key: password usernameSecret: name: another-private-repo-secret key: username sshPrivateKeySecret: name: another-private-repo-secret key: sshPrivateKey Repositories using self-signed TLS certificates (or are signed by custom CA) v1.2 or later You can manage the TLS certificates used to verify the authenticity of your repository servers in a ConfigMap object named argocd-tls-certs-cm . The data section should contain a map, with the repository server's hostname part (not the complete URL) as key, and the certificate(s) in PEM format as data. So, if you connect to a repository with the URL https://server.example.com/repos/my-repo , you should use server.example.com as key. The certificate data should be either the server's certificate (in case of self-signed certificate) or the certificate of the CA that was used to sign the server's certificate. You can configure multiple certificates for each server, e.g. if you are having a certificate roll-over planned. If there are no dedicated certificates configured for a repository server, the system's default trust store is used for validating the server's repository. This should be good enough for most (if not all) public Git repository services such as GitLab, GitHub and Bitbucket as well as most privately hosted sites which use certificates from well-known CAs, including Let's Encrypt certificates. An example ConfigMap object: apiVersion : v1 kind : ConfigMap metadata : name : argocd-tls-certs-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : server.example.com : | -----BEGIN CERTIFICATE----- MIIF1zCCA7+gAwIBAgIUQdTcSHY2Sxd3Tq/v1eIEZPCNbOowDQYJKoZIhvcNAQEL BQAwezELMAkGA1UEBhMCREUxFTATBgNVBAgMDExvd2VyIFNheG9ueTEQMA4GA1UE BwwHSGFub3ZlcjEVMBMGA1UECgwMVGVzdGluZyBDb3JwMRIwEAYDVQQLDAlUZXN0 c3VpdGUxGDAWBgNVBAMMD2Jhci5leGFtcGxlLmNvbTAeFw0xOTA3MDgxMzU2MTda Fw0yMDA3MDcxMzU2MTdaMHsxCzAJBgNVBAYTAkRFMRUwEwYDVQQIDAxMb3dlciBT YXhvbnkxEDAOBgNVBAcMB0hhbm92ZXIxFTATBgNVBAoMDFRlc3RpbmcgQ29ycDES MBAGA1UECwwJVGVzdHN1aXRlMRgwFgYDVQQDDA9iYXIuZXhhbXBsZS5jb20wggIi MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCv4mHMdVUcafmaSHVpUM0zZWp5 NFXfboxA4inuOkE8kZlbGSe7wiG9WqLirdr39Ts+WSAFA6oANvbzlu3JrEQ2CHPc CNQm6diPREFwcDPFCe/eMawbwkQAPVSHPts0UoRxnpZox5pn69ghncBR+jtvx+/u P6HdwW0qqTvfJnfAF1hBJ4oIk2AXiip5kkIznsAh9W6WRy6nTVCeetmIepDOGe0G ZJIRn/OfSz7NzKylfDCat2z3EAutyeT/5oXZoWOmGg/8T7pn/pR588GoYYKRQnp+ YilqCPFX+az09EqqK/iHXnkdZ/Z2fCuU+9M/Zhrnlwlygl3RuVBI6xhm/ZsXtL2E Gxa61lNy6pyx5+hSxHEFEJshXLtioRd702VdLKxEOuYSXKeJDs1x9o6cJ75S6hko Ml1L4zCU+xEsMcvb1iQ2n7PZdacqhkFRUVVVmJ56th8aYyX7KNX6M9CD+kMpNm6J kKC1li/Iy+RI138bAvaFplajMF551kt44dSvIoJIbTr1LigudzWPqk31QaZXV/4u kD1n4p/XMc9HYU/was/CmQBFqmIZedTLTtK7clkuFN6wbwzdo1wmUNgnySQuMacO gxhHxxzRWxd24uLyk9Px+9U3BfVPaRLiOPaPoC58lyVOykjSgfpgbus7JS69fCq7 bEH4Jatp/10zkco+UQIDAQABo1MwUTAdBgNVHQ4EFgQUjXH6PHi92y4C4hQpey86 r6+x1ewwHwYDVR0jBBgwFoAUjXH6PHi92y4C4hQpey86r6+x1ewwDwYDVR0TAQH/ BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAgEAFE4SdKsX9UsLy+Z0xuHSxhTd0jfn Iih5mtzb8CDNO5oTw4z0aMeAvpsUvjJ/XjgxnkiRACXh7K9hsG2r+ageRWGevyvx CaRXFbherV1kTnZw4Y9/pgZTYVWs9jlqFOppz5sStkfjsDQ5lmPJGDii/StENAz2 XmtiPOgfG9Upb0GAJBCuKnrU9bIcT4L20gd2F4Y14ccyjlf8UiUi192IX6yM9OjT +TuXwZgqnTOq6piVgr+FTSa24qSvaXb5z/mJDLlk23npecTouLg83TNSn3R6fYQr d/Y9eXuUJ8U7/qTh2Ulz071AO9KzPOmleYPTx4Xty4xAtWi1QE5NHW9/Ajlv5OtO OnMNWIs7ssDJBsB7VFC8hcwf79jz7kC0xmQqDfw51Xhhk04kla+v+HZcFW2AO9so 6ZdVHHQnIbJa7yQJKZ+hK49IOoBR6JgdB5kymoplLLiuqZSYTcwSBZ72FYTm3iAr jzvt1hxpxVDmXvRnkhRrIRhK4QgJL0jRmirBjDY+PYYd7bdRIjN7WNZLFsgplnS8 9w6CwG32pRlm0c8kkiQ7FXA6BYCqOsDI8f1VGQv331OpR2Ck+FTv+L7DAmg6l37W +LB9LGh4OAp68ImTjqf6ioGKG0RBSznwME+r4nXtT1S/qLR6ASWUS4ViWRhbRlNK XWyb96wrUlv+E8I= -----END CERTIFICATE----- Note The argocd-tls-certs-cm ConfigMap will be mounted as a volume at the mount path /app/config/tls in the pods of argocd-server and argocd-repo-server . It will create files for each data key in the mount path directory, so above example would leave the file /app/config/tls/server.example.com , which contains the certificate data. It might take a while for changes in the ConfigMap to be reflected in your pods, depending on your Kubernetes configuration. SSH known host public keys If you are connecting repositories via SSH, ArgoCD will need to know the SSH known hosts public key of the repository servers. You can manage the SSH known hosts data in the ConfigMap named argocd-ssh-known-hosts-cm . This ConfigMap contains a single key/value pair, with ssh_known_hosts as the key and the actual public keys of the SSH servers as data. As opposed to TLS configuration, the public key(s) of each single repository server ArgoCD will connect via SSH must be configured, otherwise the connections to the repository will fail. There is no fallback. The data can be copied from any existing ssh_known_hosts file, or from the output of the ssh-keyscan utility. The basic format is servername keydata , one entry per line. An example ConfigMap object: apiVersion : v1 kind : ConfigMap metadata : name : argocd-ssh-known-hosts-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : ssh_known_hosts : | bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw== github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ== gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY= gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9 ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H Note The argocd-ssh-known-hosts-cm ConfigMap will be mounted as a volume at the mount path /app/config/ssh in the pods of argocd-server and argocd-repo-server . It will create a file ssh_known_hosts in that directory, which contains the SSH known hosts data used by ArgoCD for connecting to Git repositories via SSH. It might take a while for changes in the ConfigMap to be reflected in your pods, depending on your Kubernetes configuration. Clusters Cluster credentials are stored in secrets same as repository credentials but does not require entry in argocd-cm config map. Each secret must have label argocd.argoproj.io/secret-type: cluster . The secret data must include following fields: name - cluster name server - cluster api server url config - JSON representation of following data structure: # Basic authentication settings username : string password : string # Bearer authentication settings bearerToken : string # IAM authentication configuration awsAuthConfig : clusterName : string roleARN : string # Transport layer security configuration settings tlsClientConfig : # PEM-encoded bytes (typically read from a client certificate file). caData : string # PEM-encoded bytes (typically read from a client certificate file). certData : string # Server should be accessed without verifying the TLS certificate insecure : boolean # PEM-encoded bytes (typically read from a client certificate key file). keyData : string # ServerName is passed to the server for SNI and is used in the client to check server # ceritificates against. If ServerName is empty, the hostname used to contact the # server is used. serverName : string Cluster secret example: apiVersion : v1 kind : Secret metadata : name : mycluster-secret labels : argocd.argoproj.io/secret-type : cluster type : Opaque stringData : name : mycluster.com server : https://mycluster.com config : | { bearerToken : authentication token , tlsClientConfig : { insecure : false, caData : base64 encoded certificate } } Helm Chart Repositories Non standard Helm Chart repositories have to be registered under the helm.repositories key in the argocd-cm ConfigMap. Each repository must have url and name fields. For private Helm repos you may need to configure access credentials and HTTPS settings using usernameSecret , passwordSecret , caSecret , certSecret and keySecret fields. Example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : helm.repositories : | - url: https://storage.googleapis.com/istio-prerelease/daily-build/master-latest-daily/charts name: istio.io - url: https://argoproj.github.io/argo-helm name: argo usernameSecret: name: my-secret key: username passwordSecret: name: my-secret key: password caSecret: name: my-secret key: ca certSecret: name: my-secret key: cert keySecret: name: my-secret key: key Resource Exclusion Resources can be excluded from discovery and sync so that ArgoCD is unaware of them. For example, events.k8s.io and metrics.k8s.io are always excluded. Use cases: You have temporal issues and you want to exclude problematic resources. There are many of a kind of resources that impacts ArgoCD's performance. Restrict ArgoCD's access to certain kinds of resources, e.g. secrets. See security.md#cluster-rbac . To configure this, edit the argcd-cm config map: kubectl edit configmap argocd - cm - n argocdconfigmap / argocd - cm edited Add resource.exclusions , e.g.: apiVersion : v1 data : resource.exclusions : | - apiGroups: - * kinds: - * clusters: - https://192.168.0.20 kind : ConfigMap The resource.exclusions node is a list of objects. Each object can have: apiGroups A list of globs to match the API group. kinds A list of kinds to match. Can be \"*\" to match all. cluster A list of globs to match the cluster. If all three match, then the resource is ignored. Notes: Quote globs in your YAML to avoid parsing errors. Invalid globs result in the whole rule being ignored. If you add a rule that matches existing resources, these will appear in the interface as OutOfSync . SSO RBAC SSO configuration details: SSO RBAC configuration details: RBAC Manage Argo CD Using Argo CD Argo CD is able to manage itself since all settings are represented by Kubernetes manifests. The suggested way is to create Kustomize based application which uses base Argo CD manifests from [https://github.com/argoproj/argo-cd] and apply required changes on top. Example of kustomization.yaml : bases : - github.com/argoproj/argo-cd//manifests/cluster-install?ref=v1.0.1 # additional resources like ingress rules, cluster and repository secrets. resources : - clusters-secrets.yaml - repos-secrets.yaml # changes to config maps patchesStrategicMerge : - overlays/argo-cd-cm.yaml The live example of self managed Argo CD config is available at https://cd.apps.argoproj.io and with configuration stored at argoproj/argoproj-deployments . Note You will need to sign-in using your github account to get access to https://cd.apps.argoproj.io","title":"Declarative Setup"},{"location":"operator-manual/declarative-setup/#declarative-setup","text":"Argo CD applications, projects and settings can be defined declaratively using Kubernetes manifests.","title":"Declarative Setup"},{"location":"operator-manual/declarative-setup/#quick-reference","text":"Name Kind Description argocd-cm.yaml ConfigMap General Argo CD configuration argocd-secret.yaml Secret Password, Certificates, Signing Key argocd-rbac-cm.yaml ConfigMap RBAC Configuration argocd-tls-certs-cm.yaml ConfigMap Custom TLS certificates for connecting Git repositories via HTTPS (v1.2 and later) argocd-ssh-known-hosts-cm.yaml ConfigMap SSH known hosts data for connecting Git repositories via SSH (v1.2 and later) application.yaml Application Example application spec project.yaml AppProject Example project spec","title":"Quick Reference"},{"location":"operator-manual/declarative-setup/#applications","text":"The Application CRD is the Kubernetes resource object representing a deployed application instance in an environment. It is defined by two key pieces of information: source reference to the desired state in Git (repository, revision, path, environment) destination reference to the target cluster and namespace. A minimal Application spec is as follows: apiVersion : argoproj.io/v1alpha1 kind : Application metadata : name : guestbook namespace : argocd spec : project : default source : repoURL : https://github.com/argoproj/argocd-example-apps.git targetRevision : HEAD path : guestbook destination : server : https://kubernetes.default.svc namespace : guestbook See application.yaml for additional fields Note The namespace must match the namespace of your Argo cd, typically this is argocd . Warning By default, deleting an application will not perform a cascade delete, thereby deleting its resources. You must add the finalizer if you want this behaviour - which you may well not want. metadata : finalizers : - resources-finalizer.argocd.argoproj.io","title":"Applications"},{"location":"operator-manual/declarative-setup/#application-of-applications","text":"You can create an application that creates other applications, which in turn can create other applications. This allows you to declaratively manage a group of applications that can be deployed and configured in concert. See cluster bootstrapping .","title":"Application of Applications"},{"location":"operator-manual/declarative-setup/#projects","text":"The AppProject CRD is the Kubernetes resource object representing a logical grouping of applications. It is defined by the following key pieces of information: sourceRepos reference to the repositories that applications within the project can pull manifests from. destinations reference to clusters and namespaces that applications within the project can deploy into. roles list of entities with definitions of their access to resources within the project. An example spec is as follows: apiVersion : argoproj.io/v1alpha1 kind : AppProject metadata : name : my-project namespace : argocd spec : description : Example Project # Allow manifests to deploy from any Git repos sourceRepos : - * # Only permit applications to deploy to the guestbook namespace in the same cluster destinations : - namespace : guestbook server : https://kubernetes.default.svc # Deny all cluster-scoped resources from being created, except for Namespace clusterResourceWhitelist : - group : kind : Namespace # Allow all namespaced-scoped resources to be created, except for ResourceQuota, LimitRange, NetworkPolicy namespaceResourceBlacklist : - group : kind : ResourceQuota - group : kind : LimitRange - group : kind : NetworkPolicy roles : # A role which provides read-only access to all applications in the project - name : read-only description : Read-only privileges to my-project policies : - p, proj:my-project:read-only, applications, get, my-project/*, allow groups : - my-oidc-group # A role which provides sync privileges to only the guestbook-dev application, e.g. to provide # sync privileges to a CI system - name : ci-role description : Sync privileges for guestbook-dev policies : - p, proj:my-project:ci-role, applications, sync, my-project/guestbook-dev, allow # NOTE: JWT tokens can only be generated by the API server and the token is not persisted # anywhere by Argo CD. It can be prematurely revoked by removing the entry from this list. jwtTokens : - iat : 1535390316","title":"Projects"},{"location":"operator-manual/declarative-setup/#repositories","text":"Repository credentials are stored in secret. Use following steps to configure a repo: Create secret which contains repository credentials. Consider using bitnami-labs/sealed-secrets to store encrypted secret definition as a Kubernetes manifest. Register repository in the argocd-cm config map. Each repository must have url field and, depending on whether you connect using HTTPS or SSH, usernameSecret and passwordSecret (for HTTPS) or sshPrivateKeySecret (for SSH). Example for HTTPS: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: https://github.com/argoproj/my-private-repository passwordSecret: name: my-secret key: password usernameSecret: name: my-secret key: username Example for SSH: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: git@github.com:argoproj/my-private-repository sshPrivateKeySecret: name: my-secret key: sshPrivateKey Tip The Kubernetes documentation has instructions for creating a secret containing a private key .","title":"Repositories"},{"location":"operator-manual/declarative-setup/#repository-credentials","text":"v1.1 If you want to use the same credentials for multiple repositories, you can use repository.credentials : apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : repositories : | - url: https://github.com/argoproj/private-repo - url: https://github.com/argoproj/other-private-repo repository.credentials : | - url: https://github.com/argoproj passwordSecret: name: my-secret key: password usernameSecret: name: my-secret key: username Argo CD will only use the credentials if you omit usernameSecret , passwordSecret , and sshPrivateKeySecret fields ( insecureIgnoreHostKey is ignored). A credential may be match if it's URL is the prefix of the repository's URL. The means that credentials may match, e.g in the above example both https://github.com/argoproj and https://github.com would match. Argo CD selects the first one that matches. Tip Order your credentials with the most specific at the top and the least specific at the bottom. A complete example. apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : repositories : | # this has it s own credentials - url: https://github.com/argoproj/private-repo passwordSecret: name: private-repo-secret key: password usernameSecret: name: private-repo-secret key: username sshPrivateKeySecret: name: private-repo-secret key: sshPrivateKey - url: https://github.com/argoproj/other-private-repo - url: https://github.com/otherproj/another-private-repo repository.credentials : | # this will be used for the second repo - url: https://github.com/argoproj passwordSecret: name: other-private-repo-secret key: password usernameSecret: name: other-private-repo-secret key: username sshPrivateKeySecret: name: other-private-repo-secret key: sshPrivateKey # this will be used for the third repo - url: https://github.com passwordSecret: name: another-private-repo-secret key: password usernameSecret: name: another-private-repo-secret key: username sshPrivateKeySecret: name: another-private-repo-secret key: sshPrivateKey","title":"Repository Credentials"},{"location":"operator-manual/declarative-setup/#repositories-using-self-signed-tls-certificates-or-are-signed-by-custom-ca","text":"v1.2 or later You can manage the TLS certificates used to verify the authenticity of your repository servers in a ConfigMap object named argocd-tls-certs-cm . The data section should contain a map, with the repository server's hostname part (not the complete URL) as key, and the certificate(s) in PEM format as data. So, if you connect to a repository with the URL https://server.example.com/repos/my-repo , you should use server.example.com as key. The certificate data should be either the server's certificate (in case of self-signed certificate) or the certificate of the CA that was used to sign the server's certificate. You can configure multiple certificates for each server, e.g. if you are having a certificate roll-over planned. If there are no dedicated certificates configured for a repository server, the system's default trust store is used for validating the server's repository. This should be good enough for most (if not all) public Git repository services such as GitLab, GitHub and Bitbucket as well as most privately hosted sites which use certificates from well-known CAs, including Let's Encrypt certificates. An example ConfigMap object: apiVersion : v1 kind : ConfigMap metadata : name : argocd-tls-certs-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : server.example.com : | -----BEGIN CERTIFICATE----- MIIF1zCCA7+gAwIBAgIUQdTcSHY2Sxd3Tq/v1eIEZPCNbOowDQYJKoZIhvcNAQEL BQAwezELMAkGA1UEBhMCREUxFTATBgNVBAgMDExvd2VyIFNheG9ueTEQMA4GA1UE BwwHSGFub3ZlcjEVMBMGA1UECgwMVGVzdGluZyBDb3JwMRIwEAYDVQQLDAlUZXN0 c3VpdGUxGDAWBgNVBAMMD2Jhci5leGFtcGxlLmNvbTAeFw0xOTA3MDgxMzU2MTda Fw0yMDA3MDcxMzU2MTdaMHsxCzAJBgNVBAYTAkRFMRUwEwYDVQQIDAxMb3dlciBT YXhvbnkxEDAOBgNVBAcMB0hhbm92ZXIxFTATBgNVBAoMDFRlc3RpbmcgQ29ycDES MBAGA1UECwwJVGVzdHN1aXRlMRgwFgYDVQQDDA9iYXIuZXhhbXBsZS5jb20wggIi MA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoICAQCv4mHMdVUcafmaSHVpUM0zZWp5 NFXfboxA4inuOkE8kZlbGSe7wiG9WqLirdr39Ts+WSAFA6oANvbzlu3JrEQ2CHPc CNQm6diPREFwcDPFCe/eMawbwkQAPVSHPts0UoRxnpZox5pn69ghncBR+jtvx+/u P6HdwW0qqTvfJnfAF1hBJ4oIk2AXiip5kkIznsAh9W6WRy6nTVCeetmIepDOGe0G ZJIRn/OfSz7NzKylfDCat2z3EAutyeT/5oXZoWOmGg/8T7pn/pR588GoYYKRQnp+ YilqCPFX+az09EqqK/iHXnkdZ/Z2fCuU+9M/Zhrnlwlygl3RuVBI6xhm/ZsXtL2E Gxa61lNy6pyx5+hSxHEFEJshXLtioRd702VdLKxEOuYSXKeJDs1x9o6cJ75S6hko Ml1L4zCU+xEsMcvb1iQ2n7PZdacqhkFRUVVVmJ56th8aYyX7KNX6M9CD+kMpNm6J kKC1li/Iy+RI138bAvaFplajMF551kt44dSvIoJIbTr1LigudzWPqk31QaZXV/4u kD1n4p/XMc9HYU/was/CmQBFqmIZedTLTtK7clkuFN6wbwzdo1wmUNgnySQuMacO gxhHxxzRWxd24uLyk9Px+9U3BfVPaRLiOPaPoC58lyVOykjSgfpgbus7JS69fCq7 bEH4Jatp/10zkco+UQIDAQABo1MwUTAdBgNVHQ4EFgQUjXH6PHi92y4C4hQpey86 r6+x1ewwHwYDVR0jBBgwFoAUjXH6PHi92y4C4hQpey86r6+x1ewwDwYDVR0TAQH/ BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAgEAFE4SdKsX9UsLy+Z0xuHSxhTd0jfn Iih5mtzb8CDNO5oTw4z0aMeAvpsUvjJ/XjgxnkiRACXh7K9hsG2r+ageRWGevyvx CaRXFbherV1kTnZw4Y9/pgZTYVWs9jlqFOppz5sStkfjsDQ5lmPJGDii/StENAz2 XmtiPOgfG9Upb0GAJBCuKnrU9bIcT4L20gd2F4Y14ccyjlf8UiUi192IX6yM9OjT +TuXwZgqnTOq6piVgr+FTSa24qSvaXb5z/mJDLlk23npecTouLg83TNSn3R6fYQr d/Y9eXuUJ8U7/qTh2Ulz071AO9KzPOmleYPTx4Xty4xAtWi1QE5NHW9/Ajlv5OtO OnMNWIs7ssDJBsB7VFC8hcwf79jz7kC0xmQqDfw51Xhhk04kla+v+HZcFW2AO9so 6ZdVHHQnIbJa7yQJKZ+hK49IOoBR6JgdB5kymoplLLiuqZSYTcwSBZ72FYTm3iAr jzvt1hxpxVDmXvRnkhRrIRhK4QgJL0jRmirBjDY+PYYd7bdRIjN7WNZLFsgplnS8 9w6CwG32pRlm0c8kkiQ7FXA6BYCqOsDI8f1VGQv331OpR2Ck+FTv+L7DAmg6l37W +LB9LGh4OAp68ImTjqf6ioGKG0RBSznwME+r4nXtT1S/qLR6ASWUS4ViWRhbRlNK XWyb96wrUlv+E8I= -----END CERTIFICATE----- Note The argocd-tls-certs-cm ConfigMap will be mounted as a volume at the mount path /app/config/tls in the pods of argocd-server and argocd-repo-server . It will create files for each data key in the mount path directory, so above example would leave the file /app/config/tls/server.example.com , which contains the certificate data. It might take a while for changes in the ConfigMap to be reflected in your pods, depending on your Kubernetes configuration.","title":"Repositories using self-signed TLS certificates (or are signed by custom CA)"},{"location":"operator-manual/declarative-setup/#ssh-known-host-public-keys","text":"If you are connecting repositories via SSH, ArgoCD will need to know the SSH known hosts public key of the repository servers. You can manage the SSH known hosts data in the ConfigMap named argocd-ssh-known-hosts-cm . This ConfigMap contains a single key/value pair, with ssh_known_hosts as the key and the actual public keys of the SSH servers as data. As opposed to TLS configuration, the public key(s) of each single repository server ArgoCD will connect via SSH must be configured, otherwise the connections to the repository will fail. There is no fallback. The data can be copied from any existing ssh_known_hosts file, or from the output of the ssh-keyscan utility. The basic format is servername keydata , one entry per line. An example ConfigMap object: apiVersion : v1 kind : ConfigMap metadata : name : argocd-ssh-known-hosts-cm namespace : argocd labels : app.kubernetes.io/name : argocd-cm app.kubernetes.io/part-of : argocd data : ssh_known_hosts : | bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw== github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ== gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY= gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9 ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H Note The argocd-ssh-known-hosts-cm ConfigMap will be mounted as a volume at the mount path /app/config/ssh in the pods of argocd-server and argocd-repo-server . It will create a file ssh_known_hosts in that directory, which contains the SSH known hosts data used by ArgoCD for connecting to Git repositories via SSH. It might take a while for changes in the ConfigMap to be reflected in your pods, depending on your Kubernetes configuration.","title":"SSH known host public keys"},{"location":"operator-manual/declarative-setup/#clusters","text":"Cluster credentials are stored in secrets same as repository credentials but does not require entry in argocd-cm config map. Each secret must have label argocd.argoproj.io/secret-type: cluster . The secret data must include following fields: name - cluster name server - cluster api server url config - JSON representation of following data structure: # Basic authentication settings username : string password : string # Bearer authentication settings bearerToken : string # IAM authentication configuration awsAuthConfig : clusterName : string roleARN : string # Transport layer security configuration settings tlsClientConfig : # PEM-encoded bytes (typically read from a client certificate file). caData : string # PEM-encoded bytes (typically read from a client certificate file). certData : string # Server should be accessed without verifying the TLS certificate insecure : boolean # PEM-encoded bytes (typically read from a client certificate key file). keyData : string # ServerName is passed to the server for SNI and is used in the client to check server # ceritificates against. If ServerName is empty, the hostname used to contact the # server is used. serverName : string Cluster secret example: apiVersion : v1 kind : Secret metadata : name : mycluster-secret labels : argocd.argoproj.io/secret-type : cluster type : Opaque stringData : name : mycluster.com server : https://mycluster.com config : | { bearerToken : authentication token , tlsClientConfig : { insecure : false, caData : base64 encoded certificate } }","title":"Clusters"},{"location":"operator-manual/declarative-setup/#helm-chart-repositories","text":"Non standard Helm Chart repositories have to be registered under the helm.repositories key in the argocd-cm ConfigMap. Each repository must have url and name fields. For private Helm repos you may need to configure access credentials and HTTPS settings using usernameSecret , passwordSecret , caSecret , certSecret and keySecret fields. Example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-cm namespace : argocd data : helm.repositories : | - url: https://storage.googleapis.com/istio-prerelease/daily-build/master-latest-daily/charts name: istio.io - url: https://argoproj.github.io/argo-helm name: argo usernameSecret: name: my-secret key: username passwordSecret: name: my-secret key: password caSecret: name: my-secret key: ca certSecret: name: my-secret key: cert keySecret: name: my-secret key: key","title":"Helm Chart Repositories"},{"location":"operator-manual/declarative-setup/#resource-exclusion","text":"Resources can be excluded from discovery and sync so that ArgoCD is unaware of them. For example, events.k8s.io and metrics.k8s.io are always excluded. Use cases: You have temporal issues and you want to exclude problematic resources. There are many of a kind of resources that impacts ArgoCD's performance. Restrict ArgoCD's access to certain kinds of resources, e.g. secrets. See security.md#cluster-rbac . To configure this, edit the argcd-cm config map: kubectl edit configmap argocd - cm - n argocdconfigmap / argocd - cm edited Add resource.exclusions , e.g.: apiVersion : v1 data : resource.exclusions : | - apiGroups: - * kinds: - * clusters: - https://192.168.0.20 kind : ConfigMap The resource.exclusions node is a list of objects. Each object can have: apiGroups A list of globs to match the API group. kinds A list of kinds to match. Can be \"*\" to match all. cluster A list of globs to match the cluster. If all three match, then the resource is ignored. Notes: Quote globs in your YAML to avoid parsing errors. Invalid globs result in the whole rule being ignored. If you add a rule that matches existing resources, these will appear in the interface as OutOfSync .","title":"Resource Exclusion"},{"location":"operator-manual/declarative-setup/#sso-rbac","text":"SSO configuration details: SSO RBAC configuration details: RBAC","title":"SSO &amp; RBAC"},{"location":"operator-manual/declarative-setup/#manage-argo-cd-using-argo-cd","text":"Argo CD is able to manage itself since all settings are represented by Kubernetes manifests. The suggested way is to create Kustomize based application which uses base Argo CD manifests from [https://github.com/argoproj/argo-cd] and apply required changes on top. Example of kustomization.yaml : bases : - github.com/argoproj/argo-cd//manifests/cluster-install?ref=v1.0.1 # additional resources like ingress rules, cluster and repository secrets. resources : - clusters-secrets.yaml - repos-secrets.yaml # changes to config maps patchesStrategicMerge : - overlays/argo-cd-cm.yaml The live example of self managed Argo CD config is available at https://cd.apps.argoproj.io and with configuration stored at argoproj/argoproj-deployments . Note You will need to sign-in using your github account to get access to https://cd.apps.argoproj.io","title":"Manage Argo CD Using Argo CD"},{"location":"operator-manual/disaster_recovery/","text":"Disaster Recovery You can use argocd-util can be used to import and export all Argo CD data. Make sure you have ~/.kube/config pointing to your Argo CD cluster. Figure out what version of Argo CD you're running: argocd version | grep server # ... export VERSION = v1.0.1 Export to a backup: docker run -v ~/.kube:/home/argocd/.kube --rm argoproj/argocd: $VERSION argocd-util export backup.yaml Import from a backup: docker run -v ~/.kube:/home/argocd/.kube --rm argoproj/argocd: $VERSION argocd-util import - backup.yaml","title":"Disaster Recovery"},{"location":"operator-manual/disaster_recovery/#disaster-recovery","text":"You can use argocd-util can be used to import and export all Argo CD data. Make sure you have ~/.kube/config pointing to your Argo CD cluster. Figure out what version of Argo CD you're running: argocd version | grep server # ... export VERSION = v1.0.1 Export to a backup: docker run -v ~/.kube:/home/argocd/.kube --rm argoproj/argocd: $VERSION argocd-util export backup.yaml Import from a backup: docker run -v ~/.kube:/home/argocd/.kube --rm argoproj/argocd: $VERSION argocd-util import - backup.yaml","title":"Disaster Recovery"},{"location":"operator-manual/health/","text":"Resource Health Overview Argo CD provides built-in health assessment for several standard Kubernetes types, which is then surfaced to the overall Application health status as a whole. The following checks are made for specific types of kuberentes resources: Deployment, ReplicaSet, StatefulSet DaemonSet Observed generation is equal to desired generation. Number of updated replicas equals the number of desired replicas. Service If service type is of type LoadBalancer , the status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP . Ingress The status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP . PersistentVolumeClaim The status.phase is Bound Custom Health Checks Argo CD supports custom health checks written in Lua . This is useful if you: Are affected by known issues where your Ingress or StatefulSet resources are stuck in Progressing state because of bug in your resource controller. Have a custom resource for which Argo CD does not have a built-in health check. There are two ways to configure a custom health check. The next two sections describe those ways. Way 1. Define a Custom Health Check in argocd-cm ConfigMap Custom health checks can be defined in resource.customizations field of argocd-cm . Following example demonstrates a health check for certmanager.k8s.io/Certificate . data : resource.customizations : | certmanager.k8s.io/Certificate: health.lua: | hs = {} if obj.status ~= nil then if obj.status.conditions ~= nil then for i, condition in ipairs(obj.status.conditions) do if condition.type == Ready and condition.status == False then hs.status = Degraded hs.message = condition.message return hs end if condition.type == Ready and condition.status == True then hs.status = Healthy hs.message = condition.message return hs end end end end hs.status = Progressing hs.message = Waiting for certificate return hs The obj is a global variable which contains the resource. The script must return an object with status and optional message field. NOTE: as a security measure you don't have access to most of the standard Lua libraries. Way 2. Contribute a Custom Health Check A health check can be bundled into Argo CD. Custom health check scripts are located in the resource_customizations directory of https://github.com/argoproj/argo-cd . This must have the following directory structure: argo - cd | -- resource_customizations | | -- your.crd.group.io # CRD group | | | -- MyKind # Resource kind | | | | -- health.lua # Health check | | | | -- health_test.yaml # Test inputs and expected results | | | + -- testdata # Directory with test resource YAML definitions Each health check must have tests defined in health_test.yaml file. The health_test.yaml is a YAML file with the following structure: tests : - healthStatus : status : ExpectedStatus message : Expected message inputPath : testdata/test-resource-definition.yaml The PR#1139 is an example of Cert Manager CRDs custom health check.","title":"Resource Health"},{"location":"operator-manual/health/#resource-health","text":"","title":"Resource Health"},{"location":"operator-manual/health/#overview","text":"Argo CD provides built-in health assessment for several standard Kubernetes types, which is then surfaced to the overall Application health status as a whole. The following checks are made for specific types of kuberentes resources:","title":"Overview"},{"location":"operator-manual/health/#deployment-replicaset-statefulset-daemonset","text":"Observed generation is equal to desired generation. Number of updated replicas equals the number of desired replicas.","title":"Deployment, ReplicaSet, StatefulSet DaemonSet"},{"location":"operator-manual/health/#service","text":"If service type is of type LoadBalancer , the status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP .","title":"Service"},{"location":"operator-manual/health/#ingress","text":"The status.loadBalancer.ingress list is non-empty, with at least one value for hostname or IP .","title":"Ingress"},{"location":"operator-manual/health/#persistentvolumeclaim","text":"The status.phase is Bound","title":"PersistentVolumeClaim"},{"location":"operator-manual/health/#custom-health-checks","text":"Argo CD supports custom health checks written in Lua . This is useful if you: Are affected by known issues where your Ingress or StatefulSet resources are stuck in Progressing state because of bug in your resource controller. Have a custom resource for which Argo CD does not have a built-in health check. There are two ways to configure a custom health check. The next two sections describe those ways.","title":"Custom Health Checks"},{"location":"operator-manual/health/#way-1-define-a-custom-health-check-in-argocd-cm-configmap","text":"Custom health checks can be defined in resource.customizations field of argocd-cm . Following example demonstrates a health check for certmanager.k8s.io/Certificate . data : resource.customizations : | certmanager.k8s.io/Certificate: health.lua: | hs = {} if obj.status ~= nil then if obj.status.conditions ~= nil then for i, condition in ipairs(obj.status.conditions) do if condition.type == Ready and condition.status == False then hs.status = Degraded hs.message = condition.message return hs end if condition.type == Ready and condition.status == True then hs.status = Healthy hs.message = condition.message return hs end end end end hs.status = Progressing hs.message = Waiting for certificate return hs The obj is a global variable which contains the resource. The script must return an object with status and optional message field. NOTE: as a security measure you don't have access to most of the standard Lua libraries.","title":"Way 1. Define a Custom Health Check in argocd-cm ConfigMap"},{"location":"operator-manual/health/#way-2-contribute-a-custom-health-check","text":"A health check can be bundled into Argo CD. Custom health check scripts are located in the resource_customizations directory of https://github.com/argoproj/argo-cd . This must have the following directory structure: argo - cd | -- resource_customizations | | -- your.crd.group.io # CRD group | | | -- MyKind # Resource kind | | | | -- health.lua # Health check | | | | -- health_test.yaml # Test inputs and expected results | | | + -- testdata # Directory with test resource YAML definitions Each health check must have tests defined in health_test.yaml file. The health_test.yaml is a YAML file with the following structure: tests : - healthStatus : status : ExpectedStatus message : Expected message inputPath : testdata/test-resource-definition.yaml The PR#1139 is an example of Cert Manager CRDs custom health check.","title":"Way 2. Contribute a Custom Health Check"},{"location":"operator-manual/high_availability/","text":"High Availability Argo CD is largely stateless, all data is persisted as Kubernetes objects, which in turn is stored in Kubernetes' etcd. Redis is only used as a throw-away cache and can be lost. When lost, it will be rebuilt without loss of service. A set HA of manifests are provided for users who wish to run Argo CD in a highly available manner. This runs more containers, and run Redis in HA mode. Manifests \u29c9 Note The HA installation will require at least three different nodes due to pod anti-affinity roles in the specs. Scaling Up You might scale up some Argo CD services in the following circumstances: The argocd-repo-server can scale up when there is too much contention on a single git repo (e.g. many apps defined in a single git repo). The argocd-server can scale up to support more front-end load. All other services should run with their pre-determined number of replicas. The argocd-application-controller must not be increased because multiple controllers will fight. The argocd-dex-server uses an in-memory database, and two or more instances would have inconsistent data. argocd-redis is pre-configured with the understanding of only three total redis servers/sentinels.","title":"High Availability"},{"location":"operator-manual/high_availability/#high-availability","text":"Argo CD is largely stateless, all data is persisted as Kubernetes objects, which in turn is stored in Kubernetes' etcd. Redis is only used as a throw-away cache and can be lost. When lost, it will be rebuilt without loss of service. A set HA of manifests are provided for users who wish to run Argo CD in a highly available manner. This runs more containers, and run Redis in HA mode. Manifests \u29c9 Note The HA installation will require at least three different nodes due to pod anti-affinity roles in the specs.","title":"High Availability"},{"location":"operator-manual/high_availability/#scaling-up","text":"You might scale up some Argo CD services in the following circumstances: The argocd-repo-server can scale up when there is too much contention on a single git repo (e.g. many apps defined in a single git repo). The argocd-server can scale up to support more front-end load. All other services should run with their pre-determined number of replicas. The argocd-application-controller must not be increased because multiple controllers will fight. The argocd-dex-server uses an in-memory database, and two or more instances would have inconsistent data. argocd-redis is pre-configured with the understanding of only three total redis servers/sentinels.","title":"Scaling Up"},{"location":"operator-manual/ingress/","text":"Ingress Configuration Argo CD runs both a gRPC server (used by the CLI), as well as a HTTP/HTTPS server (used by the UI). Both protocols are exposed by the argocd-server service object on the following ports: 443 - gRPC/HTTPS 80 - HTTP (redirects to HTTPS) There are several ways how Ingress can be configured. kubernetes/ingress-nginx Option 1: SSL-Passthrough Because Argo CD serves multiple protocols (gRPC/HTTPS) on the same port (443), this provides a challenge when attempting to define a single nginx ingress object and rule for the argocd-service, since the nginx.ingress.kubernetes.io/backend-protocol annotation accepts only a single value for the backend protocol (e.g. HTTP, HTTPS, GRPC, GRPCS). In order to expose the Argo CD API server with a single ingress rule and hostname, the nginx.ingress.kubernetes.io/ssl-passthrough annotation must be used to passthrough TLS connections and terminate TLS at the Argo CD API server. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/force-ssl-redirect : true nginx.ingress.kubernetes.io/ssl-passthrough : true spec : rules : - host : argocd.example.com http : paths : - backend : serviceName : argocd-server servicePort : https The above rule terminates TLS at the Argo CD API server, which detects the protocol being used, and responds appropriately. Note that the nginx.ingress.kubernetes.io/ssl-passthrough annotation requires that the --enable-ssl-passthrough flag be added to the command line arguments to nginx-ingress-controller . Option 2: Multiple Ingress Objects And Hosts Since ingress-nginx Ingress supports only a single protocol per Ingress object, an alternative way would be to define two Ingress objects. One for HTTP/HTTPS, and the other for gRPC: HTTP/HTTPS Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-http-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/force-ssl-redirect : true nginx.ingress.kubernetes.io/backend-protocol : HTTP spec : rules : - http : paths : - backend : serviceName : argocd-server servicePort : http host : argocd.example.com tls : - hosts : - argocd.example.com secretName : argocd-secret gRPC Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-grpc-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/backend-protocol : GRPC spec : rules : - http : paths : - backend : serviceName : argocd-server servicePort : https host : grpc.argocd.example.com tls : - hosts : - grpc.argocd.example.com secretName : argocd-secret The API server should then be run with TLS disabled. Edit the argocd-server deployment to add the --insecure flag to the argocd-server command: spec : template : spec : name : argocd-server containers : - command : - /argocd-server - --staticassets - /shared/app - --repo-server - argocd-repo-server:8081 - --insecure The obvious disadvantage to this approach is that this technique require two separate hostnames for the API server -- one for gRPC and the other for HTTP/HTTPS. However it allow TLS termination to happen at the ingress controller. AWS Application Load Balancers (ALBs) And Classic ELB (HTTP Mode) Neither ALBs and Classic ELB in HTTP mode, do not have full support for HTTP2/gRPC which is the protocol used by the argocd CLI. Thus, when using an AWS load balancer, either Classic ELB in passthrough mode is needed, or NLBs. $ argocd login host : port --grpc-web UI Base Path If Argo CD UI is available under non-root path (e.g. /argo-cd instead of / ) then UI path should be configured in API server. To configure UI path add --basehref flag into argocd-server deployment command: spec : template : spec : name : argocd-server containers : - command : - /argocd-server - --staticassets - /shared/app - --repo-server - argocd-repo-server:8081 - --basehref - /argo-cd NOTE: flag --basehref only changes UI base URL. API server keep using / path so you need to add URL rewrite rule to proxy config. Example nginx.conf with URL rewrite: worker_processes 1 ; events { worker_connections 1024 ; } http { sendfile on ; server { listen 443 ; location / argo - cd { rewrite / argo - cd / ( . * ) / $1 break ; proxy_pass https : // localhost : 8080 ; proxy_redirect off ; proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header X - Forwarded - Host $ server_name ; } } }","title":"Ingress Configuration"},{"location":"operator-manual/ingress/#ingress-configuration","text":"Argo CD runs both a gRPC server (used by the CLI), as well as a HTTP/HTTPS server (used by the UI). Both protocols are exposed by the argocd-server service object on the following ports: 443 - gRPC/HTTPS 80 - HTTP (redirects to HTTPS) There are several ways how Ingress can be configured.","title":"Ingress Configuration"},{"location":"operator-manual/ingress/#kubernetesingress-nginx","text":"","title":"kubernetes/ingress-nginx"},{"location":"operator-manual/ingress/#option-1-ssl-passthrough","text":"Because Argo CD serves multiple protocols (gRPC/HTTPS) on the same port (443), this provides a challenge when attempting to define a single nginx ingress object and rule for the argocd-service, since the nginx.ingress.kubernetes.io/backend-protocol annotation accepts only a single value for the backend protocol (e.g. HTTP, HTTPS, GRPC, GRPCS). In order to expose the Argo CD API server with a single ingress rule and hostname, the nginx.ingress.kubernetes.io/ssl-passthrough annotation must be used to passthrough TLS connections and terminate TLS at the Argo CD API server. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/force-ssl-redirect : true nginx.ingress.kubernetes.io/ssl-passthrough : true spec : rules : - host : argocd.example.com http : paths : - backend : serviceName : argocd-server servicePort : https The above rule terminates TLS at the Argo CD API server, which detects the protocol being used, and responds appropriately. Note that the nginx.ingress.kubernetes.io/ssl-passthrough annotation requires that the --enable-ssl-passthrough flag be added to the command line arguments to nginx-ingress-controller .","title":"Option 1: SSL-Passthrough"},{"location":"operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts","text":"Since ingress-nginx Ingress supports only a single protocol per Ingress object, an alternative way would be to define two Ingress objects. One for HTTP/HTTPS, and the other for gRPC: HTTP/HTTPS Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-http-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/force-ssl-redirect : true nginx.ingress.kubernetes.io/backend-protocol : HTTP spec : rules : - http : paths : - backend : serviceName : argocd-server servicePort : http host : argocd.example.com tls : - hosts : - argocd.example.com secretName : argocd-secret gRPC Ingress: apiVersion : extensions/v1beta1 kind : Ingress metadata : name : argocd-server-grpc-ingress annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/backend-protocol : GRPC spec : rules : - http : paths : - backend : serviceName : argocd-server servicePort : https host : grpc.argocd.example.com tls : - hosts : - grpc.argocd.example.com secretName : argocd-secret The API server should then be run with TLS disabled. Edit the argocd-server deployment to add the --insecure flag to the argocd-server command: spec : template : spec : name : argocd-server containers : - command : - /argocd-server - --staticassets - /shared/app - --repo-server - argocd-repo-server:8081 - --insecure The obvious disadvantage to this approach is that this technique require two separate hostnames for the API server -- one for gRPC and the other for HTTP/HTTPS. However it allow TLS termination to happen at the ingress controller.","title":"Option 2: Multiple Ingress Objects And Hosts"},{"location":"operator-manual/ingress/#aws-application-load-balancers-albs-and-classic-elb-http-mode","text":"Neither ALBs and Classic ELB in HTTP mode, do not have full support for HTTP2/gRPC which is the protocol used by the argocd CLI. Thus, when using an AWS load balancer, either Classic ELB in passthrough mode is needed, or NLBs. $ argocd login host : port --grpc-web","title":"AWS Application Load Balancers (ALBs) And Classic ELB (HTTP Mode)"},{"location":"operator-manual/ingress/#ui-base-path","text":"If Argo CD UI is available under non-root path (e.g. /argo-cd instead of / ) then UI path should be configured in API server. To configure UI path add --basehref flag into argocd-server deployment command: spec : template : spec : name : argocd-server containers : - command : - /argocd-server - --staticassets - /shared/app - --repo-server - argocd-repo-server:8081 - --basehref - /argo-cd NOTE: flag --basehref only changes UI base URL. API server keep using / path so you need to add URL rewrite rule to proxy config. Example nginx.conf with URL rewrite: worker_processes 1 ; events { worker_connections 1024 ; } http { sendfile on ; server { listen 443 ; location / argo - cd { rewrite / argo - cd / ( . * ) / $1 break ; proxy_pass https : // localhost : 8080 ; proxy_redirect off ; proxy_set_header Host $ host ; proxy_set_header X - Real - IP $ remote_addr ; proxy_set_header X - Forwarded - For $ proxy_add_x_forwarded_for ; proxy_set_header X - Forwarded - Host $ server_name ; } } }","title":"UI Base Path"},{"location":"operator-manual/metrics/","text":"Metrics Argo CD exposes two sets of Prometheus metrics Application Metrics Metrics about applications. Scraped at the argocd-metrics:8082/metrics endpoint. Gauge for application health status Gauge for application sync status Counter for application sync history API Server Metrics Metrics about API Server API request and response activity (request totals, response codes, etc...). Scraped at the argocd-server-metrics:8083/metrics endpoint. Prometheus Operator If using Prometheus Operator, the following ServiceMonitor example manifests can be used. Change metadata.labels.release to the name of label selected by your Prometheus. apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-metrics endpoints : - port : metrics apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-server-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-server-metrics endpoints : - port : metrics apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-repo-server-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-repo-server endpoints : - port : metrics Dashboards You can find an example Grafana dashboard here","title":"Metrics"},{"location":"operator-manual/metrics/#metrics","text":"Argo CD exposes two sets of Prometheus metrics","title":"Metrics"},{"location":"operator-manual/metrics/#application-metrics","text":"Metrics about applications. Scraped at the argocd-metrics:8082/metrics endpoint. Gauge for application health status Gauge for application sync status Counter for application sync history","title":"Application Metrics"},{"location":"operator-manual/metrics/#api-server-metrics","text":"Metrics about API Server API request and response activity (request totals, response codes, etc...). Scraped at the argocd-server-metrics:8083/metrics endpoint.","title":"API Server Metrics"},{"location":"operator-manual/metrics/#prometheus-operator","text":"If using Prometheus Operator, the following ServiceMonitor example manifests can be used. Change metadata.labels.release to the name of label selected by your Prometheus. apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-metrics endpoints : - port : metrics apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-server-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-server-metrics endpoints : - port : metrics apiVersion : monitoring.coreos.com/v1 kind : ServiceMonitor metadata : name : argocd-repo-server-metrics labels : release : prometheus-operator spec : selector : matchLabels : app.kubernetes.io/name : argocd-repo-server endpoints : - port : metrics","title":"Prometheus Operator"},{"location":"operator-manual/metrics/#dashboards","text":"You can find an example Grafana dashboard here","title":"Dashboards"},{"location":"operator-manual/rbac/","text":"RBAC Overview The RBAC feature enables restriction of access to Argo CD resources. Argo CD does not have its own user management system and has only one built-in user admin . The admin user is a superuser and it has unrestricted access to the system. RBAC requires SSO configuration . Once SSO is configured, additional RBAC roles can be defined, and SSO groups can man be mapped to roles. Configure RBAC RBAC configuration allows defining roles and groups. Argo CD has two pre-defined roles: role:readonly - read-only access to all resources role:admin - unrestricted access to all resources These role definitions can be seen in builtin-policy.csv Additional roles and groups can be configured in argocd-rbac-cm ConfigMap. The example below configures a custom role, named org-admin . The role is assigned to any user which belongs to your-github-org:your-team group. All other users get the default policy of role:readonly , which cannot modify Argo CD settings. ConfigMap argocd-rbac-cm example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-rbac-cm namespace : argocd data : policy.default : role:readonly policy.csv : | p, role:org-admin, applications, *, */*, allow p, role:org-admin, clusters, get, *, allow p, role:org-admin, repositories, get, *, allow p, role:org-admin, repositories, create, *, allow p, role:org-admin, repositories, update, *, allow p, role:org-admin, repositories, delete, *, allow g, your-github-org:your-team, role:org-admin Anonymous Access THe anonymous access to Argo CD can be enabled using users.anonymous.enabled field in argocd-cm (see ./argocd-cm.yaml ). The anonymous users get default role permissions specified argocd-rbac-cm.yaml.","title":"RBAC"},{"location":"operator-manual/rbac/#rbac","text":"","title":"RBAC"},{"location":"operator-manual/rbac/#overview","text":"The RBAC feature enables restriction of access to Argo CD resources. Argo CD does not have its own user management system and has only one built-in user admin . The admin user is a superuser and it has unrestricted access to the system. RBAC requires SSO configuration . Once SSO is configured, additional RBAC roles can be defined, and SSO groups can man be mapped to roles.","title":"Overview"},{"location":"operator-manual/rbac/#configure-rbac","text":"RBAC configuration allows defining roles and groups. Argo CD has two pre-defined roles: role:readonly - read-only access to all resources role:admin - unrestricted access to all resources These role definitions can be seen in builtin-policy.csv Additional roles and groups can be configured in argocd-rbac-cm ConfigMap. The example below configures a custom role, named org-admin . The role is assigned to any user which belongs to your-github-org:your-team group. All other users get the default policy of role:readonly , which cannot modify Argo CD settings. ConfigMap argocd-rbac-cm example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-rbac-cm namespace : argocd data : policy.default : role:readonly policy.csv : | p, role:org-admin, applications, *, */*, allow p, role:org-admin, clusters, get, *, allow p, role:org-admin, repositories, get, *, allow p, role:org-admin, repositories, create, *, allow p, role:org-admin, repositories, update, *, allow p, role:org-admin, repositories, delete, *, allow g, your-github-org:your-team, role:org-admin","title":"Configure RBAC"},{"location":"operator-manual/rbac/#anonymous-access","text":"THe anonymous access to Argo CD can be enabled using users.anonymous.enabled field in argocd-cm (see ./argocd-cm.yaml ). The anonymous users get default role permissions specified argocd-rbac-cm.yaml.","title":"Anonymous Access"},{"location":"operator-manual/security/","text":"Security Argo CD has undergone rigourous internal security reviews and penetration testing to satisfy PCI compliance requirements. The following are some security topics and implementation details of Argo CD. Authentication Authentication to Argo CD API server is performed exclusively using JSON Web Tokens (JWTs). Username/password bearer tokens are not used for authentication. The JWT is obtained/managed in one of the following ways: For the local admin user, a username/password is exchanged for a JWT using the /api/v1/session endpoint. This token is signed issued by the Argo CD API server itself, and has no expiration. When the admin password is updated, all existing admin JWT tokens are immediately revoked. The password is stored as a bcrypt hash in the argocd-secret Secret. For Single Sign-On users, the user completes an OAuth2 login flow to the configured OIDC identity provider (either delegated through the bundled Dex provider, or directly to a self-managed OIDC provider). This JWT is signed issued by the IDP, and expiration and revokation is handled by the provider. Dex tokens expire after 24 hours. Automation tokens are generated for a project using the /api/v1/projects/{project}/roles/{role}/token endpoint, and are signed issued by Argo CD. These tokens are limited in scope and privilege, and can only be used to manage application resources in the project which it belongs to. Project JWTs have a configurable expiration and can be immediately revoked by deleting the JWT reference ID from the project role. Authorization Authorization is performed by iterating the list of group membership in a user's JWT groups claims, and comparing each group against the roles/rules in the RBAC policy. Any matched rule permits access to the API request. TLS All network communication is performed over TLS including service-to-service communication between the three components (argocd-server, argocd-repo-server, argocd-application-controller). The Argo CD API server can enforce the use of TLS 1.2 using the flag: --tlsminversion 1.2 . Sensitive Information Secrets Argo CD never returns sensitive data from its API, and redacts all sensitive data in API payloads and logs. This includes: cluster credentials Git credentials OAuth2 client secrets Kubernetes Secret values External Cluster Credentials To manage external clusters, Argo CD stores the credentials of the external cluster as a Kubernetes Secret in the argocd namespace. This secret contains the K8s API bearer token associated with the argocd-manager ServiceAccount created during argocd cluster add , along with connection options to that API server (TLS configuration/certs, aws-iam-authenticator RoleARN, etc...). The information is used to reconstruct a REST config and kubeconfig to the cluster used by Argo CD services. To rotate the bearer token used by Argo CD, the token can be deleted (e.g. using kubectl) which causes kuberentes to generate a new secret with a new bearer token. The new token can be re-inputted to Argo CD by re-running argocd cluster add . Run the following commands against the managed cluster: # run using a kubeconfig for the externally managed cluster kubectl delete secret argocd-manager-token-XXXXXX -n kube-system argocd cluster add CONTEXTNAME To revoke Argo CD's access to a managed cluster, delete the RBAC artifacts against the managed cluster, and remove the cluster entry from Argo CD: # run using a kubeconfig for the externally managed cluster kubectl delete sa argocd-manager -n kube-system kubectl delete clusterrole argocd-manager-role kubectl delete clusterrolebinding argocd-manager-role-binding argocd cluster rm https://your-kubernetes-cluster-addr NOTE: for AWS EKS clusters, aws-iam-authenticator is used to authenticate to the external cluster, which uses IAM roles in lieu of locally stored tokens, so token rotation is not needed, and revokation is handled through IAM. Cluster RBAC By default, Argo CD uses a clusteradmin level role in order to: watch operate on cluster state deploy resources to the cluster Although Argo CD requires cluster-wide read privileges to resources in the managed cluster to function properly, it does not necessarily need full write privileges to the cluster. The ClusterRole used by argocd-server and argocd-application-controller can be modified such that write privileges are limited to only the namespaces and resources that you wish Argo CD to manage. To fine-tune privileges of externally managed clusters, edit the ClusterRole of the argocd-manager-role # run using a kubeconfig for the externally managed cluster kubectl edit clusterrole argocd-manager-role To fine-tune privileges which Argo CD has against its own cluster (i.e. https://kubernetes.default.svc), edit the following cluster roles where Argo CD is running in: # run using a kubeconfig to the cluster Argo CD is running in kubectl edit clusterrole argocd-server kubectl edit clusterrole argocd-application-controller Tip If you want to deny ArgoCD access to a kind of resource then add it as an excluded resource . Auditing As a GitOps deployment tool, the Git commit history provides a natural audit log of what changes were made to application configuration, when they were made, and by whom. However, this audit log only applies to what happened in Git and does not necessarily correlate one-to-one with events that happen in a cluster. For example, User A could have made multiple commits to application manifests, but User B could have just only synced those changes to the cluster sometime later. To complement the Git revision history, Argo CD emits Kubernetes Events of application activity, indicating the responsible actor when applicable. For example: $ kubectl get events LAST SEEN FIRST SEEN COUNT NAME KIND SUBOBJECT TYPE REASON SOURCE MESSAGE 1m 1m 1 guestbook.157f7c5edd33aeac Application Normal ResourceCreated argocd-server admin created application 1m 1m 1 guestbook.157f7c5f0f747acf Application Normal ResourceUpdated argocd-application-controller Updated sync status: - OutOfSync 1m 1m 1 guestbook.157f7c5f0fbebbff Application Normal ResourceUpdated argocd-application-controller Updated health status: - Missing 1m 1m 1 guestbook.157f7c6069e14f4d Application Normal OperationStarted argocd-server admin initiated sync to HEAD ( 8a1cb4a02d3538e54907c827352f66f20c3d7b0d ) 1m 1m 1 guestbook.157f7c60a55a81a8 Application Normal OperationCompleted argocd-application-controller Sync operation to 8a1cb4a02d3538e54907c827352f66f20c3d7b0d succeeded 1m 1m 1 guestbook.157f7c60af1ccae2 Application Normal ResourceUpdated argocd-application-controller Updated sync status: OutOfSync - Synced 1m 1m 1 guestbook.157f7c60af5bc4f0 Application Normal ResourceUpdated argocd-application-controller Updated health status: Missing - Progressing 1m 1m 1 guestbook.157f7c651990e848 Application Normal ResourceUpdated argocd-application-controller Updated health status: Progressing - Healthy These events can be then be persisted for longer periods of time using other tools as Event Exporter or Event Router . WebHook Payloads Payloads from webhook events are considered untrusted. Argo CD only examines the payload to infer the involved applications of the webhook event (e.g. which repo was modified), then refreshes the related application for reconciliation. This refresh is the same refresh which occurs regularly at three minute intervals, just fast-tracked by the webhook event. Reporting Vulnerabilities Please report security vulnerabilities by e-mailing: Jesse_Suen@intuit.com Alexander_Matyushentsev@intuit.com Edward_Lee@intuit.com","title":"Security"},{"location":"operator-manual/security/#security","text":"Argo CD has undergone rigourous internal security reviews and penetration testing to satisfy PCI compliance requirements. The following are some security topics and implementation details of Argo CD.","title":"Security"},{"location":"operator-manual/security/#authentication","text":"Authentication to Argo CD API server is performed exclusively using JSON Web Tokens (JWTs). Username/password bearer tokens are not used for authentication. The JWT is obtained/managed in one of the following ways: For the local admin user, a username/password is exchanged for a JWT using the /api/v1/session endpoint. This token is signed issued by the Argo CD API server itself, and has no expiration. When the admin password is updated, all existing admin JWT tokens are immediately revoked. The password is stored as a bcrypt hash in the argocd-secret Secret. For Single Sign-On users, the user completes an OAuth2 login flow to the configured OIDC identity provider (either delegated through the bundled Dex provider, or directly to a self-managed OIDC provider). This JWT is signed issued by the IDP, and expiration and revokation is handled by the provider. Dex tokens expire after 24 hours. Automation tokens are generated for a project using the /api/v1/projects/{project}/roles/{role}/token endpoint, and are signed issued by Argo CD. These tokens are limited in scope and privilege, and can only be used to manage application resources in the project which it belongs to. Project JWTs have a configurable expiration and can be immediately revoked by deleting the JWT reference ID from the project role.","title":"Authentication"},{"location":"operator-manual/security/#authorization","text":"Authorization is performed by iterating the list of group membership in a user's JWT groups claims, and comparing each group against the roles/rules in the RBAC policy. Any matched rule permits access to the API request.","title":"Authorization"},{"location":"operator-manual/security/#tls","text":"All network communication is performed over TLS including service-to-service communication between the three components (argocd-server, argocd-repo-server, argocd-application-controller). The Argo CD API server can enforce the use of TLS 1.2 using the flag: --tlsminversion 1.2 .","title":"TLS"},{"location":"operator-manual/security/#sensitive-information","text":"","title":"Sensitive Information"},{"location":"operator-manual/security/#secrets","text":"Argo CD never returns sensitive data from its API, and redacts all sensitive data in API payloads and logs. This includes: cluster credentials Git credentials OAuth2 client secrets Kubernetes Secret values","title":"Secrets"},{"location":"operator-manual/security/#external-cluster-credentials","text":"To manage external clusters, Argo CD stores the credentials of the external cluster as a Kubernetes Secret in the argocd namespace. This secret contains the K8s API bearer token associated with the argocd-manager ServiceAccount created during argocd cluster add , along with connection options to that API server (TLS configuration/certs, aws-iam-authenticator RoleARN, etc...). The information is used to reconstruct a REST config and kubeconfig to the cluster used by Argo CD services. To rotate the bearer token used by Argo CD, the token can be deleted (e.g. using kubectl) which causes kuberentes to generate a new secret with a new bearer token. The new token can be re-inputted to Argo CD by re-running argocd cluster add . Run the following commands against the managed cluster: # run using a kubeconfig for the externally managed cluster kubectl delete secret argocd-manager-token-XXXXXX -n kube-system argocd cluster add CONTEXTNAME To revoke Argo CD's access to a managed cluster, delete the RBAC artifacts against the managed cluster, and remove the cluster entry from Argo CD: # run using a kubeconfig for the externally managed cluster kubectl delete sa argocd-manager -n kube-system kubectl delete clusterrole argocd-manager-role kubectl delete clusterrolebinding argocd-manager-role-binding argocd cluster rm https://your-kubernetes-cluster-addr NOTE: for AWS EKS clusters, aws-iam-authenticator is used to authenticate to the external cluster, which uses IAM roles in lieu of locally stored tokens, so token rotation is not needed, and revokation is handled through IAM.","title":"External Cluster Credentials"},{"location":"operator-manual/security/#cluster-rbac","text":"By default, Argo CD uses a clusteradmin level role in order to: watch operate on cluster state deploy resources to the cluster Although Argo CD requires cluster-wide read privileges to resources in the managed cluster to function properly, it does not necessarily need full write privileges to the cluster. The ClusterRole used by argocd-server and argocd-application-controller can be modified such that write privileges are limited to only the namespaces and resources that you wish Argo CD to manage. To fine-tune privileges of externally managed clusters, edit the ClusterRole of the argocd-manager-role # run using a kubeconfig for the externally managed cluster kubectl edit clusterrole argocd-manager-role To fine-tune privileges which Argo CD has against its own cluster (i.e. https://kubernetes.default.svc), edit the following cluster roles where Argo CD is running in: # run using a kubeconfig to the cluster Argo CD is running in kubectl edit clusterrole argocd-server kubectl edit clusterrole argocd-application-controller Tip If you want to deny ArgoCD access to a kind of resource then add it as an excluded resource .","title":"Cluster RBAC"},{"location":"operator-manual/security/#auditing","text":"As a GitOps deployment tool, the Git commit history provides a natural audit log of what changes were made to application configuration, when they were made, and by whom. However, this audit log only applies to what happened in Git and does not necessarily correlate one-to-one with events that happen in a cluster. For example, User A could have made multiple commits to application manifests, but User B could have just only synced those changes to the cluster sometime later. To complement the Git revision history, Argo CD emits Kubernetes Events of application activity, indicating the responsible actor when applicable. For example: $ kubectl get events LAST SEEN FIRST SEEN COUNT NAME KIND SUBOBJECT TYPE REASON SOURCE MESSAGE 1m 1m 1 guestbook.157f7c5edd33aeac Application Normal ResourceCreated argocd-server admin created application 1m 1m 1 guestbook.157f7c5f0f747acf Application Normal ResourceUpdated argocd-application-controller Updated sync status: - OutOfSync 1m 1m 1 guestbook.157f7c5f0fbebbff Application Normal ResourceUpdated argocd-application-controller Updated health status: - Missing 1m 1m 1 guestbook.157f7c6069e14f4d Application Normal OperationStarted argocd-server admin initiated sync to HEAD ( 8a1cb4a02d3538e54907c827352f66f20c3d7b0d ) 1m 1m 1 guestbook.157f7c60a55a81a8 Application Normal OperationCompleted argocd-application-controller Sync operation to 8a1cb4a02d3538e54907c827352f66f20c3d7b0d succeeded 1m 1m 1 guestbook.157f7c60af1ccae2 Application Normal ResourceUpdated argocd-application-controller Updated sync status: OutOfSync - Synced 1m 1m 1 guestbook.157f7c60af5bc4f0 Application Normal ResourceUpdated argocd-application-controller Updated health status: Missing - Progressing 1m 1m 1 guestbook.157f7c651990e848 Application Normal ResourceUpdated argocd-application-controller Updated health status: Progressing - Healthy These events can be then be persisted for longer periods of time using other tools as Event Exporter or Event Router .","title":"Auditing"},{"location":"operator-manual/security/#webhook-payloads","text":"Payloads from webhook events are considered untrusted. Argo CD only examines the payload to infer the involved applications of the webhook event (e.g. which repo was modified), then refreshes the related application for reconciliation. This refresh is the same refresh which occurs regularly at three minute intervals, just fast-tracked by the webhook event.","title":"WebHook Payloads"},{"location":"operator-manual/security/#reporting-vulnerabilities","text":"Please report security vulnerabilities by e-mailing: Jesse_Suen@intuit.com Alexander_Matyushentsev@intuit.com Edward_Lee@intuit.com","title":"Reporting Vulnerabilities"},{"location":"operator-manual/sso/","text":"SSO Configuration Overview Argo CD does not have any local users other than the built-in admin user. All other users are expected to login via SSO. There are two ways that SSO can be configured: Bundled Dex OIDC provider - use this option if your current provider does not support OIDC (e.g. SAML, LDAP) or if you wish to leverage any of Dex's connector features (e.g. the ability to map GitHub organizations and teams to OIDC groups claims). Existing OIDC provider - use this if you already have an OIDC provider which you are using (e.g. Okta, OneLogin, Auth0, Microsoft), where you manage your users, groups, and memberships. Dex Argo CD embeds and bundles Dex as part of its installation, for the purpose of delegating authentication to an external identity provider. Multiple types of identity providers are supported (OIDC, SAML, LDAP, GitHub, etc...). SSO configuration of Argo CD requires editing the argocd-cm ConfigMap with Dex connector settings. This document describes how to configure Argo CD SSO using GitHub (OAuth2) as an example, but the steps should be similar for other identity providers. 1. Register the application in the identity provider In GitHub, register a new application. The callback address should be the /api/dex/callback endpoint of your Argo CD URL (e.g. https://argocd.example.com/api/dex/callback). After registering the app, you will receive an OAuth2 client ID and secret. These values will be inputted into the Argo CD configmap. 2. Configure Argo CD for SSO Edit the argocd-cm configmap: kubectl edit configmap argocd-cm -n argocd In the url key, input the base URL of Argo CD. In this example, it is https://argocd.example.com In the dex.config key, add the github connector to the connectors sub field. See Dex's GitHub connector documentation for explanation of the fields. A minimal config should populate the clientID, clientSecret generated in Step 1. You will very likely want to restrict logins to one or more GitHub organization. In the connectors.config.orgs list, add one or more GitHub organizations. Any member of the org will then be able to login to Argo CD to perform management tasks. data : url : https://argocd.example.com dex.config : | connectors: # GitHub example - type: github id: github name: GitHub config: clientID: aabbccddeeff00112233 clientSecret: $dex.github.clientSecret orgs: - name: your-github-org # GitHub enterprise example - type: github id: acme-github name: Acme GitHub config: hostName: github.acme.com clientID: abcdefghijklmnopqrst clientSecret: $dex.acme.clientSecret orgs: - name: your-github-org After saving, the changes should take affect automatically. NOTES: Any values which start with '$' will look to a key in argocd-secret of the same name (minus the $), to obtain the actual value. This allows you to store the clientSecret as a kubernetes secret. There is no need to set redirectURI in the connectors.config as shown in the dex documentation. Argo CD will automatically use the correct redirectURI for any OAuth2 connectors, to match the correct external callback URL (e.g. https://argocd.example.com/api/dex/callback) Existing OIDC Provider To configure Argo CD to delegate authenticate to your existing OIDC provider, add the OAuth2 configuration to the argocd-cm ConfigMap under the oidc.config key: data : url : https://argocd.example.com oidc.config : | name: Okta issuer: https://dev-123456.oktapreview.com clientID: aaaabbbbccccddddeee clientSecret: $oidc.okta.clientSecret # Some OIDC providers require a separate clientID for different callback URLs. # For example, if configuring Argo CD with self-hosted Dex, you will need a separate client ID # for the localhost (CLI) client to Dex. This field is optional. If omitted, the CLI will # use the same clientID as the Argo CD server cliClientID: vvvvwwwwxxxxyyyyzzzz","title":"SSO Configuration"},{"location":"operator-manual/sso/#sso-configuration","text":"","title":"SSO Configuration"},{"location":"operator-manual/sso/#overview","text":"Argo CD does not have any local users other than the built-in admin user. All other users are expected to login via SSO. There are two ways that SSO can be configured: Bundled Dex OIDC provider - use this option if your current provider does not support OIDC (e.g. SAML, LDAP) or if you wish to leverage any of Dex's connector features (e.g. the ability to map GitHub organizations and teams to OIDC groups claims). Existing OIDC provider - use this if you already have an OIDC provider which you are using (e.g. Okta, OneLogin, Auth0, Microsoft), where you manage your users, groups, and memberships.","title":"Overview"},{"location":"operator-manual/sso/#dex","text":"Argo CD embeds and bundles Dex as part of its installation, for the purpose of delegating authentication to an external identity provider. Multiple types of identity providers are supported (OIDC, SAML, LDAP, GitHub, etc...). SSO configuration of Argo CD requires editing the argocd-cm ConfigMap with Dex connector settings. This document describes how to configure Argo CD SSO using GitHub (OAuth2) as an example, but the steps should be similar for other identity providers.","title":"Dex"},{"location":"operator-manual/sso/#1-register-the-application-in-the-identity-provider","text":"In GitHub, register a new application. The callback address should be the /api/dex/callback endpoint of your Argo CD URL (e.g. https://argocd.example.com/api/dex/callback). After registering the app, you will receive an OAuth2 client ID and secret. These values will be inputted into the Argo CD configmap.","title":"1. Register the application in the identity provider"},{"location":"operator-manual/sso/#2-configure-argo-cd-for-sso","text":"Edit the argocd-cm configmap: kubectl edit configmap argocd-cm -n argocd In the url key, input the base URL of Argo CD. In this example, it is https://argocd.example.com In the dex.config key, add the github connector to the connectors sub field. See Dex's GitHub connector documentation for explanation of the fields. A minimal config should populate the clientID, clientSecret generated in Step 1. You will very likely want to restrict logins to one or more GitHub organization. In the connectors.config.orgs list, add one or more GitHub organizations. Any member of the org will then be able to login to Argo CD to perform management tasks. data : url : https://argocd.example.com dex.config : | connectors: # GitHub example - type: github id: github name: GitHub config: clientID: aabbccddeeff00112233 clientSecret: $dex.github.clientSecret orgs: - name: your-github-org # GitHub enterprise example - type: github id: acme-github name: Acme GitHub config: hostName: github.acme.com clientID: abcdefghijklmnopqrst clientSecret: $dex.acme.clientSecret orgs: - name: your-github-org After saving, the changes should take affect automatically. NOTES: Any values which start with '$' will look to a key in argocd-secret of the same name (minus the $), to obtain the actual value. This allows you to store the clientSecret as a kubernetes secret. There is no need to set redirectURI in the connectors.config as shown in the dex documentation. Argo CD will automatically use the correct redirectURI for any OAuth2 connectors, to match the correct external callback URL (e.g. https://argocd.example.com/api/dex/callback)","title":"2. Configure Argo CD for SSO"},{"location":"operator-manual/sso/#existing-oidc-provider","text":"To configure Argo CD to delegate authenticate to your existing OIDC provider, add the OAuth2 configuration to the argocd-cm ConfigMap under the oidc.config key: data : url : https://argocd.example.com oidc.config : | name: Okta issuer: https://dev-123456.oktapreview.com clientID: aaaabbbbccccddddeee clientSecret: $oidc.okta.clientSecret # Some OIDC providers require a separate clientID for different callback URLs. # For example, if configuring Argo CD with self-hosted Dex, you will need a separate client ID # for the localhost (CLI) client to Dex. This field is optional. If omitted, the CLI will # use the same clientID as the Argo CD server cliClientID: vvvvwwwwxxxxyyyyzzzz","title":"Existing OIDC Provider"},{"location":"operator-manual/webhook/","text":"Git Webhook Configuration Overview Argo CD polls Git repositories every three minutes to detect changes to the manifests. To eliminate this delay from polling, the API server can be configured to receive webhook events. Argo CD supports Git webhook notifications from GitHub, GitLab, Bitbucket, Bitbucket Server and Gogs. The following explains how to configure a Git webhook for GitHub, but the same process should be applicable to other providers. 1. Create The WebHook In The Git Provider In your Git provider, navigate to the settings page where webhooks can be configured. The payload URL configured in the Git provider should use the /api/webhook endpoint of your Argo CD instance (e.g. [https://argocd.example.com/api/webhook]). If you wish to use a shared secret, input an arbitrary value in the secret. This value will be used when configuring the webhook in the next step. 2. Configure Argo CD With The WebHook Secret Optional) Configuring a webhook shared secret is optional, since Argo CD will still refresh applications related to the Git repository, even with unauthenticated webhook events. This is safe to do since the contents of webhook payloads are considered untrusted, and will only result in a refresh of the application (a process which already occurs at three-minute intervals). If Argo CD is publicly accessible, then configuring a webhook secret is recommended to prevent a DDoS attack. In the argocd-secret kubernetes secret, configure one of the following keys with the Git provider's webhook secret configured in step 1. Provider K8s Secret Key GitHub webhook.github.secret GitLab webhook.gitlab.secret BitBucket webhook.bitbucket.uuid BitBucketServer webhook.bitbucketserver.secret Gogs webhook.gogs.secret Edit the Argo CD kubernetes secret: kubectl edit secret argocd-secret -n argocd TIP: for ease of entering secrets, kubernetes supports inputting secrets in the stringData field, which saves you the trouble of base64 encoding the values and copying it to the data field. Simply copy the shared webhook secret created in step 1, to the corresponding GitHub/GitLab/BitBucket key under the stringData field: apiVersion : v1 kind : Secret metadata : name : argocd-secret namespace : argocd type : Opaque data : ... stringData : # github webhook secret webhook.github.secret : shhhh! it s a github secret # gitlab webhook secret webhook.gitlab.secret : shhhh! it s a gitlab secret # bitbucket webhook secret webhook.bitbucket.uuid : your-bitbucket-uuid # bitbucket server webhook secret webhook.bitbucketserver.secret : shhhh! it s a bitbucket server secret # gogs server webhook secret webhook.gogs.secret : shhhh! it s a gogs server secret After saving, the changes should take affect automatically.","title":"Git Webhook Configuration"},{"location":"operator-manual/webhook/#git-webhook-configuration","text":"","title":"Git Webhook Configuration"},{"location":"operator-manual/webhook/#overview","text":"Argo CD polls Git repositories every three minutes to detect changes to the manifests. To eliminate this delay from polling, the API server can be configured to receive webhook events. Argo CD supports Git webhook notifications from GitHub, GitLab, Bitbucket, Bitbucket Server and Gogs. The following explains how to configure a Git webhook for GitHub, but the same process should be applicable to other providers.","title":"Overview"},{"location":"operator-manual/webhook/#1-create-the-webhook-in-the-git-provider","text":"In your Git provider, navigate to the settings page where webhooks can be configured. The payload URL configured in the Git provider should use the /api/webhook endpoint of your Argo CD instance (e.g. [https://argocd.example.com/api/webhook]). If you wish to use a shared secret, input an arbitrary value in the secret. This value will be used when configuring the webhook in the next step.","title":"1. Create The WebHook In The Git Provider"},{"location":"operator-manual/webhook/#2-configure-argo-cd-with-the-webhook-secret-optional","text":"Configuring a webhook shared secret is optional, since Argo CD will still refresh applications related to the Git repository, even with unauthenticated webhook events. This is safe to do since the contents of webhook payloads are considered untrusted, and will only result in a refresh of the application (a process which already occurs at three-minute intervals). If Argo CD is publicly accessible, then configuring a webhook secret is recommended to prevent a DDoS attack. In the argocd-secret kubernetes secret, configure one of the following keys with the Git provider's webhook secret configured in step 1. Provider K8s Secret Key GitHub webhook.github.secret GitLab webhook.gitlab.secret BitBucket webhook.bitbucket.uuid BitBucketServer webhook.bitbucketserver.secret Gogs webhook.gogs.secret Edit the Argo CD kubernetes secret: kubectl edit secret argocd-secret -n argocd TIP: for ease of entering secrets, kubernetes supports inputting secrets in the stringData field, which saves you the trouble of base64 encoding the values and copying it to the data field. Simply copy the shared webhook secret created in step 1, to the corresponding GitHub/GitLab/BitBucket key under the stringData field: apiVersion : v1 kind : Secret metadata : name : argocd-secret namespace : argocd type : Opaque data : ... stringData : # github webhook secret webhook.github.secret : shhhh! it s a github secret # gitlab webhook secret webhook.gitlab.secret : shhhh! it s a gitlab secret # bitbucket webhook secret webhook.bitbucket.uuid : your-bitbucket-uuid # bitbucket server webhook secret webhook.bitbucketserver.secret : shhhh! it s a bitbucket server secret # gogs server webhook secret webhook.gogs.secret : shhhh! it s a gogs server secret After saving, the changes should take affect automatically.","title":"2. Configure Argo CD With The WebHook Secret Optional)"},{"location":"user-guide/","text":"Overview This guide is for developers who have Argo CD installed for them and are managing applications. Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"user-guide/#overview","text":"This guide is for developers who have Argo CD installed for them and are managing applications. Note Please make sure you've completed the getting started guide .","title":"Overview"},{"location":"user-guide/app_deletion/","text":"App Deletion Apps can be deleted with or without a cascade option. A cascade delete , deletes the both app's and its resources, rather than only the app. Deletion Using argocd To perform an non-cascade delete: argocd app delete APPNAME To perform a cascade delete: argocd app delete APPNAME --cascade Deletion Using kubectl To perform a non-cascade delete: kubetctl delete app APPNAME To perform a cascade delete set the finalizer, e.g. using kubctl patch : kubectl patch app APPNAME -p { metadata : { finalizers : [ resources-finalizer.argocd.argoproj.io ]}} --type merge kubectl delete app APPNAME About The Deletion Finalizer For the technical amongst you, the Argo CD application controller watches for this finalizer: metadata : finalizers : - resources-finalizer.argocd.argoproj.io Argo CD's app controller watches for this and will then delete both the app and its resources. When you invoke argocd app delete with --cascade , the finalizer is added automatically.","title":"App Deletion"},{"location":"user-guide/app_deletion/#app-deletion","text":"Apps can be deleted with or without a cascade option. A cascade delete , deletes the both app's and its resources, rather than only the app.","title":"App Deletion"},{"location":"user-guide/app_deletion/#deletion-using-argocd","text":"To perform an non-cascade delete: argocd app delete APPNAME To perform a cascade delete: argocd app delete APPNAME --cascade","title":"Deletion Using argocd"},{"location":"user-guide/app_deletion/#deletion-using-kubectl","text":"To perform a non-cascade delete: kubetctl delete app APPNAME To perform a cascade delete set the finalizer, e.g. using kubctl patch : kubectl patch app APPNAME -p { metadata : { finalizers : [ resources-finalizer.argocd.argoproj.io ]}} --type merge kubectl delete app APPNAME","title":"Deletion Using kubectl"},{"location":"user-guide/app_deletion/#about-the-deletion-finalizer","text":"For the technical amongst you, the Argo CD application controller watches for this finalizer: metadata : finalizers : - resources-finalizer.argocd.argoproj.io Argo CD's app controller watches for this and will then delete both the app and its resources. When you invoke argocd app delete with --cascade , the finalizer is added automatically.","title":"About The Deletion Finalizer"},{"location":"user-guide/application_sources/","text":"Tools Production Argo CD supports several different ways in which Kubernetes manifests can be defined: Kustomize applications Helm charts Ksonnet applications A directory of YAML/JSO/Jsonnet manifests Any custom config management tool configured as a config management plugin Development Argo CD also supports uploading local manifests directly. Since this is an anti-pattern of the GitOps paradigm, this should only be done for development purposes. A user with an override permission is required to upload manifests locally (typically an admin). All of the different Kubernetes deployment tools above are supported. To upload a local application: $ argocd app sync APPNAME --local /path/to/dir/","title":"Tools"},{"location":"user-guide/application_sources/#tools","text":"","title":"Tools"},{"location":"user-guide/application_sources/#production","text":"Argo CD supports several different ways in which Kubernetes manifests can be defined: Kustomize applications Helm charts Ksonnet applications A directory of YAML/JSO/Jsonnet manifests Any custom config management tool configured as a config management plugin","title":"Production"},{"location":"user-guide/application_sources/#development","text":"Argo CD also supports uploading local manifests directly. Since this is an anti-pattern of the GitOps paradigm, this should only be done for development purposes. A user with an override permission is required to upload manifests locally (typically an admin). All of the different Kubernetes deployment tools above are supported. To upload a local application: $ argocd app sync APPNAME --local /path/to/dir/","title":"Development"},{"location":"user-guide/auto_sync/","text":"Automated Sync Policy Argo CD has the ability to automatically sync an application when it detects differences between the desired manifests in Git, and the live state in the cluster. A benefit of automatic sync is that CI/CD pipelines no longer need direct access to the Argo CD API server to perform the deployment. Instead, the pipeline makes a commit and push to the Git repository with the changes to the manifests in the tracking Git repo. To configure automated sync run: argocd app set APPNAME --sync-policy automated Alternatively, if creating the application an application manifest, specify a syncPolicy with an automated policy. spec : syncPolicy : automated : {} Automatic Pruning By default (and as a safety mechanism), automated sync will not delete resources when Argo CD detects the resource is no longer defined in Git. To prune the resources, a manual sync can always be performed (with pruning checked). Pruning can also be enabled to happen automatically as part of the automated sync by running: argocd app set APPNAME --auto-prune Or by setting the prune option to true in the automated sync policy: spec : syncPolicy : automated : prune : true Automated Sync Semantics An automated sync will only be performed if the application is OutOfSync. Applications in a Synced or error state will not attempt automated sync. Automated sync will only attempt one synchronization per unique combination of commit SHA1 and application parameters. If the most recent successful sync in the history was already performed against the same commit-SHA and parameters, a second sync will not be attempted. Automatic sync will not reattempt a sync if the previous sync attempt against the same commit-SHA and parameters had failed. Rollback cannot be performed against an application with automated sync enabled.","title":"Automated Sync Policy"},{"location":"user-guide/auto_sync/#automated-sync-policy","text":"Argo CD has the ability to automatically sync an application when it detects differences between the desired manifests in Git, and the live state in the cluster. A benefit of automatic sync is that CI/CD pipelines no longer need direct access to the Argo CD API server to perform the deployment. Instead, the pipeline makes a commit and push to the Git repository with the changes to the manifests in the tracking Git repo. To configure automated sync run: argocd app set APPNAME --sync-policy automated Alternatively, if creating the application an application manifest, specify a syncPolicy with an automated policy. spec : syncPolicy : automated : {}","title":"Automated Sync Policy"},{"location":"user-guide/auto_sync/#automatic-pruning","text":"By default (and as a safety mechanism), automated sync will not delete resources when Argo CD detects the resource is no longer defined in Git. To prune the resources, a manual sync can always be performed (with pruning checked). Pruning can also be enabled to happen automatically as part of the automated sync by running: argocd app set APPNAME --auto-prune Or by setting the prune option to true in the automated sync policy: spec : syncPolicy : automated : prune : true","title":"Automatic Pruning"},{"location":"user-guide/auto_sync/#automated-sync-semantics","text":"An automated sync will only be performed if the application is OutOfSync. Applications in a Synced or error state will not attempt automated sync. Automated sync will only attempt one synchronization per unique combination of commit SHA1 and application parameters. If the most recent successful sync in the history was already performed against the same commit-SHA and parameters, a second sync will not be attempted. Automatic sync will not reattempt a sync if the previous sync attempt against the same commit-SHA and parameters had failed. Rollback cannot be performed against an application with automated sync enabled.","title":"Automated Sync Semantics"},{"location":"user-guide/best_practices/","text":"Best Practices Separating Config Vs. Source Code Repositories Using a separate Git repository to hold your kubernetes manifests, keeping the config separate from your application source code, is highly recommended for the following reasons: It provides a clean separation of application code vs. application config. There will be times when you wish to modify just the manifests without triggering an entire CI build. For example, you likely do not want to trigger a build if you simply wish to bump the number of replicas in a Deployment spec. Cleaner audit log. For auditing purposes, a repo which only holds configuration will have a much cleaner Git history of what changes were made, without the noise coming from check-ins due to normal development activity. Your application may be comprised of services built from multiple Git repositories, but is deployed as a single unit. Oftentimes, microservices applications are comprised of services with different versioning schemes, and release cycles (e.g. ELK, Kafka + Zookeeper). It may not make sense to store the manifests in one of the source code repositories of a single component. Separation of access. The developers who are developing the application, may not necessarily be the same people who can/should push to production environments, either intentionally or unintentionally. By having separate repos, commit access can be given to the source code repo, and not the application config repo. If you are automating your CI pipeline, pushing manifest changes to the same Git repository can trigger an infinite loop of build jobs and Git commit triggers. Having a separate repo to push config changes to, prevents this from happening. Leaving Room For Imperativeness It may be desired to leave room for some imperativeness/automation, and not have everything defined in your Git manifests. For example, if you want the number of your deployment's replicas to be managed by Horizontal Pod Autoscaler , then you would not want to track replicas in Git. apiVersion : apps/v1 kind : Deployment metadata : name : nginx-deployment spec : # do not include replicas in the manifests if you want replicas to be controlled by HPA # replicas: 1 template : spec : containers : - image : nginx:1.7.9 name : nginx ports : - containerPort : 80 ... Ensuring Manifests At Git Revisions Are Truly Immutable When using templating tools like helm or kustomize , it is possible for manifests to change their meaning from one day to the next. This is typically caused by changes made to an upstream helm repository or kustomize base. For example, consider the following kustomization.yaml bases : - github.com/argoproj/argo-cd//manifests/cluster-install The above kustomization has a remote base to he HEAD revision of the argo-cd repo. Since this is not stable target, the manifests for this kustomize application can suddenly change meaning, even without any changes to your own Git repository. A better version would be to use a Git tag or commit SHA. For example: bases : - github.com/argoproj/argo-cd//manifests/cluster-install?ref=v0.11.1","title":"Best Practices"},{"location":"user-guide/best_practices/#best-practices","text":"","title":"Best Practices"},{"location":"user-guide/best_practices/#separating-config-vs-source-code-repositories","text":"Using a separate Git repository to hold your kubernetes manifests, keeping the config separate from your application source code, is highly recommended for the following reasons: It provides a clean separation of application code vs. application config. There will be times when you wish to modify just the manifests without triggering an entire CI build. For example, you likely do not want to trigger a build if you simply wish to bump the number of replicas in a Deployment spec. Cleaner audit log. For auditing purposes, a repo which only holds configuration will have a much cleaner Git history of what changes were made, without the noise coming from check-ins due to normal development activity. Your application may be comprised of services built from multiple Git repositories, but is deployed as a single unit. Oftentimes, microservices applications are comprised of services with different versioning schemes, and release cycles (e.g. ELK, Kafka + Zookeeper). It may not make sense to store the manifests in one of the source code repositories of a single component. Separation of access. The developers who are developing the application, may not necessarily be the same people who can/should push to production environments, either intentionally or unintentionally. By having separate repos, commit access can be given to the source code repo, and not the application config repo. If you are automating your CI pipeline, pushing manifest changes to the same Git repository can trigger an infinite loop of build jobs and Git commit triggers. Having a separate repo to push config changes to, prevents this from happening.","title":"Separating Config Vs. Source Code Repositories"},{"location":"user-guide/best_practices/#leaving-room-for-imperativeness","text":"It may be desired to leave room for some imperativeness/automation, and not have everything defined in your Git manifests. For example, if you want the number of your deployment's replicas to be managed by Horizontal Pod Autoscaler , then you would not want to track replicas in Git. apiVersion : apps/v1 kind : Deployment metadata : name : nginx-deployment spec : # do not include replicas in the manifests if you want replicas to be controlled by HPA # replicas: 1 template : spec : containers : - image : nginx:1.7.9 name : nginx ports : - containerPort : 80 ...","title":"Leaving Room For Imperativeness"},{"location":"user-guide/best_practices/#ensuring-manifests-at-git-revisions-are-truly-immutable","text":"When using templating tools like helm or kustomize , it is possible for manifests to change their meaning from one day to the next. This is typically caused by changes made to an upstream helm repository or kustomize base. For example, consider the following kustomization.yaml bases : - github.com/argoproj/argo-cd//manifests/cluster-install The above kustomization has a remote base to he HEAD revision of the argo-cd repo. Since this is not stable target, the manifests for this kustomize application can suddenly change meaning, even without any changes to your own Git repository. A better version would be to use a Git tag or commit SHA. For example: bases : - github.com/argoproj/argo-cd//manifests/cluster-install?ref=v0.11.1","title":"Ensuring Manifests At Git Revisions Are Truly Immutable"},{"location":"user-guide/ci_automation/","text":"Automation from CI Pipelines Argo CD follows the GitOps model of deployment, where desired configuration changes are first pushed to Git, and the cluster state then syncs to the desired state in git. This is a departure from imperative pipelines which do not traditionally use Git repositories to hold application config. To push new container images into to a cluster managed by Argo CD, the following workflow (or variations), might be used: Build And Publish A New Container Image docker build -t mycompany/guestbook:v2.0 . docker push mycompany/guestbook:v2.0 Update The Local Manifests Using Your Preferred Templating Tool, And Push The Changes To Git Tip The use of a different Git repository to hold your kubernetes manifests (separate from your application source code), is highly recommended. See best practices for further rationale. git clone https://github.com/mycompany/guestbook-config.git cd guestbook-config # kustomize kustomize edit set imagetag mycompany/guestbook:v2.0 # ksonnet ks param set guestbook image mycompany/guestbook:v2.0 # plain yaml kubectl patch --local -f config-deployment.yaml -p { spec :{ template :{ spec :{ containers :[{ name : guestbook , image : mycompany/guestbook:v2.0 }]}}}} -o yaml git add . -m Update guestbook to v2.0 git push Synchronize The App (Optional) For convenience, the argocd CLI can be downloaded directly from the API server. This is useful so that the CLI used in the CI pipeline is always kept in-sync and uses argocd binary that is always compatible with the Argo CD API server. export ARGOCD_SERVER = argocd.mycompany.com export ARGOCD_AUTH_TOKEN = JWT token generated from project curl -sSL -o /usr/local/bin/argocd https:// ${ ARGOCD_SERVER } /download/argocd-linux-amd64 argocd app sync guestbook argocd app wait guestbook If automated synchronization is configured for the application, this step is unnecessary. The controller will automatically detect the new config (fast tracked using a webhook , or polled every 3 minutes), and automatically sync the new manifests.","title":"Automation from CI Pipelines"},{"location":"user-guide/ci_automation/#automation-from-ci-pipelines","text":"Argo CD follows the GitOps model of deployment, where desired configuration changes are first pushed to Git, and the cluster state then syncs to the desired state in git. This is a departure from imperative pipelines which do not traditionally use Git repositories to hold application config. To push new container images into to a cluster managed by Argo CD, the following workflow (or variations), might be used:","title":"Automation from CI Pipelines"},{"location":"user-guide/ci_automation/#build-and-publish-a-new-container-image","text":"docker build -t mycompany/guestbook:v2.0 . docker push mycompany/guestbook:v2.0","title":"Build And Publish A New Container Image"},{"location":"user-guide/ci_automation/#update-the-local-manifests-using-your-preferred-templating-tool-and-push-the-changes-to-git","text":"Tip The use of a different Git repository to hold your kubernetes manifests (separate from your application source code), is highly recommended. See best practices for further rationale. git clone https://github.com/mycompany/guestbook-config.git cd guestbook-config # kustomize kustomize edit set imagetag mycompany/guestbook:v2.0 # ksonnet ks param set guestbook image mycompany/guestbook:v2.0 # plain yaml kubectl patch --local -f config-deployment.yaml -p { spec :{ template :{ spec :{ containers :[{ name : guestbook , image : mycompany/guestbook:v2.0 }]}}}} -o yaml git add . -m Update guestbook to v2.0 git push","title":"Update The Local Manifests Using Your Preferred Templating Tool, And Push The Changes To Git"},{"location":"user-guide/ci_automation/#synchronize-the-app-optional","text":"For convenience, the argocd CLI can be downloaded directly from the API server. This is useful so that the CLI used in the CI pipeline is always kept in-sync and uses argocd binary that is always compatible with the Argo CD API server. export ARGOCD_SERVER = argocd.mycompany.com export ARGOCD_AUTH_TOKEN = JWT token generated from project curl -sSL -o /usr/local/bin/argocd https:// ${ ARGOCD_SERVER } /download/argocd-linux-amd64 argocd app sync guestbook argocd app wait guestbook If automated synchronization is configured for the application, this step is unnecessary. The controller will automatically detect the new config (fast tracked using a webhook , or polled every 3 minutes), and automatically sync the new manifests.","title":"Synchronize The App (Optional)"},{"location":"user-guide/compare-options/","text":"Compare Options Ignoring Resources That Are Extraneous v1.1 You may wish to exclude resources from the app's overall sync status under certain circumstances. E.g. if they are generated by a tool. This can be done by adding this annotation: metadata : annotations : argocd.argoproj.io/compare-options : IgnoreExtraneous Note This only affects the sync status. If the resource's health is degraded, then the app will also be degraded. Kustomize has a feature that allows you to generate config maps ( read more \u29c9 ). You can set generatorOptions to add this annotation so that your app remains in sync: configMapGenerator : - name : my-map literals : - foo=bar generatorOptions : annotations : argocd.argoproj.io/compare-options : IgnoreExtraneous kind : Kustomization Note generatorOptions adds annotations to both config maps and secrets ( read more \u29c9 ). You may wish to combine this with the Prune=false sync option .","title":"Compare Options"},{"location":"user-guide/compare-options/#compare-options","text":"","title":"Compare Options"},{"location":"user-guide/compare-options/#ignoring-resources-that-are-extraneous","text":"v1.1 You may wish to exclude resources from the app's overall sync status under certain circumstances. E.g. if they are generated by a tool. This can be done by adding this annotation: metadata : annotations : argocd.argoproj.io/compare-options : IgnoreExtraneous Note This only affects the sync status. If the resource's health is degraded, then the app will also be degraded. Kustomize has a feature that allows you to generate config maps ( read more \u29c9 ). You can set generatorOptions to add this annotation so that your app remains in sync: configMapGenerator : - name : my-map literals : - foo=bar generatorOptions : annotations : argocd.argoproj.io/compare-options : IgnoreExtraneous kind : Kustomization Note generatorOptions adds annotations to both config maps and secrets ( read more \u29c9 ). You may wish to combine this with the Prune=false sync option .","title":"Ignoring Resources That Are Extraneous"},{"location":"user-guide/config-management-plugins/","text":"Plugins Argo CD allows integrating more config management tools using config management plugins. Following changes are required to configure new plugin: Make sure required binaries are available in argocd-repo-server pod. The binaries can be added via volume mounts or using custom image (see custom_tools ). Register a new plugin in argocd-cm ConfigMap: data : configManagementPlugins : | - name: pluginName init: # Optional command to initialize application source directory command: [ sample command ] args: [ sample args ] generate: # Command to generate manifests YAML command: [ sample command ] args: [ sample args ] The generate command must print a valid YAML stream to stdout. Both init and generate commands are executed inside the application source directory. Create an application and specify required config management plugin name. argocd app create appName --config-management-plugin pluginName More config management plugin examples are available in argocd-example-apps . Environment Commands have access to (1) The system environment variables (2) Argo CD environment variables: ARGOCD_APP_NAME - name of application ARGOCD_APP_NAMESPACE - destination application namespace. (3) Variables in the application spec: spec : source : plugin : env : - name : FOO value : bar","title":"Plugins"},{"location":"user-guide/config-management-plugins/#plugins","text":"Argo CD allows integrating more config management tools using config management plugins. Following changes are required to configure new plugin: Make sure required binaries are available in argocd-repo-server pod. The binaries can be added via volume mounts or using custom image (see custom_tools ). Register a new plugin in argocd-cm ConfigMap: data : configManagementPlugins : | - name: pluginName init: # Optional command to initialize application source directory command: [ sample command ] args: [ sample args ] generate: # Command to generate manifests YAML command: [ sample command ] args: [ sample args ] The generate command must print a valid YAML stream to stdout. Both init and generate commands are executed inside the application source directory. Create an application and specify required config management plugin name. argocd app create appName --config-management-plugin pluginName More config management plugin examples are available in argocd-example-apps .","title":"Plugins"},{"location":"user-guide/config-management-plugins/#environment","text":"Commands have access to (1) The system environment variables (2) Argo CD environment variables: ARGOCD_APP_NAME - name of application ARGOCD_APP_NAMESPACE - destination application namespace. (3) Variables in the application spec: spec : source : plugin : env : - name : FOO value : bar","title":"Environment"},{"location":"user-guide/diffing/","text":"Diffing Customization It is possible for an application to be OutOfSync even immediately after a successful Sync operation. Some reasons for this might be: There is a bug in the manifest, where it contains extra/unknown fields from the actual K8s spec. These extra fields would get dropped when querying Kubernetes for the live state, resulting in an OutOfSync status indicating a missing field was detected. The sync was performed (with pruning disabled), and there are resources which need to be deleted. A controller or mutating webhook is altering the object after it was submitted to Kubernetes in a manner which contradicts Git. A Helm chart is using a template function such as randAlphaNum , which generates different data every time helm template is invoked. For Horizontal Pod Autoscaling (HPA) objects, the HPA controller is known to reorder spec.metrics in a specific order. See kubernetes issue #74099 . To work around this, you can order spec.replicas in Git in the same order that the controller prefers. In case it is impossible to fix the upstream issue, Argo CD allows you to optionally ignore differences of problematic resources. The diffing customization can be configured for single or multiple application resources or at a system level. Application Level Configuration Argo CD allows ignoring differences at a specific JSON path. The following sample application is configured to ignore differences in spec.replicas for all deployments: spec : ignoreDifferences : - group : apps kind : Deployment jsonPointers : - /spec/replicas The above customization could be narrowed to a resource with the specified name and optional namespace: spec : ignoreDifferences : - group : apps kind : Deployment name : guestbook namespace : default jsonPointers : - /spec/replicas System-Level Configuration The comparison of resources with well-known issues can be customized at a system level. Ignored differences can be configured for a specified group and kind in resource.customizations key of argocd-cm ConfigMap. Following is an example of a customization which ignores the caBundle field of a MutatingWebhookConfiguration webhooks: data : resource.customizations : | admissionregistration.k8s.io/MutatingWebhookConfiguration: ignoreDifferences: | jsonPointers: - /webhooks/0/clientConfig/caBundle","title":"Diffing Customization"},{"location":"user-guide/diffing/#diffing-customization","text":"It is possible for an application to be OutOfSync even immediately after a successful Sync operation. Some reasons for this might be: There is a bug in the manifest, where it contains extra/unknown fields from the actual K8s spec. These extra fields would get dropped when querying Kubernetes for the live state, resulting in an OutOfSync status indicating a missing field was detected. The sync was performed (with pruning disabled), and there are resources which need to be deleted. A controller or mutating webhook is altering the object after it was submitted to Kubernetes in a manner which contradicts Git. A Helm chart is using a template function such as randAlphaNum , which generates different data every time helm template is invoked. For Horizontal Pod Autoscaling (HPA) objects, the HPA controller is known to reorder spec.metrics in a specific order. See kubernetes issue #74099 . To work around this, you can order spec.replicas in Git in the same order that the controller prefers. In case it is impossible to fix the upstream issue, Argo CD allows you to optionally ignore differences of problematic resources. The diffing customization can be configured for single or multiple application resources or at a system level.","title":"Diffing Customization"},{"location":"user-guide/diffing/#application-level-configuration","text":"Argo CD allows ignoring differences at a specific JSON path. The following sample application is configured to ignore differences in spec.replicas for all deployments: spec : ignoreDifferences : - group : apps kind : Deployment jsonPointers : - /spec/replicas The above customization could be narrowed to a resource with the specified name and optional namespace: spec : ignoreDifferences : - group : apps kind : Deployment name : guestbook namespace : default jsonPointers : - /spec/replicas","title":"Application Level Configuration"},{"location":"user-guide/diffing/#system-level-configuration","text":"The comparison of resources with well-known issues can be customized at a system level. Ignored differences can be configured for a specified group and kind in resource.customizations key of argocd-cm ConfigMap. Following is an example of a customization which ignores the caBundle field of a MutatingWebhookConfiguration webhooks: data : resource.customizations : | admissionregistration.k8s.io/MutatingWebhookConfiguration: ignoreDifferences: | jsonPointers: - /webhooks/0/clientConfig/caBundle","title":"System-Level Configuration"},{"location":"user-guide/helm/","text":"Helm Values Files Helm has the ability to use a different, or even multiple \"values.yaml\" files to derive its parameters from. Alternate or multiple values file(s), can be specified using the --values flag. The flag can be repeated to support multiple values files: argocd app set helm-guestbook --values values-production.yaml Helm Parameters Helm has the ability to set parameter values, which override any values in a values.yaml . For example, service.type is a common parameter which is exposed in a Helm chart: helm template . --set service.type = LoadBalancer Similarly Argo CD can override values in the values.yaml parameters using argo app set command, in the form of -p PARAM=VALUE . For example: argocd app set helm-guestbook -p service.type = LoadBalancer Helm Release Name By default the Helm release name is equal to the Application name to which it belongs. Sometimes, especially on a centralised ArgoCD, you may want to override that name, and it is possible with the release-name flag on the cli: argocd app set helm-guestbook --release-name myRelease or using the releaseName for yaml: source : helm : releaseName : myRelease Important notice on overriding the release name Please note that overriding the Helm release name might cause problems when the chart you are deploying is using the app.kubernetes.io/instance label. ArgoCD injects this label with the value of the Application name for tracking purposes. So when overriding the release name, the Application name will stop being equal to the release name. Because ArgoCD will overwrite the label with the Application name it might cause some selectors on the resources to stop working. In order to avoid this we can configure ArgoCD to use another label for tracking in the ArgoCD configmap argocd-cm.yaml - check the lines describing application.instanceLabelKey . Helm Hooks Helm hooks are equivalent in concept to Argo CD resource hooks . In helm, a hook is any normal kubernetes resource annotated with the helm.sh/hook annotation. When Argo CD deploys helm application which contains helm hooks, all helm hook resources are currently ignored during the kubectl apply of the manifests. There is an open issue to map Helm hooks to Argo CD's concept of Pre/Post/Sync hooks. Random Data Helm templating has the ability to generate random data during chart rendering via the randAlphaNum function. Many helm charts from the charts repository make use of this feature. For example, the following is the secret for the redis helm chart : data : {{ - if .Values.password }} redis-password : {{ .Values.password | b64enc | quote }} {{ - else }} redis-password : {{ randAlphaNum 10 | b64enc | quote }} {{ - end }} The Argo CD application controller periodically compares Git state against the live state, running the helm template CHART command to generate the helm manifests. Because the random value is regenerated every time the comparison is made, any application which makes use of the randAlphaNum function will always be in an OutOfSync state. This can be mitigated by explicitly setting a value, in the values.yaml such that the value is stable between each comparison. For example: argocd app set redis -p password = abc123","title":"Helm"},{"location":"user-guide/helm/#helm","text":"","title":"Helm"},{"location":"user-guide/helm/#values-files","text":"Helm has the ability to use a different, or even multiple \"values.yaml\" files to derive its parameters from. Alternate or multiple values file(s), can be specified using the --values flag. The flag can be repeated to support multiple values files: argocd app set helm-guestbook --values values-production.yaml","title":"Values Files"},{"location":"user-guide/helm/#helm-parameters","text":"Helm has the ability to set parameter values, which override any values in a values.yaml . For example, service.type is a common parameter which is exposed in a Helm chart: helm template . --set service.type = LoadBalancer Similarly Argo CD can override values in the values.yaml parameters using argo app set command, in the form of -p PARAM=VALUE . For example: argocd app set helm-guestbook -p service.type = LoadBalancer","title":"Helm Parameters"},{"location":"user-guide/helm/#helm-release-name","text":"By default the Helm release name is equal to the Application name to which it belongs. Sometimes, especially on a centralised ArgoCD, you may want to override that name, and it is possible with the release-name flag on the cli: argocd app set helm-guestbook --release-name myRelease or using the releaseName for yaml: source : helm : releaseName : myRelease Important notice on overriding the release name Please note that overriding the Helm release name might cause problems when the chart you are deploying is using the app.kubernetes.io/instance label. ArgoCD injects this label with the value of the Application name for tracking purposes. So when overriding the release name, the Application name will stop being equal to the release name. Because ArgoCD will overwrite the label with the Application name it might cause some selectors on the resources to stop working. In order to avoid this we can configure ArgoCD to use another label for tracking in the ArgoCD configmap argocd-cm.yaml - check the lines describing application.instanceLabelKey .","title":"Helm Release Name"},{"location":"user-guide/helm/#helm-hooks","text":"Helm hooks are equivalent in concept to Argo CD resource hooks . In helm, a hook is any normal kubernetes resource annotated with the helm.sh/hook annotation. When Argo CD deploys helm application which contains helm hooks, all helm hook resources are currently ignored during the kubectl apply of the manifests. There is an open issue to map Helm hooks to Argo CD's concept of Pre/Post/Sync hooks.","title":"Helm Hooks"},{"location":"user-guide/helm/#random-data","text":"Helm templating has the ability to generate random data during chart rendering via the randAlphaNum function. Many helm charts from the charts repository make use of this feature. For example, the following is the secret for the redis helm chart : data : {{ - if .Values.password }} redis-password : {{ .Values.password | b64enc | quote }} {{ - else }} redis-password : {{ randAlphaNum 10 | b64enc | quote }} {{ - end }} The Argo CD application controller periodically compares Git state against the live state, running the helm template CHART command to generate the helm manifests. Because the random value is regenerated every time the comparison is made, any application which makes use of the randAlphaNum function will always be in an OutOfSync state. This can be mitigated by explicitly setting a value, in the values.yaml such that the value is stable between each comparison. For example: argocd app set redis -p password = abc123","title":"Random Data"},{"location":"user-guide/ksonnet/","text":"Ksonnet Environments Ksonnet has a first class concept of an \"environment.\" To create an application from a ksonnet app directory, an environment must be specified. For example, the following command creates the \"guestbook-default\" app, which points to the default environment: argocd app create guestbook-default --repo https://github.com/argoproj/argocd-example-apps.git --path guestbook --env default Parameters Ksonnet parameters all belong to a component. For example, the following are the parameters available in the guestbook app, all of which belong to the guestbook-ui component: $ ks param list COMPONENT PARAM VALUE ========= ===== ===== guestbook-ui containerPort 80 guestbook-ui image gcr.io/heptio-images/ks-guestbook-demo:0.1 guestbook-ui name guestbook-ui guestbook-ui replicas 1 guestbook-ui servicePort 80 guestbook-ui type LoadBalancer When overriding ksonnet parameters in Argo CD, the component name should also be specified in the argocd app set command, in the form of -p COMPONENT=PARAM=VALUE . For example: argocd app set guestbook-default -p guestbook-ui = image = gcr.io/heptio-images/ks-guestbook-demo:0.1","title":"Ksonnet"},{"location":"user-guide/ksonnet/#ksonnet","text":"","title":"Ksonnet"},{"location":"user-guide/ksonnet/#environments","text":"Ksonnet has a first class concept of an \"environment.\" To create an application from a ksonnet app directory, an environment must be specified. For example, the following command creates the \"guestbook-default\" app, which points to the default environment: argocd app create guestbook-default --repo https://github.com/argoproj/argocd-example-apps.git --path guestbook --env default","title":"Environments"},{"location":"user-guide/ksonnet/#parameters","text":"Ksonnet parameters all belong to a component. For example, the following are the parameters available in the guestbook app, all of which belong to the guestbook-ui component: $ ks param list COMPONENT PARAM VALUE ========= ===== ===== guestbook-ui containerPort 80 guestbook-ui image gcr.io/heptio-images/ks-guestbook-demo:0.1 guestbook-ui name guestbook-ui guestbook-ui replicas 1 guestbook-ui servicePort 80 guestbook-ui type LoadBalancer When overriding ksonnet parameters in Argo CD, the component name should also be specified in the argocd app set command, in the form of -p COMPONENT=PARAM=VALUE . For example: argocd app set guestbook-default -p guestbook-ui = image = gcr.io/heptio-images/ks-guestbook-demo:0.1","title":"Parameters"},{"location":"user-guide/kustomize/","text":"Kustomize Warning Argo CD supports both versions, and auto-detects then by looking for apiVersion/kind is kustomize.yaml . You're probably using version 2 now, so make sure you you have those fields. You have three configuration options for Kustomize: namePrefix is a prefix appended to resources for Kustomize apps imageTags is a list of Kustomize 1.0 image tag overrides images is a list of Kustomize 2.0 image overrides To use Kustomize with an overlay, point your path to the overlay. Tip If you're generating resources, you should read up how to ignore those generated resources using the IgnoreExtraneous compare option . Private Remote Bases If you have remote bases that are either (a) HTTPS and need username/password (b) SSH and need SSH private key, then they'll inherit that from the app's repo. This will work if the remote bases uses the same credentials/private key. It will not work if they use different ones. For security reasons your app only ever knows about it's own repo (not other team's or users repos), and so you won't be able to access other private repo, even if Argo CD knows about them. Read more about private repos .","title":"Kustomize"},{"location":"user-guide/kustomize/#kustomize","text":"Warning Argo CD supports both versions, and auto-detects then by looking for apiVersion/kind is kustomize.yaml . You're probably using version 2 now, so make sure you you have those fields. You have three configuration options for Kustomize: namePrefix is a prefix appended to resources for Kustomize apps imageTags is a list of Kustomize 1.0 image tag overrides images is a list of Kustomize 2.0 image overrides To use Kustomize with an overlay, point your path to the overlay. Tip If you're generating resources, you should read up how to ignore those generated resources using the IgnoreExtraneous compare option .","title":"Kustomize"},{"location":"user-guide/kustomize/#private-remote-bases","text":"If you have remote bases that are either (a) HTTPS and need username/password (b) SSH and need SSH private key, then they'll inherit that from the app's repo. This will work if the remote bases uses the same credentials/private key. It will not work if they use different ones. For security reasons your app only ever knows about it's own repo (not other team's or users repos), and so you won't be able to access other private repo, even if Argo CD knows about them. Read more about private repos .","title":"Private Remote Bases"},{"location":"user-guide/parameters/","text":"Parameter Overrides Argo CD provides a mechanism to override the parameters of a ksonnet/helm app. This provides flexibility in having most of the application manifests defined in Git, while leaving room for some parts of the k8s manifests determined dynamically, or outside of Git. It also serves as an alternative way of redeploying an application by changing application parameters via Argo CD, instead of making the changes to the manifests in Git. Tip Many consider this mode of operation as an anti-pattern to GitOps, since the source of truth becomes a union of the Git repository, and the application overrides. The Argo CD parameter overrides feature is provided mainly as a convenience to developers and is intended to be used in dev/test environments, vs. production environments. To use parameter overrides, run the argocd app set -p (COMPONENT=)PARAM=VALUE command: argocd app set guestbook -p guestbook = image = example/guestbook:abcd123 argocd app sync guestbook The PARAM is expected to be a normal YAML path argocd app set guestbook -p guestbook = ingress.enabled = true argocd app set guestbook -p guestbook = ingress.hosts [ 0 ]= guestbook.myclusterurl The following are situations where parameter overrides would be useful: A team maintains a \"dev\" environment, which needs to be continually updated with the latest version of their guestbook application after every build in the tip of master. To address this use case, the application would expose a parameter named image , whose value used in the dev environment contains a placeholder value (e.g. example/guestbook:replaceme ). The placeholder value would be determined externally (outside of Git) such as a build system. Then, as part of the build pipeline, the parameter value of the image would be continually updated to the freshly built image (e.g. argocd app set guestbook -p guestbook=image=example/guestbook:abcd123 ). A sync operation would result in the application being redeployed with the new image. A repository of Helm manifests is already publicly available (e.g. https://github.com/helm/charts). Since commit access to the repository is unavailable, it is useful to be able to install charts from the public repository and customize the deployment with different parameters, without resorting to forking the repository to make the changes. For example, to install Redis from the Helm chart repository and customize the the database password, you would run: argocd app create redis --repo https://github.com/helm/charts.git --path stable/redis --dest-server https://kubernetes.default.svc --dest-namespace default -p password = abc123","title":"Parameter Overrides"},{"location":"user-guide/parameters/#parameter-overrides","text":"Argo CD provides a mechanism to override the parameters of a ksonnet/helm app. This provides flexibility in having most of the application manifests defined in Git, while leaving room for some parts of the k8s manifests determined dynamically, or outside of Git. It also serves as an alternative way of redeploying an application by changing application parameters via Argo CD, instead of making the changes to the manifests in Git. Tip Many consider this mode of operation as an anti-pattern to GitOps, since the source of truth becomes a union of the Git repository, and the application overrides. The Argo CD parameter overrides feature is provided mainly as a convenience to developers and is intended to be used in dev/test environments, vs. production environments. To use parameter overrides, run the argocd app set -p (COMPONENT=)PARAM=VALUE command: argocd app set guestbook -p guestbook = image = example/guestbook:abcd123 argocd app sync guestbook The PARAM is expected to be a normal YAML path argocd app set guestbook -p guestbook = ingress.enabled = true argocd app set guestbook -p guestbook = ingress.hosts [ 0 ]= guestbook.myclusterurl The following are situations where parameter overrides would be useful: A team maintains a \"dev\" environment, which needs to be continually updated with the latest version of their guestbook application after every build in the tip of master. To address this use case, the application would expose a parameter named image , whose value used in the dev environment contains a placeholder value (e.g. example/guestbook:replaceme ). The placeholder value would be determined externally (outside of Git) such as a build system. Then, as part of the build pipeline, the parameter value of the image would be continually updated to the freshly built image (e.g. argocd app set guestbook -p guestbook=image=example/guestbook:abcd123 ). A sync operation would result in the application being redeployed with the new image. A repository of Helm manifests is already publicly available (e.g. https://github.com/helm/charts). Since commit access to the repository is unavailable, it is useful to be able to install charts from the public repository and customize the deployment with different parameters, without resorting to forking the repository to make the changes. For example, to install Redis from the Helm chart repository and customize the the database password, you would run: argocd app create redis --repo https://github.com/helm/charts.git --path stable/redis --dest-server https://kubernetes.default.svc --dest-namespace default -p password = abc123","title":"Parameter Overrides"},{"location":"user-guide/private-repositories/","text":"Private Repositories Credentials If application manifests are located in private repository then repository credentials have to be configured. Argo CD supports both HTTP and SSH Git credentials. HTTPS Username And Password Credential Private repositories that require a username and password typically have a URL that start with \"https://\" rather than \"git@\" or \"ssh://\". Credentials can be configured using Argo CD CLI: argocd repo add https://github.com/argoproj/argocd-example-apps --username username --password password or UI: Navigate to Settings/Repositories Click Connect Repo button and enter HTTP credentials Access Token Instead of using username and password you might use access token. Following instructions of your Git hosting service to generate the token: Github Gitlab Bitbucket Then, connect the repository using an empty string as a username and access token value as a password. SSH Private Key Credential Private repositories that require an SSH private key have a URL that typically start with \"git@\" or \"ssh://\" rather than \"https://\". The Argo CD UI don't support configuring SSH credentials. The SSH credentials can only be configured using the Argo CD CLI: argocd repo add git @github . com : argoproj / argocd - example - apps . git --ssh-private-key-path ~/.ssh/id_rsa Self-signed Untrusted TLS Certificates v1.2 or higher If you are connecting a repository on a HTTPS server using a self-signed certificate, or a certificate signed by a custom Certificate Authority (CA) which are not known to ArgoCD, the repository will not be added due to security reasons. This is indicated by an error message such as x509: certificate signed by unknown authority . You can let ArgoCD connect the repository in an insecure way, without verifying the server's certificate at all. This can be accomplished by using the --insecure-skip-server-verification flag when adding the repository with the argocd CLI utility. However, this should be done only for non-production setups, as it imposes a serious security issue through possible man-in-the-middle attacks. You can let ArgoCD use a custom certificate for the verification of the server's certificate using the cert add-tls command of the argocd CLI utility. This is the recommended method and suitable for production use. In order to do so, you will need the server's certificate, or the certificate of the CA used to sign the server's certificate, in PEM format. Note For invalid server certificates, such as those without matching server name, or those that are expired, adding a CA certificate will not help. In this case, your only option will be to use the --insecure-skip-server-verification flag to connect the repository. You are strongly urged to use a valid certificate on the repository server, or to urge the server's administrator to replace the faulty certificate with a valid one. Example for adding a HTTPS repository to ArgoCD without verifying the server's certificate ( Caution: This is not recommended for production use): argocd repo add --insecure-skip-server-verification https://git.example.com/test-repo Example for adding a CA certificate contained in file ~/myca-cert.pem to properly verify the repository server: argocd cert add-tls git.example.com --from ~/myca-cert.pem argocd repo add https://git.example.com/test-repo You can also add more than one PEM for a server by concatenating them into the input stream. This might be useful if the repository server is about to replace the server certificate, possibly with one signed by a different CA. This way, you can have the old (current) as well as the new (future) certificate co-existing. If you already have the old certificate configured, use the --upsert flag and add the old and the new one in a single run: cat cert1.pem cert2.pem | argocd cert add-tls git.example.com --upsert Note To replace an existing certificate for a server, use the --upsert flag to the cert add-tls CLI command. Note TLS certificates are configured on a per-server, not on a per-repository basis. If you connect multiple repositories from the same server, you only have to configure the certificates once for this server. Note It can take up to a couple of minutes until the changes performed by the argocd cert command are propagated across your cluster, depending on your Kubernetes setup. You can also manage TLS certificates in a declarative, self-managed ArgoCD setup. All TLS certificates are stored in the ConfigMap object argocd-tls-cert-cm . Managing TLS certificates via the web UI is currently not possible. Before v1.2 We do not currently have first-class support for this. See #1513 . As a work-around, you can customize your Argo CD image. See #1344 Unknown SSH Hosts If you are using a privately hosted Git service over SSH, then you have the following options: v1.2 or later You can let ArgoCD connect the repository in an insecure way, without verifying the server's SSH host key at all. This can be accomplished by using the --insecure-skip-server-verification flag when adding the repository with the argocd CLI utility. However, this should be done only for non-production setups, as it imposes a serious security issue through possible man-in-the-middle attacks. You can make the server's SSH public key known to ArgoCD by using the cert add-ssh command of the argocd CLI utility. This is the recommended method and suitable for production use. In order to do so, you will need the server's SSH public host key, in the known_hosts format understood by ssh . You can get the server's public SSH host key e.g. by using the ssh-keyscan utility. Example for adding all available SSH public host keys for a server to ArgoCD: ssh-keyscan server.example.com | argocd cert add-ssh --batch Example for importing an existing known_hosts file to ArgoCD: argocd cert add-ssh --batch --from /etc/ssh/ssh_known_hosts Note It can take up to a couple of minutes until the changes performed by the argocd cert command are propagated across your cluster, depending on your Kubernetes setup. You can also manage SSH known hosts entries in a declarative, self-managed ArgoCD setup. All SSH public host keys are stored in the ConfigMap object argocd-ssh-known-hosts-cm . Managing SSH public host keys via the web UI is currently not possible. Before v1.2 (1) You can customize the Argo CD Docker image by adding the host's SSH public key to /etc/ssh/ssh_known_hosts . Additional entries to this file can be generated using the ssh-keyscan utility (e.g. ssh-keyscan your-private-git-server.com . For more information see example which demonstrates how /etc/ssh/ssh_known_hosts can be customized. Note The /etc/ssh/ssh_known_hosts should include Git host on each Argo CD deployment as well as on a computer where argocd repo add is executed. After resolving issue #1514 only argocd-repo-server deployment has to be customized. (1) Add repository using Argo CD CLI and --insecure-ignore-host-key flag: argocd repo add git@github.com:argoproj/argocd-example-apps.git --ssh-private-key-path ~/.ssh/id_rsa --insecure-ignore-host-key Don't use in production The --insecure-ignore-host-key should not be used in production as this is subject to man-in-the-middle attacks. This does not work for Kustomize remote bases or custom plugins For Kustomize support, see #827 . Declarative Configuration See declarative setup","title":"Private Repositories"},{"location":"user-guide/private-repositories/#private-repositories","text":"","title":"Private Repositories"},{"location":"user-guide/private-repositories/#credentials","text":"If application manifests are located in private repository then repository credentials have to be configured. Argo CD supports both HTTP and SSH Git credentials.","title":"Credentials"},{"location":"user-guide/private-repositories/#https-username-and-password-credential","text":"Private repositories that require a username and password typically have a URL that start with \"https://\" rather than \"git@\" or \"ssh://\". Credentials can be configured using Argo CD CLI: argocd repo add https://github.com/argoproj/argocd-example-apps --username username --password password or UI: Navigate to Settings/Repositories Click Connect Repo button and enter HTTP credentials","title":"HTTPS Username And Password Credential"},{"location":"user-guide/private-repositories/#access-token","text":"Instead of using username and password you might use access token. Following instructions of your Git hosting service to generate the token: Github Gitlab Bitbucket Then, connect the repository using an empty string as a username and access token value as a password.","title":"Access Token"},{"location":"user-guide/private-repositories/#ssh-private-key-credential","text":"Private repositories that require an SSH private key have a URL that typically start with \"git@\" or \"ssh://\" rather than \"https://\". The Argo CD UI don't support configuring SSH credentials. The SSH credentials can only be configured using the Argo CD CLI: argocd repo add git @github . com : argoproj / argocd - example - apps . git --ssh-private-key-path ~/.ssh/id_rsa","title":"SSH Private Key Credential"},{"location":"user-guide/private-repositories/#self-signed-untrusted-tls-certificates","text":"v1.2 or higher If you are connecting a repository on a HTTPS server using a self-signed certificate, or a certificate signed by a custom Certificate Authority (CA) which are not known to ArgoCD, the repository will not be added due to security reasons. This is indicated by an error message such as x509: certificate signed by unknown authority . You can let ArgoCD connect the repository in an insecure way, without verifying the server's certificate at all. This can be accomplished by using the --insecure-skip-server-verification flag when adding the repository with the argocd CLI utility. However, this should be done only for non-production setups, as it imposes a serious security issue through possible man-in-the-middle attacks. You can let ArgoCD use a custom certificate for the verification of the server's certificate using the cert add-tls command of the argocd CLI utility. This is the recommended method and suitable for production use. In order to do so, you will need the server's certificate, or the certificate of the CA used to sign the server's certificate, in PEM format. Note For invalid server certificates, such as those without matching server name, or those that are expired, adding a CA certificate will not help. In this case, your only option will be to use the --insecure-skip-server-verification flag to connect the repository. You are strongly urged to use a valid certificate on the repository server, or to urge the server's administrator to replace the faulty certificate with a valid one. Example for adding a HTTPS repository to ArgoCD without verifying the server's certificate ( Caution: This is not recommended for production use): argocd repo add --insecure-skip-server-verification https://git.example.com/test-repo Example for adding a CA certificate contained in file ~/myca-cert.pem to properly verify the repository server: argocd cert add-tls git.example.com --from ~/myca-cert.pem argocd repo add https://git.example.com/test-repo You can also add more than one PEM for a server by concatenating them into the input stream. This might be useful if the repository server is about to replace the server certificate, possibly with one signed by a different CA. This way, you can have the old (current) as well as the new (future) certificate co-existing. If you already have the old certificate configured, use the --upsert flag and add the old and the new one in a single run: cat cert1.pem cert2.pem | argocd cert add-tls git.example.com --upsert Note To replace an existing certificate for a server, use the --upsert flag to the cert add-tls CLI command. Note TLS certificates are configured on a per-server, not on a per-repository basis. If you connect multiple repositories from the same server, you only have to configure the certificates once for this server. Note It can take up to a couple of minutes until the changes performed by the argocd cert command are propagated across your cluster, depending on your Kubernetes setup. You can also manage TLS certificates in a declarative, self-managed ArgoCD setup. All TLS certificates are stored in the ConfigMap object argocd-tls-cert-cm . Managing TLS certificates via the web UI is currently not possible. Before v1.2 We do not currently have first-class support for this. See #1513 . As a work-around, you can customize your Argo CD image. See #1344","title":"Self-signed &amp; Untrusted TLS Certificates"},{"location":"user-guide/private-repositories/#unknown-ssh-hosts","text":"If you are using a privately hosted Git service over SSH, then you have the following options: v1.2 or later You can let ArgoCD connect the repository in an insecure way, without verifying the server's SSH host key at all. This can be accomplished by using the --insecure-skip-server-verification flag when adding the repository with the argocd CLI utility. However, this should be done only for non-production setups, as it imposes a serious security issue through possible man-in-the-middle attacks. You can make the server's SSH public key known to ArgoCD by using the cert add-ssh command of the argocd CLI utility. This is the recommended method and suitable for production use. In order to do so, you will need the server's SSH public host key, in the known_hosts format understood by ssh . You can get the server's public SSH host key e.g. by using the ssh-keyscan utility. Example for adding all available SSH public host keys for a server to ArgoCD: ssh-keyscan server.example.com | argocd cert add-ssh --batch Example for importing an existing known_hosts file to ArgoCD: argocd cert add-ssh --batch --from /etc/ssh/ssh_known_hosts Note It can take up to a couple of minutes until the changes performed by the argocd cert command are propagated across your cluster, depending on your Kubernetes setup. You can also manage SSH known hosts entries in a declarative, self-managed ArgoCD setup. All SSH public host keys are stored in the ConfigMap object argocd-ssh-known-hosts-cm . Managing SSH public host keys via the web UI is currently not possible. Before v1.2 (1) You can customize the Argo CD Docker image by adding the host's SSH public key to /etc/ssh/ssh_known_hosts . Additional entries to this file can be generated using the ssh-keyscan utility (e.g. ssh-keyscan your-private-git-server.com . For more information see example which demonstrates how /etc/ssh/ssh_known_hosts can be customized. Note The /etc/ssh/ssh_known_hosts should include Git host on each Argo CD deployment as well as on a computer where argocd repo add is executed. After resolving issue #1514 only argocd-repo-server deployment has to be customized. (1) Add repository using Argo CD CLI and --insecure-ignore-host-key flag: argocd repo add git@github.com:argoproj/argocd-example-apps.git --ssh-private-key-path ~/.ssh/id_rsa --insecure-ignore-host-key Don't use in production The --insecure-ignore-host-key should not be used in production as this is subject to man-in-the-middle attacks. This does not work for Kustomize remote bases or custom plugins For Kustomize support, see #827 .","title":"Unknown SSH Hosts"},{"location":"user-guide/private-repositories/#declarative-configuration","text":"See declarative setup","title":"Declarative Configuration"},{"location":"user-guide/projects/","text":"Projects Projects provide a logical grouping of applications, which is useful when Argo CD is used by multiple teams. Projects provide the following features: restrict what may be deployed (trusted Git source repositories) restrict where apps may be deployed to (destination clusters and namespaces) restrict what kinds of objects may or may not be deployed (e.g. RBAC, CRDs, DaemonSets, NetworkPolicy etc...) defining project roles to provide application RBAC (bound to OIDC groups and/or JWT tokens) The Default Project Every application belongs to a single project. If unspecified, an application belongs to the default project, which is created automatically and by default, permits deployments from any source repo, to any cluster, and all resource Kinds. The default project can be modified, but not deleted. When initially created, it's specification is configured to be the most permissive: spec : sourceRepos : - * destinations : - namespace : * server : * clusterResourceWhitelist : - group : * kind : * Creating Projects Additional projects can be created to give separate teams different levels of access to namespaces. The following command creates a new project myproject which can deploy applications to namespace mynamespace of cluster https://kubernetes.default.svc . The permitted Git source repository is set to https://github.com/argoproj/argocd-example-apps.git repository. argocd proj create myproject -d https://kubernetes.default.svc,mynamespace -s https://github.com/argoproj/argocd-example-apps.git Managing Projects Permitted source Git repositories are managed using commands: argocd proj add-source PROJECT REPO argocd proj remove-source PROJECT REPO Permitted destination clusters and namespaces are managed with the commands: argocd proj add-destination PROJECT CLUSTER , NAMESPACE argocd proj remove-destination PROJECT CLUSTER , NAMESPACE Permitted destination K8s resource kinds are managed with the commands. Note that namespaced-scoped resources are restricted via a blacklist, whereas cluster-scoped resources are restricted via whitelist. argocd proj allow-cluster-resource PROJECT GROUP KIND argocd proj allow-namespace-resource PROJECT GROUP KIND argocd proj deny-cluster-resource PROJECT GROUP KIND argocd proj deny-namespace-resource PROJECT GROUP KIND Assign Application To A Project The application project can be changed using app set command. In order to change the project of an app, the user must have permissions to access the new project. argocd app set guestbook - default --project myproject Configuring RBAC With Projects Once projects have been defined, RBAC rules can be written to restrict access to the applications in the project. The following example configures RBAC for two GitHub teams: team1 and team2 , both in the GitHub org, some-github-org . There are two projects, project-a and project-b . team1 can only manage applications in project-a , while team2 can only manage applications in project-b . Both team1 and team2 have the ability to manage repositories. ConfigMap argocd-rbac-cm example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-rbac-cm namespace : argocd data : policy.default : policy.csv : | p, some-github-org:team1, applications, *, project-a/*, allow p, some-github-org:team2, applications, *, project-a/*, allow p, role:org-admin, repositories, get, *, allow p, role:org-admin, repositories, create, *, allow p, role:org-admin, repositories, update, *, allow p, role:org-admin, repositories, delete, *, allow g, some-github-org:team1, org-admin g, some-github-org:team2, org-admin Project Roles Projects include a feature called roles that enable automated access to a project's applications. These can be used to give a CI pipeline a restricted set of permissions. For example, a CI system may only be able to sync a single app (but not change its source or destination). Projects can have multiple roles, and those roles can have different access granted to them. These permissions are called policies, and they are stored within the role as a list of policy strings. A role's policy can only grant access to that role and are limited to applications within the role's project. However, the policies have an option for granting wildcard access to any application within a project. In order to create roles in a project and add policies to a role, a user will need permission to update a project. The following commands can be used to manage a role. argocd proj role list argocd proj role get argocd proj role create argocd proj role delete argocd proj role add-policy argocd proj role remove-policy Project roles in itself are not useful without generating a token to associate to that role. Argo CD supports JWT tokens as the means to authenticate to a role. Since the JWT token is associated with a role's policies, any changes to the role's policies will immediately take effect for that JWT token. The following commands are used to manage the JWT tokens. argocd proj role create-token PROJECT ROLE-NAME argocd proj role delete-token PROJECT ROLE-NAME ISSUED-AT Since the JWT tokens aren't stored in Argo CD, they can only be retrieved when they are created. A user can leverage them in the cli by either passing them in using the --auth-token flag or setting the ARGOCD_AUTH_TOKEN environment variable. The JWT tokens can be used until they expire or are revoked. The JWT tokens can created with or without an expiration, but the default on the cli is creates them without an expirations date. Even if a token has not expired, it cannot be used if the token has been revoked. Below is an example of leveraging a JWT token to access a guestbook application. It makes the assumption that the user already has a project named myproject and an application called guestbook-default. PROJ = myproject APP = guestbook-default ROLE = get-role argocd proj role create $PROJ $ROLE argocd proj role create-token $PROJ $ROLE -e 10m JWT = value from command above argocd proj role list $PROJ argocd proj role get $PROJ $ROLE # This command will fail because the JWT Token associated with the project role does not have a policy to allow access to the application argocd app get $APP --auth-token $JWT # Adding a policy to grant access to the application for the new role argocd proj role add-policy $PROJ $ROLE --action get --permission allow --object $APP argocd app get $PROJ - $ROLE --auth-token $JWT # Removing the policy we added and adding one with a wildcard. argocd proj role remove-policy $PROJ $TOKEN -a get -o $PROJ - $TOKEN argocd proj role remove-policy $PROJ $TOKEN -a get -o * # The wildcard allows us to access the application due to the wildcard. argocd app get $PROJ - $TOKEN --auth-token $JWT argocd proj role get $PROJ argocd proj role get $PROJ $ROLE # Revoking the JWT token argocd proj role delete-token $PROJ $ROLE id field from the last command # This will fail since the JWT Token was deleted for the project role. argocd app get $APP --auth-token $JWT","title":"Projects"},{"location":"user-guide/projects/#projects","text":"Projects provide a logical grouping of applications, which is useful when Argo CD is used by multiple teams. Projects provide the following features: restrict what may be deployed (trusted Git source repositories) restrict where apps may be deployed to (destination clusters and namespaces) restrict what kinds of objects may or may not be deployed (e.g. RBAC, CRDs, DaemonSets, NetworkPolicy etc...) defining project roles to provide application RBAC (bound to OIDC groups and/or JWT tokens)","title":"Projects"},{"location":"user-guide/projects/#the-default-project","text":"Every application belongs to a single project. If unspecified, an application belongs to the default project, which is created automatically and by default, permits deployments from any source repo, to any cluster, and all resource Kinds. The default project can be modified, but not deleted. When initially created, it's specification is configured to be the most permissive: spec : sourceRepos : - * destinations : - namespace : * server : * clusterResourceWhitelist : - group : * kind : *","title":"The Default Project"},{"location":"user-guide/projects/#creating-projects","text":"Additional projects can be created to give separate teams different levels of access to namespaces. The following command creates a new project myproject which can deploy applications to namespace mynamespace of cluster https://kubernetes.default.svc . The permitted Git source repository is set to https://github.com/argoproj/argocd-example-apps.git repository. argocd proj create myproject -d https://kubernetes.default.svc,mynamespace -s https://github.com/argoproj/argocd-example-apps.git","title":"Creating Projects"},{"location":"user-guide/projects/#managing-projects","text":"Permitted source Git repositories are managed using commands: argocd proj add-source PROJECT REPO argocd proj remove-source PROJECT REPO Permitted destination clusters and namespaces are managed with the commands: argocd proj add-destination PROJECT CLUSTER , NAMESPACE argocd proj remove-destination PROJECT CLUSTER , NAMESPACE Permitted destination K8s resource kinds are managed with the commands. Note that namespaced-scoped resources are restricted via a blacklist, whereas cluster-scoped resources are restricted via whitelist. argocd proj allow-cluster-resource PROJECT GROUP KIND argocd proj allow-namespace-resource PROJECT GROUP KIND argocd proj deny-cluster-resource PROJECT GROUP KIND argocd proj deny-namespace-resource PROJECT GROUP KIND","title":"Managing Projects"},{"location":"user-guide/projects/#assign-application-to-a-project","text":"The application project can be changed using app set command. In order to change the project of an app, the user must have permissions to access the new project. argocd app set guestbook - default --project myproject","title":"Assign Application To A Project"},{"location":"user-guide/projects/#configuring-rbac-with-projects","text":"Once projects have been defined, RBAC rules can be written to restrict access to the applications in the project. The following example configures RBAC for two GitHub teams: team1 and team2 , both in the GitHub org, some-github-org . There are two projects, project-a and project-b . team1 can only manage applications in project-a , while team2 can only manage applications in project-b . Both team1 and team2 have the ability to manage repositories. ConfigMap argocd-rbac-cm example: apiVersion : v1 kind : ConfigMap metadata : name : argocd-rbac-cm namespace : argocd data : policy.default : policy.csv : | p, some-github-org:team1, applications, *, project-a/*, allow p, some-github-org:team2, applications, *, project-a/*, allow p, role:org-admin, repositories, get, *, allow p, role:org-admin, repositories, create, *, allow p, role:org-admin, repositories, update, *, allow p, role:org-admin, repositories, delete, *, allow g, some-github-org:team1, org-admin g, some-github-org:team2, org-admin","title":"Configuring RBAC With Projects"},{"location":"user-guide/projects/#project-roles","text":"Projects include a feature called roles that enable automated access to a project's applications. These can be used to give a CI pipeline a restricted set of permissions. For example, a CI system may only be able to sync a single app (but not change its source or destination). Projects can have multiple roles, and those roles can have different access granted to them. These permissions are called policies, and they are stored within the role as a list of policy strings. A role's policy can only grant access to that role and are limited to applications within the role's project. However, the policies have an option for granting wildcard access to any application within a project. In order to create roles in a project and add policies to a role, a user will need permission to update a project. The following commands can be used to manage a role. argocd proj role list argocd proj role get argocd proj role create argocd proj role delete argocd proj role add-policy argocd proj role remove-policy Project roles in itself are not useful without generating a token to associate to that role. Argo CD supports JWT tokens as the means to authenticate to a role. Since the JWT token is associated with a role's policies, any changes to the role's policies will immediately take effect for that JWT token. The following commands are used to manage the JWT tokens. argocd proj role create-token PROJECT ROLE-NAME argocd proj role delete-token PROJECT ROLE-NAME ISSUED-AT Since the JWT tokens aren't stored in Argo CD, they can only be retrieved when they are created. A user can leverage them in the cli by either passing them in using the --auth-token flag or setting the ARGOCD_AUTH_TOKEN environment variable. The JWT tokens can be used until they expire or are revoked. The JWT tokens can created with or without an expiration, but the default on the cli is creates them without an expirations date. Even if a token has not expired, it cannot be used if the token has been revoked. Below is an example of leveraging a JWT token to access a guestbook application. It makes the assumption that the user already has a project named myproject and an application called guestbook-default. PROJ = myproject APP = guestbook-default ROLE = get-role argocd proj role create $PROJ $ROLE argocd proj role create-token $PROJ $ROLE -e 10m JWT = value from command above argocd proj role list $PROJ argocd proj role get $PROJ $ROLE # This command will fail because the JWT Token associated with the project role does not have a policy to allow access to the application argocd app get $APP --auth-token $JWT # Adding a policy to grant access to the application for the new role argocd proj role add-policy $PROJ $ROLE --action get --permission allow --object $APP argocd app get $PROJ - $ROLE --auth-token $JWT # Removing the policy we added and adding one with a wildcard. argocd proj role remove-policy $PROJ $TOKEN -a get -o $PROJ - $TOKEN argocd proj role remove-policy $PROJ $TOKEN -a get -o * # The wildcard allows us to access the application due to the wildcard. argocd app get $PROJ - $TOKEN --auth-token $JWT argocd proj role get $PROJ argocd proj role get $PROJ $ROLE # Revoking the JWT token argocd proj role delete-token $PROJ $ROLE id field from the last command # This will fail since the JWT Token was deleted for the project role. argocd app get $APP --auth-token $JWT","title":"Project Roles"},{"location":"user-guide/resource_hooks/","text":"Resource Hooks Warning Helm hooks are currently ignored. Read more . Overview Synchronization can be configured using resource hooks. Hooks are ways to interject custom logic before, during, and after a Sync operation. Some use cases for hooks are: Using a PreSync hook to perform a database schema migration before deploying a new version of the app. Using a Sync hook to orchestrate a complex deployment requiring more sophistication than the kubernetes rolling update strategy (e.g. a blue/green deployment). Using a PostSync hook to run integration and health checks after a deployment. Using a SyncFail hook to run clean-up or finalizer logic if a Sync operation fails. Usage Hooks are simply kubernetes manifests annotated with the argocd.argoproj.io/hook annotation. To make use of hooks, simply add the annotation to any resource: apiVersion : batch/v1 kind : Job metadata : generateName : schema-migrate- annotations : argocd.argoproj.io/hook : PreSync During a Sync operation, Argo CD will create the resource during the appropriate stage of the deployment. Hooks can be any type of Kuberentes resource kind, but tend to be most useful as a Pod, Job or Argo Workflows . Multiple hooks can be specified as a comma separated list. Available Hooks The following hooks are defined: Hook Description PreSync Executes prior to the apply of the manifests. Sync Executes after all PreSync hooks completed and were successful. Occurs in conjuction with the apply of the manifests. Skip Indicates to Argo CD to skip the apply of the manifest. This is typically used in conjunction with a Sync hook which is presumably handling the deployment in an alternate way (e.g. blue-green deployment) PostSync Executes after all Sync hooks completed and were successful, a succcessful apply, and all resources in a Healthy state. SyncFail Executes if and only if any part of the Sync operation fails. Selective Sync Hooks are run during selective sync . Hook Deletion Policies Hooks can be deleted in an automatic fashion using the annotation: argocd.argoproj.io/hook-delete-policy . apiVersion : batch/v1 kind : Job metadata : generateName : integration-test- annotations : argocd.argoproj.io/hook : PostSync argocd.argoproj.io/hook-delete-policy : HookSucceeded The following policies define when the hook will be deleted. Policy Description HookSucceeded The hook resource is deleted after the hook succeeded (e.g. Job/Workflow completed successfully). HookFailed The hook resource is deleted after the hook failed. As an alternative to hook deletion policies, both Jobs and Argo Workflows support the ttlSecondsAfterFinished field in the spec, which let their respective controllers delete the Job/Workflow after it completes. spec : ttlSecondsAfterFinished : 600","title":"Resource Hooks"},{"location":"user-guide/resource_hooks/#resource-hooks","text":"Warning Helm hooks are currently ignored. Read more .","title":"Resource Hooks"},{"location":"user-guide/resource_hooks/#overview","text":"Synchronization can be configured using resource hooks. Hooks are ways to interject custom logic before, during, and after a Sync operation. Some use cases for hooks are: Using a PreSync hook to perform a database schema migration before deploying a new version of the app. Using a Sync hook to orchestrate a complex deployment requiring more sophistication than the kubernetes rolling update strategy (e.g. a blue/green deployment). Using a PostSync hook to run integration and health checks after a deployment. Using a SyncFail hook to run clean-up or finalizer logic if a Sync operation fails.","title":"Overview"},{"location":"user-guide/resource_hooks/#usage","text":"Hooks are simply kubernetes manifests annotated with the argocd.argoproj.io/hook annotation. To make use of hooks, simply add the annotation to any resource: apiVersion : batch/v1 kind : Job metadata : generateName : schema-migrate- annotations : argocd.argoproj.io/hook : PreSync During a Sync operation, Argo CD will create the resource during the appropriate stage of the deployment. Hooks can be any type of Kuberentes resource kind, but tend to be most useful as a Pod, Job or Argo Workflows . Multiple hooks can be specified as a comma separated list.","title":"Usage"},{"location":"user-guide/resource_hooks/#available-hooks","text":"The following hooks are defined: Hook Description PreSync Executes prior to the apply of the manifests. Sync Executes after all PreSync hooks completed and were successful. Occurs in conjuction with the apply of the manifests. Skip Indicates to Argo CD to skip the apply of the manifest. This is typically used in conjunction with a Sync hook which is presumably handling the deployment in an alternate way (e.g. blue-green deployment) PostSync Executes after all Sync hooks completed and were successful, a succcessful apply, and all resources in a Healthy state. SyncFail Executes if and only if any part of the Sync operation fails.","title":"Available Hooks"},{"location":"user-guide/resource_hooks/#selective-sync","text":"Hooks are run during selective sync .","title":"Selective Sync"},{"location":"user-guide/resource_hooks/#hook-deletion-policies","text":"Hooks can be deleted in an automatic fashion using the annotation: argocd.argoproj.io/hook-delete-policy . apiVersion : batch/v1 kind : Job metadata : generateName : integration-test- annotations : argocd.argoproj.io/hook : PostSync argocd.argoproj.io/hook-delete-policy : HookSucceeded The following policies define when the hook will be deleted. Policy Description HookSucceeded The hook resource is deleted after the hook succeeded (e.g. Job/Workflow completed successfully). HookFailed The hook resource is deleted after the hook failed. As an alternative to hook deletion policies, both Jobs and Argo Workflows support the ttlSecondsAfterFinished field in the spec, which let their respective controllers delete the Job/Workflow after it completes. spec : ttlSecondsAfterFinished : 600","title":"Hook Deletion Policies"},{"location":"user-guide/selective_sync/","text":"Selective Sync A selective sync is one where only some resources are sync'd. You can choose which resources from the UI: When doing so, bear in mind: Your sync is not recorded in the history, and so rollback is not possible.","title":"Selective Sync"},{"location":"user-guide/selective_sync/#selective-sync","text":"A selective sync is one where only some resources are sync'd. You can choose which resources from the UI: When doing so, bear in mind: Your sync is not recorded in the history, and so rollback is not possible.","title":"Selective Sync"},{"location":"user-guide/status-badge/","text":"Status Badge v1.2 Argo CD can display a badge with health and sync status for any application. The feature is disabled by default because badge image is available to any user without authentication. The feature can be enabled using statusbadge.enabled key of argocd-cm ConfigMap (see argocd-cm.yaml ). To show this badge, use the following URL format ${argoCdBaseUrl}/api/badge?name=${appName} , e.g. http://localhost:8080/api/badge?name=guestbook. The URLs for status image are available on application details page: Navigate to application details page and click on 'Details' button. Scroll down to 'Status Badge' section. Select required template such as URL, Markdown etc. for the status image URL in markdown, html, etc are available . Copy the text and paste it into your README or website.","title":"Status Badge"},{"location":"user-guide/status-badge/#status-badge","text":"v1.2 Argo CD can display a badge with health and sync status for any application. The feature is disabled by default because badge image is available to any user without authentication. The feature can be enabled using statusbadge.enabled key of argocd-cm ConfigMap (see argocd-cm.yaml ). To show this badge, use the following URL format ${argoCdBaseUrl}/api/badge?name=${appName} , e.g. http://localhost:8080/api/badge?name=guestbook. The URLs for status image are available on application details page: Navigate to application details page and click on 'Details' button. Scroll down to 'Status Badge' section. Select required template such as URL, Markdown etc. for the status image URL in markdown, html, etc are available . Copy the text and paste it into your README or website.","title":"Status Badge"},{"location":"user-guide/sync-options/","text":"Sync Options No Prune Resources v1.1 You may wish to prevent an object from being pruned: metadata : annotations : argocd.argoproj.io/sync-options : Prune=false In the UI, the pod will simply appear as out-of-sync: The sync-status panel shows that pruning was skipped, and why: The app will be out of sync if Argo CD expects a resource to be pruned. You may wish to use this along with compare options . Disable Kubectl Validation v1.2 For a certain class of objects, it is necessary to kubectl apply them using the --validate=false flag. Examples of this are kubernetes types which uses RawExtension , such as ServiceCatalog . You can do using this annotations: metadata : annotations : argocd.argoproj.io/sync-options : Validate=false If you want to exclude a whole class of objects globally, consider setting resource.customizations in system level configuation .","title":"Sync Options"},{"location":"user-guide/sync-options/#sync-options","text":"","title":"Sync Options"},{"location":"user-guide/sync-options/#no-prune-resources","text":"v1.1 You may wish to prevent an object from being pruned: metadata : annotations : argocd.argoproj.io/sync-options : Prune=false In the UI, the pod will simply appear as out-of-sync: The sync-status panel shows that pruning was skipped, and why: The app will be out of sync if Argo CD expects a resource to be pruned. You may wish to use this along with compare options .","title":"No Prune Resources"},{"location":"user-guide/sync-options/#disable-kubectl-validation","text":"v1.2 For a certain class of objects, it is necessary to kubectl apply them using the --validate=false flag. Examples of this are kubernetes types which uses RawExtension , such as ServiceCatalog . You can do using this annotations: metadata : annotations : argocd.argoproj.io/sync-options : Validate=false If you want to exclude a whole class of objects globally, consider setting resource.customizations in system level configuation .","title":"Disable Kubectl Validation"},{"location":"user-guide/sync-waves/","text":"Sync Phases and Waves v1.1 Argo CD executes a sync operation in a number of steps. At a high-level, there are three phases pre-sync , sync and post-sync . Within each phase you can have one or more waves, than allows you to ensure certain resources are healthy before subsequent resources are synced. How Do I Configure Phases? Pre-sync and post-sync can only contain hooks. Apply the hook annotation: metadata : annotations : argocd.argoproj.io/hook : PreSync Read more about hooks . How Do I Configure Waves? Specify the wave using the following annotation: metadata : annotations : argocd.argoproj.io/sync-wave : 5 Hooks and resources are assigned to wave zero by default. The wave can be negative, so you can create a wave that runs before all other resources. How Does It Work? When Argo CD starts a sync, it orders the resources in the following precedence: The phase The wave they are in (lower values first) By kind (e.g. namespaces first) By name It then determines which the number of the next wave to apply. This is the first number where any resource is out-of-sync or unhealthy. It applies resources in that wave. It repeats this process until all phases and waves are in in-sync and healthy. Because an application can have resources that are unhealthy in the first wave, it may be that the app can never get to healthy.","title":"Sync Phases and Waves"},{"location":"user-guide/sync-waves/#sync-phases-and-waves","text":"v1.1 Argo CD executes a sync operation in a number of steps. At a high-level, there are three phases pre-sync , sync and post-sync . Within each phase you can have one or more waves, than allows you to ensure certain resources are healthy before subsequent resources are synced.","title":"Sync Phases and Waves"},{"location":"user-guide/sync-waves/#how-do-i-configure-phases","text":"Pre-sync and post-sync can only contain hooks. Apply the hook annotation: metadata : annotations : argocd.argoproj.io/hook : PreSync Read more about hooks .","title":"How Do I Configure Phases?"},{"location":"user-guide/sync-waves/#how-do-i-configure-waves","text":"Specify the wave using the following annotation: metadata : annotations : argocd.argoproj.io/sync-wave : 5 Hooks and resources are assigned to wave zero by default. The wave can be negative, so you can create a wave that runs before all other resources.","title":"How Do I Configure Waves?"},{"location":"user-guide/sync-waves/#how-does-it-work","text":"When Argo CD starts a sync, it orders the resources in the following precedence: The phase The wave they are in (lower values first) By kind (e.g. namespaces first) By name It then determines which the number of the next wave to apply. This is the first number where any resource is out-of-sync or unhealthy. It applies resources in that wave. It repeats this process until all phases and waves are in in-sync and healthy. Because an application can have resources that are unhealthy in the first wave, it may be that the app can never get to healthy.","title":"How Does It Work?"},{"location":"user-guide/tool_detection/","text":"Tool Detection The tool used to build an application is detected as follows: If a specific tool is explicitly configured, then that tool is selected to create your application's manifests. If not, then the tool is detected implicitly as follows: Ksonnet if there are two files, one named app.yaml and one named components/params.libsonnet . Helm if there's a file matching Chart.yaml . Kustomize if there's a kustomization.yaml , kustomization.yml , or Kustomization Otherwise it is assumed to be a plain directory application. References reposerver/repository/repository.go/GetAppSourceType server/repository/repository.go/listAppTypes","title":"Tool Detection"},{"location":"user-guide/tool_detection/#tool-detection","text":"The tool used to build an application is detected as follows: If a specific tool is explicitly configured, then that tool is selected to create your application's manifests. If not, then the tool is detected implicitly as follows: Ksonnet if there are two files, one named app.yaml and one named components/params.libsonnet . Helm if there's a file matching Chart.yaml . Kustomize if there's a kustomization.yaml , kustomization.yml , or Kustomization Otherwise it is assumed to be a plain directory application.","title":"Tool Detection"},{"location":"user-guide/tool_detection/#references","text":"reposerver/repository/repository.go/GetAppSourceType server/repository/repository.go/listAppTypes","title":"References"},{"location":"user-guide/tracking_strategies/","text":"Tracking and Deployment Strategies An Argo CD application spec provides several different ways of track kubernetes resource manifests in Git. This document describes the different techniques and the means of deploying those manifests to the target environment. HEAD / Branch Tracking If a branch name, or a symbolic reference (like HEAD) is specified, Argo CD will continually compare live state against the resource manifests defined at the tip of the specified branch or the dereferenced commit of the symbolic reference. To redeploy an application, a user makes changes to the manifests, and commit/pushes those the changes to the tracked branch/symbolic reference, which will then be detected by Argo CD controller. Tag Tracking If a tag is specified, the manifests at the specified Git tag will be used to perform the sync comparison. This provides some advantages over branch tracking in that a tag is generally considered more stable, and less frequently updated, with some manual judgement of what constitutes a tag. To redeploy an application, the user uses Git to change the meaning of a tag by retagging it to a different commit SHA. Argo CD will detect the new meaning of the tag when performing the comparison/sync. Commit Pinning If a Git commit SHA is specified, the application is effectively pinned to the manifests defined at the specified commit. This is the most restrictive of the techniques and is typically used to control production environments. Since commit SHAs cannot change meaning, the only way to change the live state of an application which is pinned to a commit, is by updating the tracking revision in the application to a different commit containing the new manifests. Note that parameter overrides can still be set on an application which is pinned to a revision. Automated Sync In all tracking strategies, the application has the option to sync automatically. If auto-sync is configured, the new resources manifests will be applied automatically -- as soon as a difference is detected between the target state (Git) and live state. If auto-sync is disabled, a manual sync will be needed using the Argo UI, CLI, or API. Parameter Overrides Note that in all tracking strategies, any parameter overrides set in the application instance take precedence over the Git state.","title":"Tracking and Deployment Strategies"},{"location":"user-guide/tracking_strategies/#tracking-and-deployment-strategies","text":"An Argo CD application spec provides several different ways of track kubernetes resource manifests in Git. This document describes the different techniques and the means of deploying those manifests to the target environment.","title":"Tracking and Deployment Strategies"},{"location":"user-guide/tracking_strategies/#head-branch-tracking","text":"If a branch name, or a symbolic reference (like HEAD) is specified, Argo CD will continually compare live state against the resource manifests defined at the tip of the specified branch or the dereferenced commit of the symbolic reference. To redeploy an application, a user makes changes to the manifests, and commit/pushes those the changes to the tracked branch/symbolic reference, which will then be detected by Argo CD controller.","title":"HEAD / Branch Tracking"},{"location":"user-guide/tracking_strategies/#tag-tracking","text":"If a tag is specified, the manifests at the specified Git tag will be used to perform the sync comparison. This provides some advantages over branch tracking in that a tag is generally considered more stable, and less frequently updated, with some manual judgement of what constitutes a tag. To redeploy an application, the user uses Git to change the meaning of a tag by retagging it to a different commit SHA. Argo CD will detect the new meaning of the tag when performing the comparison/sync.","title":"Tag Tracking"},{"location":"user-guide/tracking_strategies/#commit-pinning","text":"If a Git commit SHA is specified, the application is effectively pinned to the manifests defined at the specified commit. This is the most restrictive of the techniques and is typically used to control production environments. Since commit SHAs cannot change meaning, the only way to change the live state of an application which is pinned to a commit, is by updating the tracking revision in the application to a different commit containing the new manifests. Note that parameter overrides can still be set on an application which is pinned to a revision.","title":"Commit Pinning"},{"location":"user-guide/tracking_strategies/#automated-sync","text":"In all tracking strategies, the application has the option to sync automatically. If auto-sync is configured, the new resources manifests will be applied automatically -- as soon as a difference is detected between the target state (Git) and live state. If auto-sync is disabled, a manual sync will be needed using the Argo UI, CLI, or API.","title":"Automated Sync"},{"location":"user-guide/tracking_strategies/#parameter-overrides","text":"Note that in all tracking strategies, any parameter overrides set in the application instance take precedence over the Git state.","title":"Parameter Overrides"}]}